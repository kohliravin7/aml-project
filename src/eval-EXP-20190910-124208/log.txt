2019-09-10 12:42:19,602 Evaluate: [2.38912492e+01 3.87260251e-01 7.74709142e+00 5.52115588e-02
 2.33652277e-01 3.43746865e+00 1.43725224e+00 4.55496617e-04]
2019-09-10 12:42:19,700 gpu device = cuda:0
2019-09-10 12:42:19,700 config = {'batch_size': 32, 'drop_path_prob': 0.15490410044073497, 'grad_clip_value': 8, 'initial_lr': 1.8882426118644182e-06, 'lr_scheduler': 'Exponential', 'n_conv_layers': 6, 'optimizer': 'adad', 'weight_decay': 1.0020998410272621e-05}
2019-09-10 12:43:07,026 param size = 0.255930MB
2019-09-10 12:43:07,522 epoch 0 lr 1.888243e-07
2019-09-10 12:43:12,503 train 000 2.394835e+00 12.500000 40.625000
2019-09-10 12:43:21,927 train 050 2.351189e+00 7.322304 48.897059
2019-09-10 12:43:31,336 train 100 2.352858e+00 7.193688 47.617574
2019-09-10 12:43:40,744 train 150 2.353511e+00 6.932947 47.299255
2019-09-10 12:43:50,154 train 200 2.355045e+00 6.856343 46.937189
2019-09-10 12:43:59,564 train 250 2.353546e+00 6.928536 47.285857
2019-09-10 12:44:08,973 train 300 2.352476e+00 7.002699 47.601744
2019-09-10 12:44:18,378 train 350 2.351774e+00 7.006766 47.840990
2019-09-10 12:44:27,788 train 400 2.351263e+00 7.013716 47.969919
2019-09-10 12:44:37,192 train 450 2.350875e+00 7.067627 48.108370
2019-09-10 12:44:46,593 train 500 2.350838e+00 7.054641 48.156811
2019-09-10 12:44:55,989 train 550 2.350522e+00 7.024161 48.077359
2019-09-10 12:45:05,377 train 600 2.350206e+00 7.053349 48.055324
2019-09-10 12:45:14,767 train 650 2.350713e+00 7.018049 48.039075
2019-09-10 12:45:24,162 train 700 2.350680e+00 6.985556 48.029601
2019-09-10 12:45:33,367 train_acc 7.022917
2019-09-10 12:45:33,401 valid 000 2.387204e+00 4.687500 35.937500
2019-09-10 12:45:34,943 valid 050 2.350773e+00 7.475490 47.334559
2019-09-10 12:45:36,484 valid 100 2.352339e+00 7.209158 47.648515
2019-09-10 12:45:38,026 valid 150 2.349659e+00 7.357202 48.209851
2019-09-10 12:45:39,262 valid_acc 7.275000
2019-09-10 12:45:39,262 epoch 1 lr 1.888243e-08
2019-09-10 12:45:39,472 train 000 2.360397e+00 6.250000 51.562500
2019-09-10 12:45:49,117 train 050 2.354706e+00 7.689951 48.897059
2019-09-10 12:45:58,760 train 100 2.354243e+00 7.719678 48.406559
2019-09-10 12:46:08,405 train 150 2.354806e+00 7.698675 47.806291
2019-09-10 12:46:18,045 train 200 2.355120e+00 7.641480 48.064366
2019-09-10 12:46:27,690 train 250 2.354460e+00 7.706673 47.933267
2019-09-10 12:46:37,333 train 300 2.354117e+00 7.807309 47.913206
2019-09-10 12:46:46,976 train 350 2.353680e+00 7.883725 47.961182
2019-09-10 12:46:56,617 train 400 2.353294e+00 7.929395 48.176434
2019-09-10 12:47:06,255 train 450 2.353625e+00 7.951081 48.181125
2019-09-10 12:47:15,884 train 500 2.353918e+00 7.899825 48.200474
2019-09-10 12:47:25,512 train 550 2.354300e+00 7.863544 48.100045
2019-09-10 12:47:35,139 train 600 2.354017e+00 7.934692 48.156718
2019-09-10 12:47:44,772 train 650 2.353725e+00 7.906106 48.293491
2019-09-10 12:47:54,457 train 700 2.353602e+00 7.894971 48.348342
2019-09-10 12:48:03,934 train_acc 7.827083
2019-09-10 12:48:03,969 valid 000 2.352321e+00 4.687500 46.875000
2019-09-10 12:48:05,513 valid 050 2.330292e+00 8.363971 48.223039
2019-09-10 12:48:07,055 valid 100 2.335712e+00 8.013614 47.230817
2019-09-10 12:48:08,596 valid 150 2.335062e+00 8.143626 47.175083
2019-09-10 12:48:09,726 valid_acc 8.008333
2019-09-10 12:48:09,726 epoch 2 lr 1.888243e-09
2019-09-10 12:48:09,925 train 000 2.332361e+00 14.062500 50.000000
2019-09-10 12:48:19,623 train 050 2.363893e+00 7.567402 47.242647
2019-09-10 12:48:29,951 train 100 2.361735e+00 7.812500 48.004332
2019-09-10 12:48:39,598 train 150 2.359066e+00 8.071192 48.240894
2019-09-10 12:48:49,239 train 200 2.358865e+00 8.037935 48.491915
2019-09-10 12:48:58,882 train 250 2.357273e+00 8.273157 48.823456
2019-09-10 12:49:08,530 train 300 2.357406e+00 8.378322 48.852782
2019-09-10 12:49:18,170 train 350 2.358662e+00 8.248754 48.611111
2019-09-10 12:49:27,816 train 400 2.359785e+00 8.202151 48.433603
2019-09-10 12:49:37,456 train 450 2.360244e+00 8.120843 48.305848
2019-09-10 12:49:47,092 train 500 2.360294e+00 8.096307 48.303393
2019-09-10 12:49:56,733 train 550 2.360201e+00 8.110254 48.233326
2019-09-10 12:50:06,373 train 600 2.360051e+00 8.106281 48.232113
2019-09-10 12:50:16,014 train 650 2.359931e+00 8.150922 48.175883
2019-09-10 12:50:25,655 train 700 2.360088e+00 8.142386 48.201230
2019-09-10 12:50:35,107 train_acc 8.137500
2019-09-10 12:50:35,139 valid 000 2.334623e+00 9.375000 35.937500
2019-09-10 12:50:36,679 valid 050 2.340460e+00 9.375000 44.638480
2019-09-10 12:50:38,219 valid 100 2.333636e+00 10.133045 45.993193
2019-09-10 12:50:39,760 valid 150 2.331610e+00 10.120033 46.792219
2019-09-10 12:50:40,888 valid_acc 10.008333
2019-09-10 12:50:40,888 epoch 3 lr 1.888243e-10
2019-09-10 12:50:41,083 train 000 2.307962e+00 14.062500 53.125000
2019-09-10 12:50:50,721 train 050 2.367816e+00 9.742647 47.334559
2019-09-10 12:51:00,364 train 100 2.369518e+00 8.941832 47.246287
2019-09-10 12:51:10,005 train 150 2.365943e+00 8.909354 47.920116
2019-09-10 12:51:19,646 train 200 2.363235e+00 8.939677 48.328669
2019-09-10 12:51:29,286 train 250 2.362597e+00 8.777390 48.400149
2019-09-10 12:51:38,928 train 300 2.362499e+00 8.674211 48.447882
2019-09-10 12:51:48,568 train 350 2.363133e+00 8.595976 48.450855
2019-09-10 12:51:58,210 train 400 2.363662e+00 8.517768 48.340087
2019-09-10 12:52:07,851 train 450 2.364121e+00 8.432650 48.330100
2019-09-10 12:52:17,487 train 500 2.363872e+00 8.483034 48.331462
2019-09-10 12:52:27,129 train 550 2.362922e+00 8.501588 48.409142
2019-09-10 12:52:36,769 train 600 2.362320e+00 8.524854 48.562292
2019-09-10 12:52:46,409 train 650 2.362356e+00 8.542147 48.564708
2019-09-10 12:52:56,050 train 700 2.361897e+00 8.614925 48.622504
2019-09-10 12:53:05,498 train_acc 8.656250
2019-09-10 12:53:05,532 valid 000 2.317297e+00 12.500000 45.312500
2019-09-10 12:53:07,072 valid 050 2.330471e+00 9.926471 46.109069
2019-09-10 12:53:08,612 valid 100 2.330750e+00 10.241337 46.921411
2019-09-10 12:53:10,151 valid 150 2.332215e+00 10.140728 46.543874
2019-09-10 12:53:11,278 valid_acc 10.275000
2019-09-10 12:53:11,278 epoch 4 lr 1.888243e-11
2019-09-10 12:53:11,474 train 000 2.387145e+00 4.687500 50.000000
2019-09-10 12:53:21,114 train 050 2.366821e+00 8.425245 48.958333
2019-09-10 12:53:30,756 train 100 2.366872e+00 8.926361 48.932550
2019-09-10 12:53:40,399 train 150 2.367616e+00 8.816225 48.758278
2019-09-10 12:53:50,037 train 200 2.366728e+00 8.854167 48.958333
2019-09-10 12:53:59,893 train 250 2.367442e+00 8.951693 48.730080
2019-09-10 12:54:09,537 train 300 2.367228e+00 8.949336 48.738580
2019-09-10 12:54:19,176 train 350 2.367877e+00 8.849715 48.664530
2019-09-10 12:54:28,813 train 400 2.368828e+00 8.794420 48.753117
2019-09-10 12:54:38,442 train 450 2.368846e+00 8.779102 48.725055
2019-09-10 12:54:48,072 train 500 2.368009e+00 8.829217 48.814870
2019-09-10 12:54:57,702 train 550 2.368900e+00 8.770985 48.715404
2019-09-10 12:55:07,334 train 600 2.369136e+00 8.790037 48.728681
2019-09-10 12:55:16,971 train 650 2.369324e+00 8.772561 48.715918
2019-09-10 12:55:26,663 train 700 2.369191e+00 8.755350 48.658167
2019-09-10 12:55:36,182 train_acc 8.770833
2019-09-10 12:55:36,216 valid 000 2.355633e+00 7.812500 42.187500
2019-09-10 12:55:37,755 valid 050 2.334447e+00 10.079657 46.905637
2019-09-10 12:55:39,293 valid 100 2.335123e+00 10.225866 46.983292
2019-09-10 12:55:40,834 valid 150 2.336968e+00 10.057947 46.564570
2019-09-10 12:55:41,961 valid_acc 10.225000
2019-09-10 12:55:41,963 Configuration achieved a performance of 2.335721 in 802.355533 seconds
2019-09-10 12:55:41,963 Evaluate: [3.19274864e+01 1.17996324e-01 5.49662182e+00 1.18243871e-02
 1.18006918e+00 4.95029287e+00 5.59375501e-01 3.30343244e-05]
2019-09-10 12:55:41,964 gpu device = cuda:0
2019-09-10 12:55:41,964 config = {'batch_size': 32, 'drop_path_prob': 0.04719852978282222, 'grad_clip_value': 8, 'initial_lr': 1.1458346081253595e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'adad', 'weight_decay': 1.0001521402582232e-05}
2019-09-10 12:55:42,008 param size = 0.255930MB
2019-09-10 12:55:42,011 epoch 0 lr 1.036417e-06
2019-09-10 12:55:42,208 train 000 2.394835e+00 12.500000 40.625000
2019-09-10 12:55:51,635 train 050 2.351186e+00 7.322304 48.897059
2019-09-10 12:56:01,057 train 100 2.352853e+00 7.193688 47.617574
2019-09-10 12:56:10,477 train 150 2.353503e+00 6.932947 47.299255
2019-09-10 12:56:19,899 train 200 2.355035e+00 6.856343 46.944963
2019-09-10 12:56:29,320 train 250 2.353533e+00 6.934761 47.292082
2019-09-10 12:56:38,748 train 300 2.352460e+00 7.007890 47.606935
2019-09-10 12:56:48,166 train 350 2.351755e+00 7.011218 47.845442
2019-09-10 12:56:57,583 train 400 2.351242e+00 7.017612 47.973815
2019-09-10 12:57:07,006 train 450 2.350852e+00 7.071092 48.108370
2019-09-10 12:57:16,423 train 500 2.350812e+00 7.057759 48.156811
2019-09-10 12:57:25,843 train 550 2.350493e+00 7.026996 48.077359
2019-09-10 12:57:35,263 train 600 2.350175e+00 7.055948 48.055324
2019-09-10 12:57:44,688 train 650 2.350679e+00 7.020449 48.043875
2019-09-10 12:57:54,106 train 700 2.350644e+00 6.987785 48.034058
2019-09-10 12:58:03,340 train_acc 7.025000
2019-09-10 12:58:03,374 valid 000 2.387103e+00 4.687500 35.937500
2019-09-10 12:58:04,923 valid 050 2.350693e+00 7.475490 47.334559
2019-09-10 12:58:06,471 valid 100 2.352256e+00 7.209158 47.648515
2019-09-10 12:58:08,017 valid 150 2.349577e+00 7.367550 48.209851
2019-09-10 12:58:09,148 valid_acc 7.283333
2019-09-10 12:58:09,148 epoch 1 lr 7.499585e-07
2019-09-10 12:58:09,350 train 000 2.337937e+00 7.812500 50.000000
2019-09-10 12:58:19,008 train 050 2.348508e+00 7.935049 49.356618
2019-09-10 12:58:28,667 train 100 2.348410e+00 7.487624 49.118193
2019-09-10 12:58:38,329 train 150 2.350543e+00 7.408940 48.230546
2019-09-10 12:58:47,985 train 200 2.350901e+00 7.276119 48.126555
2019-09-10 12:58:57,641 train 250 2.350772e+00 7.295817 48.082669
2019-09-10 12:59:07,299 train 300 2.350547e+00 7.251869 48.172757
2019-09-10 12:59:16,964 train 350 2.350238e+00 7.224893 48.214922
2019-09-10 12:59:26,630 train 400 2.350316e+00 7.220231 48.211502
2019-09-10 12:59:36,294 train 450 2.350853e+00 7.178492 48.278132
2019-09-10 12:59:45,955 train 500 2.350978e+00 7.110778 48.290918
2019-09-10 12:59:55,618 train 550 2.351734e+00 6.992967 48.199297
2019-09-10 13:00:05,281 train 600 2.351722e+00 6.980553 48.102121
2019-09-10 13:00:14,946 train 650 2.351513e+00 7.015649 48.156682
2019-09-10 13:00:24,610 train 700 2.351589e+00 7.014533 48.158880
2019-09-10 13:00:34,077 train_acc 6.983333
2019-09-10 13:00:34,110 valid 000 2.362878e+00 4.687500 45.312500
2019-09-10 13:00:35,659 valid 050 2.339858e+00 7.475490 48.590686
2019-09-10 13:00:37,207 valid 100 2.343761e+00 7.332921 47.957921
2019-09-10 13:00:38,753 valid 150 2.343194e+00 7.305464 47.961507
2019-09-10 13:00:39,886 valid_acc 7.233333
2019-09-10 13:00:39,886 epoch 2 lr 3.958761e-07
2019-09-10 13:00:40,082 train 000 2.345737e+00 7.812500 45.312500
2019-09-10 13:00:49,742 train 050 2.358383e+00 6.617647 46.997549
2019-09-10 13:00:59,400 train 100 2.356243e+00 6.714109 47.509282
2019-09-10 13:01:09,063 train 150 2.352972e+00 7.119205 48.261589
2019-09-10 13:01:18,727 train 200 2.353012e+00 7.105100 48.243159
2019-09-10 13:01:28,384 train 250 2.352825e+00 7.040588 48.362799
2019-09-10 13:01:38,045 train 300 2.352451e+00 6.981935 48.468646
2019-09-10 13:01:47,705 train 350 2.353732e+00 6.895477 48.312856
2019-09-10 13:01:57,367 train 400 2.353936e+00 6.947475 48.379052
2019-09-10 13:02:07,028 train 450 2.354486e+00 6.939440 48.194983
2019-09-10 13:02:16,688 train 500 2.354445e+00 6.973553 48.191118
2019-09-10 13:02:26,348 train 550 2.354492e+00 6.950431 48.173775
2019-09-10 13:02:36,031 train 600 2.354469e+00 6.988353 48.078723
2019-09-10 13:02:45,735 train 650 2.354463e+00 7.018049 48.003072
2019-09-10 13:02:55,444 train 700 2.354266e+00 7.056883 48.002853
2019-09-10 13:03:04,910 train_acc 7.062500
2019-09-10 13:03:04,944 valid 000 2.338934e+00 10.937500 42.187500
2019-09-10 13:03:06,493 valid 050 2.351185e+00 6.770833 45.649510
2019-09-10 13:03:08,041 valid 100 2.342737e+00 6.977104 47.261757
2019-09-10 13:03:09,588 valid 150 2.340140e+00 7.357202 47.744205
2019-09-10 13:03:10,721 valid_acc 7.241667
2019-09-10 13:03:10,721 epoch 3 lr 1.094175e-07
2019-09-10 13:03:10,920 train 000 2.306992e+00 12.500000 59.375000
2019-09-10 13:03:20,581 train 050 2.353574e+00 7.751225 47.763480
2019-09-10 13:03:30,246 train 100 2.354525e+00 7.363861 47.957921
2019-09-10 13:03:39,910 train 150 2.354140e+00 7.439983 48.013245
2019-09-10 13:03:49,569 train 200 2.352200e+00 7.509328 48.585199
2019-09-10 13:03:59,230 train 250 2.352502e+00 7.345618 48.618028
2019-09-10 13:04:08,891 train 300 2.353239e+00 7.376453 48.473837
2019-09-10 13:04:18,552 train 350 2.353382e+00 7.451923 48.464209
2019-09-10 13:04:28,217 train 400 2.353951e+00 7.337126 48.418017
2019-09-10 13:04:37,878 train 450 2.354317e+00 7.313609 48.340493
2019-09-10 13:04:47,539 train 500 2.354680e+00 7.301023 48.184880
2019-09-10 13:04:57,211 train 550 2.354263e+00 7.268035 48.204968
2019-09-10 13:05:06,873 train 600 2.353964e+00 7.341930 48.239913
2019-09-10 13:05:16,535 train 650 2.354187e+00 7.385273 48.250288
2019-09-10 13:05:26,198 train 700 2.353899e+00 7.449180 48.326052
2019-09-10 13:05:35,669 train_acc 7.445833
2019-09-10 13:05:35,703 valid 000 2.341103e+00 4.687500 40.625000
2019-09-10 13:05:37,249 valid 050 2.334231e+00 7.536765 48.253676
2019-09-10 13:05:38,798 valid 100 2.334610e+00 7.797030 47.679455
2019-09-10 13:05:40,346 valid 150 2.336441e+00 7.533113 47.237169
2019-09-10 13:05:41,477 valid_acc 7.691667
2019-09-10 13:05:41,478 epoch 4 lr 0.000000e+00
2019-09-10 13:05:41,675 train 000 2.364559e+00 4.687500 54.687500
2019-09-10 13:05:51,337 train 050 2.353701e+00 7.352941 49.019608
2019-09-10 13:06:00,999 train 100 2.356320e+00 7.626856 48.855198
2019-09-10 13:06:10,660 train 150 2.353280e+00 7.709023 48.892798
2019-09-10 13:06:20,324 train 200 2.352229e+00 7.719216 49.245958
2019-09-10 13:06:29,986 train 250 2.352787e+00 7.538596 49.103586
2019-09-10 13:06:39,649 train 300 2.352490e+00 7.537375 49.153862
2019-09-10 13:06:49,312 train 350 2.352911e+00 7.532051 49.065171
2019-09-10 13:06:58,975 train 400 2.352646e+00 7.531951 49.162251
2019-09-10 13:07:08,640 train 450 2.353339e+00 7.542267 49.005682
2019-09-10 13:07:18,301 train 500 2.352971e+00 7.622255 49.048777
2019-09-10 13:07:27,962 train 550 2.353900e+00 7.596983 48.894056
2019-09-10 13:07:37,618 train 600 2.354224e+00 7.581115 48.869072
2019-09-10 13:07:47,269 train 650 2.354064e+00 7.615687 48.807124
2019-09-10 13:07:56,925 train 700 2.354515e+00 7.553941 48.780760
2019-09-10 13:08:06,385 train_acc 7.570833
2019-09-10 13:08:06,418 valid 000 2.306514e+00 9.375000 48.437500
2019-09-10 13:08:07,967 valid 050 2.327996e+00 8.547794 48.774510
2019-09-10 13:08:09,515 valid 100 2.332790e+00 7.998144 47.679455
2019-09-10 13:08:11,064 valid 150 2.334806e+00 8.081540 47.144040
2019-09-10 13:08:12,195 valid_acc 7.975000
2019-09-10 13:08:12,196 Configuration achieved a performance of 2.334932 in 750.233156 seconds
2019-09-10 13:08:12,197 Evaluate: [2.04998385e+01 2.66354991e-01 4.71654036e+00 9.92598167e-02
 1.42206669e+00 5.83974105e+00 2.57841706e+00 8.96447207e-04]
2019-09-10 13:08:12,197 Configuration achieved a performance of 100.000000 in 0.000241 seconds
2019-09-10 13:08:12,197 Start iteration 3 ... 
2019-09-10 13:08:12,197 Train model...
2019-09-10 13:08:16,034 Time to train the model: 3.836768
2019-09-10 13:08:48,504 Maximize acquisition function...
2019-09-10 13:09:01,913 Time to maximize the acquisition function: 13.407756
2019-09-10 13:09:01,914 Next candidate [2.22222222e+01 8.14814815e-02 6.59259259e+00 8.33335000e-02
 3.33333333e-01 5.38888889e+00 1.38888889e+00 3.95000000e-04]
2019-09-10 13:09:01,915 gpu device = cuda:0
2019-09-10 13:09:01,915 config = {'batch_size': 32, 'drop_path_prob': 0.0325925925925926, 'grad_clip_value': 8, 'initial_lr': 2.6101622241115896e-06, 'lr_scheduler': 'Exponential', 'n_conv_layers': 6, 'optimizer': 'adad', 'weight_decay': 1.0018206976844024e-05}
2019-09-10 13:09:01,966 param size = 0.255930MB
2019-09-10 13:09:01,968 epoch 0 lr 2.610162e-07
2019-09-10 13:09:02,180 train 000 2.394835e+00 12.500000 40.625000
2019-09-10 13:09:11,626 train 050 2.351188e+00 7.322304 48.897059
2019-09-10 13:09:21,047 train 100 2.352858e+00 7.193688 47.617574
2019-09-10 13:09:30,468 train 150 2.353510e+00 6.932947 47.299255
2019-09-10 13:09:39,888 train 200 2.355045e+00 6.856343 46.937189
2019-09-10 13:09:49,323 train 250 2.353545e+00 6.928536 47.285857
2019-09-10 13:09:58,797 train 300 2.352475e+00 7.002699 47.601744
2019-09-10 13:10:08,283 train 350 2.351773e+00 7.006766 47.840990
2019-09-10 13:10:17,702 train 400 2.351262e+00 7.013716 47.969919
2019-09-10 13:10:27,123 train 450 2.350874e+00 7.067627 48.108370
2019-09-10 13:10:36,544 train 500 2.350837e+00 7.054641 48.156811
2019-09-10 13:10:45,960 train 550 2.350520e+00 7.024161 48.077359
2019-09-10 13:10:55,381 train 600 2.350204e+00 7.053349 48.055324
2019-09-10 13:11:04,798 train 650 2.350711e+00 7.018049 48.039075
2019-09-10 13:11:14,213 train 700 2.350678e+00 6.985556 48.027372
2019-09-10 13:11:23,445 train_acc 7.022917
2019-09-10 13:11:23,479 valid 000 2.387199e+00 4.687500 35.937500
2019-09-10 13:11:25,030 valid 050 2.350769e+00 7.475490 47.334559
2019-09-10 13:11:26,579 valid 100 2.352335e+00 7.209158 47.648515
2019-09-10 13:11:28,131 valid 150 2.349655e+00 7.357202 48.209851
2019-09-10 13:11:29,263 valid_acc 7.275000
2019-09-10 13:11:29,263 epoch 1 lr 2.610162e-08
2019-09-10 13:11:29,460 train 000 2.338592e+00 7.812500 50.000000
2019-09-10 13:11:39,112 train 050 2.349707e+00 7.751225 49.203431
2019-09-10 13:11:48,768 train 100 2.349669e+00 7.441213 48.948020
2019-09-10 13:11:58,423 train 150 2.351982e+00 7.212334 48.023593
2019-09-10 13:12:08,075 train 200 2.352336e+00 7.221704 47.978856
2019-09-10 13:12:17,718 train 250 2.351903e+00 7.314492 48.001743
2019-09-10 13:12:27,365 train 300 2.351693e+00 7.236296 48.058555
2019-09-10 13:12:37,015 train 350 2.351393e+00 7.305021 48.112536
2019-09-10 13:12:46,666 train 400 2.351211e+00 7.344919 48.242675
2019-09-10 13:12:56,319 train 450 2.351564e+00 7.324002 48.229629
2019-09-10 13:13:05,969 train 500 2.351619e+00 7.276073 48.272206
2019-09-10 13:13:15,623 train 550 2.352027e+00 7.239678 48.193625
2019-09-10 13:13:25,273 train 600 2.351986e+00 7.237937 48.107321
2019-09-10 13:13:34,930 train 650 2.351824e+00 7.260465 48.173483
2019-09-10 13:13:44,583 train 700 2.351822e+00 7.273092 48.248039
2019-09-10 13:13:54,036 train_acc 7.227083
2019-09-10 13:13:54,070 valid 000 2.358418e+00 4.687500 40.625000
2019-09-10 13:13:55,618 valid 050 2.336233e+00 7.628676 48.345588
2019-09-10 13:13:57,165 valid 100 2.340656e+00 7.286510 47.772277
2019-09-10 13:13:58,712 valid 150 2.340025e+00 7.284768 47.826987
2019-09-10 13:13:59,845 valid_acc 7.208333
2019-09-10 13:13:59,846 Configuration achieved a performance of 2.341012 
2019-09-10 13:13:59,846 Evaluation of this configuration took 297.931660 seconds
2019-09-10 13:13:59,847 Current incumbent [3.19274864e+01 1.17996324e-01 5.49662182e+00 1.18243871e-02
 1.00000000e+00 4.95029287e+00 1.00000000e+00 3.30343244e-05] with estimated performance 2.334932
2019-09-10 13:13:59,847 Start iteration 4 ... 
2019-09-10 13:13:59,847 Train model...
2019-09-10 13:14:02,437 Time to train the model: 2.589752
2019-09-10 13:14:33,577 Maximize acquisition function...
2019-09-10 13:14:46,121 Time to maximize the acquisition function: 12.542638
2019-09-10 13:14:46,121 Next candidate [2.57777778e+01 1.11111111e-01 7.92592593e+00 5.00005000e-02
 1.66666667e+00 4.61111111e+00 1.83333333e+00 8.35000000e-04]
2019-09-10 13:14:46,122 Configuration achieved a performance of 100.000000 
2019-09-10 13:14:46,122 Evaluation of this configuration took 0.000237 seconds
2019-09-10 13:14:46,122 Current incumbent [3.19274864e+01 1.17996324e-01 5.49662182e+00 1.18243871e-02
 1.00000000e+00 4.95029287e+00 1.00000000e+00 3.30343244e-05] with estimated performance 2.334932
2019-09-10 13:14:46,122 Start iteration 5 ... 
2019-09-10 13:14:46,122 Train model...
2019-09-10 13:14:48,711 Time to train the model: 2.589103
2019-09-10 13:15:17,270 Maximize acquisition function...
2019-09-10 13:15:29,652 Time to maximize the acquisition function: 12.381244
2019-09-10 13:15:29,653 Next candidate [1.86666667e+01 6.66666667e-02 7.33333333e+00 8.33335000e-02
 3.33333333e-01 5.50000000e+00 2.83333333e+00 3.95000000e-04]
2019-09-10 13:15:29,653 Configuration achieved a performance of 100.000000 
2019-09-10 13:15:29,653 Evaluation of this configuration took 0.000232 seconds
2019-09-10 13:15:29,654 Current incumbent [3.19274864e+01 1.17996324e-01 5.49662182e+00 1.18243871e-02
 1.00000000e+00 4.95029287e+00 1.00000000e+00 3.30343244e-05] with estimated performance 2.334932
2019-09-10 13:15:29,654 Start iteration 6 ... 
2019-09-10 13:15:29,654 Train model...
2019-09-10 13:15:32,247 Time to train the model: 2.593346
2019-09-10 13:16:00,557 Maximize acquisition function...
2019-09-10 13:16:13,754 Time to maximize the acquisition function: 13.195698
2019-09-10 13:16:13,755 Next candidate [2.34074074e+01 1.40740741e-01 5.70370370e+00 6.48151667e-02
 1.00000000e+00 5.16666667e+00 1.61111111e+00 5.05000000e-04]
2019-09-10 13:16:13,755 gpu device = cuda:0
2019-09-10 13:16:13,756 config = {'batch_size': 32, 'drop_path_prob': 0.0562962962962963, 'grad_clip_value': 8, 'initial_lr': 2.1089963753414107e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.0023283172746057e-05}
2019-09-10 13:16:13,810 param size = 0.255930MB
2019-09-10 13:16:13,812 epoch 0 lr 1.054498e-06
2019-09-10 13:16:13,983 train 000 2.394835e+00 12.500000 40.625000
2019-09-10 13:16:21,915 train 050 2.351037e+00 7.352941 48.927696
2019-09-10 13:16:29,833 train 100 2.352515e+00 7.240099 47.663985
2019-09-10 13:16:37,749 train 150 2.353002e+00 7.036424 47.309603
2019-09-10 13:16:45,666 train 200 2.354336e+00 6.941853 46.906095
2019-09-10 13:16:53,795 train 250 2.352687e+00 6.990787 47.254731
2019-09-10 13:17:01,737 train 300 2.351431e+00 7.080565 47.601744
2019-09-10 13:17:09,683 train 350 2.350544e+00 7.082443 47.894409
2019-09-10 13:17:17,630 train 400 2.349876e+00 7.072163 48.032263
2019-09-10 13:17:25,538 train 450 2.349292e+00 7.112666 48.163803
2019-09-10 13:17:33,444 train 500 2.349061e+00 7.082710 48.200474
2019-09-10 13:17:41,350 train 550 2.348596e+00 7.078040 48.153925
2019-09-10 13:17:49,252 train 600 2.348142e+00 7.123544 48.102121
2019-09-10 13:17:57,155 train 650 2.348452e+00 7.080453 48.079877
2019-09-10 13:18:05,056 train 700 2.348241e+00 7.056883 48.105385
2019-09-10 13:18:12,801 train_acc 7.093750
2019-09-10 13:18:12,833 valid 000 2.379672e+00 6.250000 32.812500
2019-09-10 13:18:14,377 valid 050 2.345509e+00 7.628676 48.069853
2019-09-10 13:18:15,921 valid 100 2.346884e+00 7.286510 48.035272
2019-09-10 13:18:17,461 valid 150 2.344257e+00 7.408940 48.468543
2019-09-10 13:18:18,591 valid_acc 7.350000
2019-09-10 13:18:18,591 epoch 1 lr 0.000000e+00
2019-09-10 13:18:18,758 train 000 2.355103e+00 3.125000 50.000000
2019-09-10 13:18:26,904 train 050 2.348323e+00 7.996324 49.571078
2019-09-10 13:18:35,052 train 100 2.348907e+00 7.936262 49.056312
2019-09-10 13:18:43,243 train 150 2.349190e+00 7.853891 48.603063
2019-09-10 13:18:51,455 train 200 2.349214e+00 7.804726 48.569652
2019-09-10 13:18:59,667 train 250 2.348869e+00 7.818725 48.437500
2019-09-10 13:19:07,880 train 300 2.348519e+00 7.926703 48.385590
2019-09-10 13:19:16,089 train 350 2.348174e+00 7.990563 48.299501
2019-09-10 13:19:24,297 train 400 2.347584e+00 8.050187 48.433603
2019-09-10 13:19:32,507 train 450 2.347843e+00 8.034229 48.496397
2019-09-10 13:19:40,718 train 500 2.348238e+00 7.971557 48.521707
2019-09-10 13:19:48,928 train 550 2.348465e+00 7.965631 48.471529
2019-09-10 13:19:57,132 train 600 2.348143e+00 8.012687 48.507696
2019-09-10 13:20:05,342 train 650 2.347909e+00 8.011713 48.571909
2019-09-10 13:20:13,553 train 700 2.347889e+00 8.001961 48.609130
2019-09-10 13:20:21,595 train_acc 7.954167
2019-09-10 13:20:21,630 valid 000 2.346821e+00 6.250000 45.312500
2019-09-10 13:20:23,185 valid 050 2.327696e+00 8.578431 48.498775
2019-09-10 13:20:24,743 valid 100 2.333020e+00 8.245668 47.663985
2019-09-10 13:20:26,303 valid 150 2.332331e+00 8.278146 47.651076
2019-09-10 13:20:27,442 valid_acc 8.125000
2019-09-10 13:20:27,445 Configuration achieved a performance of 2.333142 
2019-09-10 13:20:27,445 Evaluation of this configuration took 253.689917 seconds
2019-09-10 13:20:27,446 Current incumbent [2.34074074e+01 1.40740741e-01 5.70370370e+00 6.48151667e-02
 1.00000000e+00 5.16666667e+00 2.00000000e+00 5.05000000e-04] with estimated performance 2.333142
2019-09-10 13:20:27,446 Start iteration 7 ... 
2019-09-10 13:20:27,446 Train model...
2019-09-10 13:20:29,983 Time to train the model: 2.536991
2019-09-10 13:20:58,254 Maximize acquisition function...
2019-09-10 13:21:11,038 Time to maximize the acquisition function: 12.782765
2019-09-10 13:21:11,039 Next candidate [2.51851852e+01 2.00000000e-01 5.11111111e+00 5.00005000e-02
 1.51851852e+00 4.05555556e+00 2.05555556e+00 5.05000000e-04]
2019-09-10 13:21:11,040 Configuration achieved a performance of 100.000000 
2019-09-10 13:21:11,040 Evaluation of this configuration took 0.000236 seconds
2019-09-10 13:21:11,040 Current incumbent [2.34074074e+01 1.40740741e-01 5.70370370e+00 6.48151667e-02
 1.00000000e+00 5.16666667e+00 2.00000000e+00 5.05000000e-04] with estimated performance 2.333142
2019-09-10 13:21:11,040 Start iteration 8 ... 
2019-09-10 13:21:11,040 Train model...
2019-09-10 13:21:13,585 Time to train the model: 2.544885
2019-09-10 13:21:41,613 Maximize acquisition function...
2019-09-10 13:21:54,729 Time to maximize the acquisition function: 13.111000
2019-09-10 13:21:54,731 Next candidate [2.57777778e+01 2.00000000e-01 7.77777778e+00 1.66675000e-02
 1.66666667e+00 5.50000000e+00 1.94444444e+00 6.88333333e-04]
2019-09-10 13:21:54,731 Configuration achieved a performance of 100.000000 
2019-09-10 13:21:54,731 Evaluation of this configuration took 0.000239 seconds
2019-09-10 13:21:54,731 Current incumbent [2.34074074e+01 1.40740741e-01 5.70370370e+00 6.48151667e-02
 1.00000000e+00 5.16666667e+00 2.00000000e+00 5.05000000e-04] with estimated performance 2.333142
2019-09-10 13:21:54,731 Start iteration 9 ... 
2019-09-10 13:21:54,732 Train model...
2019-09-10 13:21:57,288 Time to train the model: 2.556035
2019-09-10 13:22:25,520 Maximize acquisition function...
2019-09-10 13:22:38,609 Time to maximize the acquisition function: 13.088329
2019-09-10 13:22:38,612 Next candidate [2.34074074e+01 6.66666667e-02 6.14814815e+00 1.66675000e-02
 1.96296296e+00 3.72222222e+00 1.50000000e+00 8.35000000e-04]
2019-09-10 13:22:38,612 Configuration achieved a performance of 100.000000 
2019-09-10 13:22:38,613 Evaluation of this configuration took 0.000233 seconds
2019-09-10 13:22:38,613 Current incumbent [2.34074074e+01 1.40740741e-01 5.70370370e+00 6.48151667e-02
 1.00000000e+00 5.16666667e+00 2.00000000e+00 5.05000000e-04] with estimated performance 2.333142
2019-09-10 13:22:38,613 Start iteration 10 ... 
2019-09-10 13:22:38,613 Train model...
2019-09-10 13:22:41,153 Time to train the model: 2.540400
2019-09-10 13:23:09,639 Maximize acquisition function...
2019-09-10 13:23:23,190 Time to maximize the acquisition function: 13.549233
2019-09-10 13:23:23,197 Next candidate [2.63703704e+01 7.16049383e-02 6.00000000e+00 7.22225000e-02
 9.25925926e-01 5.50000000e+00 1.50000000e+00 5.05000000e-04]
2019-09-10 13:23:23,198 gpu device = cuda:0
2019-09-10 13:23:23,198 config = {'batch_size': 32, 'drop_path_prob': 0.028641975308641984, 'grad_clip_value': 8, 'initial_lr': 2.2967435213927177e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.0023283172746057e-05}
2019-09-10 13:23:23,288 param size = 0.255930MB
2019-09-10 13:23:23,290 epoch 0 lr 1.148372e-06
2019-09-10 13:23:23,461 train 000 2.394835e+00 12.500000 40.625000
2019-09-10 13:23:31,386 train 050 2.351024e+00 7.352941 48.958333
2019-09-10 13:23:39,291 train 100 2.352485e+00 7.240099 47.663985
2019-09-10 13:23:47,197 train 150 2.352962e+00 7.036424 47.268212
2019-09-10 13:23:55,101 train 200 2.354274e+00 6.941853 46.875000
2019-09-10 13:24:03,006 train 250 2.352617e+00 6.990787 47.242281
2019-09-10 13:24:10,937 train 300 2.351347e+00 7.080565 47.606935
2019-09-10 13:24:18,863 train 350 2.350440e+00 7.086895 47.894409
2019-09-10 13:24:26,778 train 400 2.349759e+00 7.076060 48.036160
2019-09-10 13:24:34,680 train 450 2.349157e+00 7.112666 48.177661
2019-09-10 13:24:42,579 train 500 2.348911e+00 7.079591 48.228543
2019-09-10 13:24:50,478 train 550 2.348433e+00 7.072368 48.179446
2019-09-10 13:24:58,373 train 600 2.347965e+00 7.120944 48.120320
2019-09-10 13:25:06,269 train 650 2.348260e+00 7.078053 48.089478
2019-09-10 13:25:14,163 train 700 2.348033e+00 7.056883 48.127675
2019-09-10 13:25:21,933 train_acc 7.097917
2019-09-10 13:25:21,966 valid 000 2.379201e+00 6.250000 32.812500
2019-09-10 13:25:23,511 valid 050 2.345081e+00 7.781863 47.886029
2019-09-10 13:25:25,058 valid 100 2.346387e+00 7.332921 47.911510
2019-09-10 13:25:26,604 valid 150 2.343775e+00 7.471026 48.447848
2019-09-10 13:25:27,737 valid_acc 7.416667
2019-09-10 13:25:27,737 epoch 1 lr 0.000000e+00
2019-09-10 13:25:27,903 train 000 2.334303e+00 9.375000 48.437500
2019-09-10 13:25:36,048 train 050 2.343025e+00 7.904412 49.111520
2019-09-10 13:25:44,195 train 100 2.342726e+00 7.642327 49.334777
2019-09-10 13:25:53,195 train 150 2.345125e+00 7.522765 48.313328
2019-09-10 13:26:01,340 train 200 2.345527e+00 7.470460 48.289801
2019-09-10 13:26:09,482 train 250 2.345440e+00 7.526145 48.312998
2019-09-10 13:26:17,630 train 300 2.345189e+00 7.454319 48.328488
2019-09-10 13:26:25,775 train 350 2.344922e+00 7.483084 48.352920
2019-09-10 13:26:33,921 train 400 2.344854e+00 7.539744 48.476465
2019-09-10 13:26:42,064 train 450 2.345307e+00 7.528409 48.503326
2019-09-10 13:26:50,210 train 500 2.345440e+00 7.472555 48.499875
2019-09-10 13:26:58,357 train 550 2.345967e+00 7.418330 48.417650
2019-09-10 13:27:06,499 train 600 2.345991e+00 7.414725 48.320507
2019-09-10 13:27:14,643 train 650 2.345814e+00 7.411674 48.377496
2019-09-10 13:27:22,784 train 700 2.345882e+00 7.395685 48.386234
2019-09-10 13:27:30,764 train_acc 7.370833
2019-09-10 13:27:30,798 valid 000 2.353284e+00 6.250000 42.187500
2019-09-10 13:27:32,350 valid 050 2.332449e+00 8.149510 48.835784
2019-09-10 13:27:33,924 valid 100 2.336841e+00 7.827970 48.143564
2019-09-10 13:27:35,501 valid 150 2.336271e+00 7.781457 48.127070
2019-09-10 13:27:36,656 valid_acc 7.666667
2019-09-10 13:27:36,658 Configuration achieved a performance of 2.337267 
2019-09-10 13:27:36,658 Evaluation of this configuration took 253.460398 seconds
2019-09-10 13:27:36,658 Current incumbent [2.34074074e+01 1.40740741e-01 5.70370370e+00 6.48151667e-02
 1.00000000e+00 5.16666667e+00 2.00000000e+00 5.05000000e-04] with estimated performance 2.333142
2019-09-10 13:27:36,659 Start iteration 11 ... 
2019-09-10 13:27:36,659 Train model...
2019-09-10 13:27:39,153 Time to train the model: 2.494200
2019-09-10 13:28:07,643 Maximize acquisition function...
2019-09-10 13:28:20,726 Time to maximize the acquisition function: 13.082141
2019-09-10 13:28:20,728 Next candidate [2.99259259e+01 2.00000000e-01 6.44444444e+00 5.00005000e-02
 1.51851852e+00 3.72222222e+00 5.00000000e-01 5.05000000e-04]
2019-09-10 13:28:20,728 Configuration achieved a performance of 100.000000 
2019-09-10 13:28:20,728 Evaluation of this configuration took 0.000241 seconds
2019-09-10 13:28:20,729 Current incumbent [2.34074074e+01 1.40740741e-01 5.70370370e+00 6.48151667e-02
 1.00000000e+00 5.16666667e+00 2.00000000e+00 5.05000000e-04] with estimated performance 2.333142
2019-09-10 13:28:20,729 Start iteration 12 ... 
2019-09-10 13:28:20,729 Train model...
2019-09-10 13:28:23,221 Time to train the model: 2.492077
2019-09-10 13:28:51,648 Maximize acquisition function...
2019-09-10 13:29:06,348 Time to maximize the acquisition function: 14.698305
2019-09-10 13:29:06,349 Next candidate [2.93333333e+01 1.70370370e-01 4.66666667e+00 9.44445000e-02
 1.59259259e+00 3.16666667e+00 2.50000000e+00 5.05000000e-04]
2019-09-10 13:29:06,350 Configuration achieved a performance of 100.000000 
2019-09-10 13:29:06,350 Evaluation of this configuration took 0.000235 seconds
2019-09-10 13:29:06,350 Current incumbent [2.34074074e+01 1.40740741e-01 5.70370370e+00 6.48151667e-02
 1.00000000e+00 5.16666667e+00 2.00000000e+00 5.05000000e-04] with estimated performance 2.333142
2019-09-10 13:29:06,350 Start iteration 13 ... 
2019-09-10 13:29:06,350 Train model...
2019-09-10 13:29:08,854 Time to train the model: 2.503808
2019-09-10 13:29:37,320 Maximize acquisition function...
2019-09-10 13:29:50,360 Time to maximize the acquisition function: 13.037292
2019-09-10 13:29:50,363 Next candidate [1.68888889e+01 6.66666667e-02 7.33333333e+00 8.33335000e-02
 1.00000000e+00 5.50000000e+00 1.50000000e+00 1.75000000e-04]
2019-09-10 13:29:50,363 gpu device = cuda:0
2019-09-10 13:29:50,363 config = {'batch_size': 32, 'drop_path_prob': 0.026666666666666672, 'grad_clip_value': 8, 'initial_lr': 2.6101622241115896e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.0008062296110608e-05}
2019-09-10 13:29:50,414 param size = 0.255930MB
2019-09-10 13:29:50,416 epoch 0 lr 1.305081e-06
2019-09-10 13:29:50,587 train 000 2.394835e+00 12.500000 40.625000
2019-09-10 13:29:58,499 train 050 2.351002e+00 7.383578 48.988971
2019-09-10 13:30:06,397 train 100 2.352437e+00 7.271040 47.633045
2019-09-10 13:30:14,296 train 150 2.352884e+00 7.046772 47.268212
2019-09-10 13:30:22,197 train 200 2.354164e+00 6.949627 46.890547
2019-09-10 13:30:30,093 train 250 2.352488e+00 7.003237 47.236056
2019-09-10 13:30:37,989 train 300 2.351192e+00 7.085756 47.601744
2019-09-10 13:30:45,888 train 350 2.350263e+00 7.095798 47.876603
2019-09-10 13:30:53,783 train 400 2.349557e+00 7.076060 48.012781
2019-09-10 13:31:01,677 train 450 2.348928e+00 7.109202 48.156874
2019-09-10 13:31:09,567 train 500 2.348654e+00 7.063997 48.222305
2019-09-10 13:31:17,495 train 550 2.348157e+00 7.066697 48.176611
2019-09-10 13:31:25,416 train 600 2.347672e+00 7.120944 48.122920
2019-09-10 13:31:33,351 train 650 2.347934e+00 7.080453 48.099078
2019-09-10 13:31:41,244 train 700 2.347685e+00 7.070257 48.147735
2019-09-10 13:31:48,986 train_acc 7.108333
2019-09-10 13:31:49,020 valid 000 2.377456e+00 6.250000 32.812500
2019-09-10 13:31:50,562 valid 050 2.344309e+00 7.720588 47.794118
2019-09-10 13:31:52,103 valid 100 2.345588e+00 7.348391 47.896040
2019-09-10 13:31:53,644 valid 150 2.343009e+00 7.460679 48.489238
2019-09-10 13:31:54,771 valid_acc 7.416667
2019-09-10 13:31:54,771 epoch 1 lr 0.000000e+00
2019-09-10 13:31:54,938 train 000 2.332457e+00 9.375000 50.000000
2019-09-10 13:32:03,081 train 050 2.342139e+00 7.873775 49.295343
2019-09-10 13:32:11,225 train 100 2.341881e+00 7.735149 49.303837
2019-09-10 13:32:19,368 train 150 2.344087e+00 7.553808 48.323675
2019-09-10 13:32:27,518 train 200 2.344482e+00 7.517102 48.351990
2019-09-10 13:32:35,713 train 250 2.344434e+00 7.551046 48.468625
2019-09-10 13:32:43,909 train 300 2.344092e+00 7.490656 48.530939
2019-09-10 13:32:52,101 train 350 2.343773e+00 7.518697 48.575499
2019-09-10 13:33:00,299 train 400 2.343714e+00 7.567020 48.612843
2019-09-10 13:33:08,495 train 450 2.344157e+00 7.563054 48.662694
2019-09-10 13:33:16,688 train 500 2.344356e+00 7.513099 48.627745
2019-09-10 13:33:24,879 train 550 2.344887e+00 7.458031 48.511230
2019-09-10 13:33:33,074 train 600 2.344949e+00 7.451123 48.414101
2019-09-10 13:33:41,265 train 650 2.344775e+00 7.447677 48.475902
2019-09-10 13:33:49,458 train 700 2.344818e+00 7.440264 48.504369
2019-09-10 13:33:57,486 train_acc 7.412500
2019-09-10 13:33:57,520 valid 000 2.352194e+00 6.250000 42.187500
2019-09-10 13:33:59,075 valid 050 2.332374e+00 8.149510 48.927696
2019-09-10 13:34:00,629 valid 100 2.336691e+00 7.874381 48.267327
2019-09-10 13:34:02,184 valid 150 2.336113e+00 7.853891 48.220199
2019-09-10 13:34:03,320 valid_acc 7.691667
2019-09-10 13:34:03,321 Configuration achieved a performance of 2.337101 
2019-09-10 13:34:03,322 Evaluation of this configuration took 252.958417 seconds
2019-09-10 13:34:03,322 Current incumbent [2.34074074e+01 1.40740741e-01 5.70370370e+00 6.48151667e-02
 1.00000000e+00 5.16666667e+00 2.00000000e+00 5.05000000e-04] with estimated performance 2.333142
2019-09-10 13:34:03,322 Start iteration 14 ... 
2019-09-10 13:34:03,322 Train model...
2019-09-10 13:34:05,796 Time to train the model: 2.474218
2019-09-10 13:34:34,483 Maximize acquisition function...
2019-09-10 13:34:47,828 Time to maximize the acquisition function: 13.342177
2019-09-10 13:34:47,828 Next candidate [2.40000000e+01 7.40740741e-03 4.51851852e+00 8.33335000e-02
 1.00000000e+00 4.38888889e+00 2.50000000e+00 2.11666667e-04]
2019-09-10 13:34:47,829 gpu device = cuda:0
2019-09-10 13:34:47,829 config = {'batch_size': 32, 'drop_path_prob': 0.0029629629629629676, 'grad_clip_value': 8, 'initial_lr': 2.6101622241115896e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.0009752362566264e-05}
2019-09-10 13:34:47,882 param size = 0.255930MB
2019-09-10 13:34:47,884 epoch 0 lr 1.305081e-06
2019-09-10 13:34:48,054 train 000 2.394835e+00 12.500000 40.625000
2019-09-10 13:34:55,966 train 050 2.351002e+00 7.383578 48.988971
2019-09-10 13:35:03,869 train 100 2.352437e+00 7.271040 47.679455
2019-09-10 13:35:11,778 train 150 2.352881e+00 7.046772 47.288907
2019-09-10 13:35:19,685 train 200 2.354162e+00 6.941853 46.890547
2019-09-10 13:35:27,585 train 250 2.352483e+00 6.990787 47.236056
2019-09-10 13:35:35,490 train 300 2.351191e+00 7.085756 47.601744
2019-09-10 13:35:43,389 train 350 2.350263e+00 7.100249 47.881054
2019-09-10 13:35:51,287 train 400 2.349556e+00 7.091646 48.024470
2019-09-10 13:35:59,187 train 450 2.348928e+00 7.123060 48.170732
2019-09-10 13:36:07,103 train 500 2.348656e+00 7.092066 48.234780
2019-09-10 13:36:15,062 train 550 2.348156e+00 7.095054 48.204968
2019-09-10 13:36:23,022 train 600 2.347670e+00 7.146943 48.133319
2019-09-10 13:36:30,979 train 650 2.347937e+00 7.109255 48.103879
2019-09-10 13:36:38,933 train 700 2.347689e+00 7.090317 48.149964
2019-09-10 13:36:46,730 train_acc 7.131250
2019-09-10 13:36:46,765 valid 000 2.376992e+00 6.250000 32.812500
2019-09-10 13:36:48,321 valid 050 2.344306e+00 7.751225 47.794118
2019-09-10 13:36:49,879 valid 100 2.345618e+00 7.379332 48.004332
2019-09-10 13:36:51,434 valid 150 2.343066e+00 7.533113 48.582368
2019-09-10 13:36:52,572 valid_acc 7.475000
2019-09-10 13:36:52,573 epoch 1 lr 0.000000e+00
2019-09-10 13:36:52,739 train 000 2.335348e+00 9.375000 43.750000
2019-09-10 13:37:00,943 train 050 2.342974e+00 7.536765 49.172794
2019-09-10 13:37:09,148 train 100 2.341918e+00 7.224629 49.164604
2019-09-10 13:37:17,353 train 150 2.344919e+00 7.026076 48.075331
2019-09-10 13:37:25,554 train 200 2.344778e+00 6.887438 48.344216
2019-09-10 13:37:33,757 train 250 2.344438e+00 6.922311 48.288098
2019-09-10 13:37:41,964 train 300 2.344281e+00 6.909261 48.432309
2019-09-10 13:37:50,166 train 350 2.343780e+00 6.971154 48.482016
2019-09-10 13:37:58,368 train 400 2.343762e+00 7.029302 48.340087
2019-09-10 13:38:06,574 train 450 2.344115e+00 7.039911 48.406319
2019-09-10 13:38:14,777 train 500 2.344277e+00 7.017216 48.453094
2019-09-10 13:38:22,987 train 550 2.344814e+00 6.981624 48.341084
2019-09-10 13:38:31,211 train 600 2.344774e+00 7.029950 48.133319
2019-09-10 13:38:39,455 train 650 2.344402e+00 7.039651 48.130280
2019-09-10 13:38:47,659 train 700 2.344320e+00 7.050196 48.141049
2019-09-10 13:38:55,693 train_acc 7.027083
2019-09-10 13:38:55,726 valid 000 2.363688e+00 6.250000 42.187500
2019-09-10 13:38:57,282 valid 050 2.338906e+00 7.659314 49.142157
2019-09-10 13:38:58,840 valid 100 2.342076e+00 7.673267 48.545792
2019-09-10 13:39:00,396 valid 150 2.341638e+00 7.688328 48.613411
2019-09-10 13:39:01,536 valid_acc 7.616667
2019-09-10 13:39:01,537 Configuration achieved a performance of 2.342612 
2019-09-10 13:39:01,537 Evaluation of this configuration took 253.708454 seconds
2019-09-10 13:39:01,537 Current incumbent [2.34074074e+01 1.40740741e-01 5.70370370e+00 6.48151667e-02
 1.00000000e+00 5.16666667e+00 2.00000000e+00 5.05000000e-04] with estimated performance 2.333142
2019-09-10 13:39:01,538 Start iteration 15 ... 
2019-09-10 13:39:01,538 Train model...
2019-09-10 13:39:04,078 Time to train the model: 2.539980
2019-09-10 13:39:32,545 Maximize acquisition function...
2019-09-10 13:39:46,246 Time to maximize the acquisition function: 13.698857
2019-09-10 13:39:46,247 Next candidate [2.40000000e+01 2.22222222e-02 6.14814815e+00 5.74078333e-02
 1.00000000e+00 3.50000000e+00 3.88888889e-01 1.75000000e-04]
2019-09-10 13:39:46,248 gpu device = cuda:0
2019-09-10 13:39:46,248 config = {'batch_size': 32, 'drop_path_prob': 0.008888888888888894, 'grad_clip_value': 8, 'initial_lr': 1.936596607228515e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'adam', 'weight_decay': 1.0008062296110608e-05}
2019-09-10 13:39:46,302 param size = 0.255930MB
2019-09-10 13:39:46,304 epoch 0 lr 9.682983e-07
2019-09-10 13:39:46,500 train 000 2.394835e+00 12.500000 40.625000
2019-09-10 13:39:55,134 train 050 2.349817e+00 7.444853 49.172794
2019-09-10 13:40:03,760 train 100 2.350080e+00 7.348391 48.097153
2019-09-10 13:40:12,387 train 150 2.349305e+00 7.284768 48.023593
2019-09-10 13:40:21,014 train 200 2.349322e+00 7.237251 47.761194
2019-09-10 13:40:29,642 train 250 2.346423e+00 7.370518 48.281873
2019-09-10 13:40:38,271 train 300 2.343954e+00 7.532184 48.728198
2019-09-10 13:40:46,898 train 350 2.341921e+00 7.683405 49.091880
2019-09-10 13:40:55,523 train 400 2.340145e+00 7.824190 49.345387
2019-09-10 13:41:04,150 train 450 2.338445e+00 7.964939 49.587722
2019-09-10 13:41:12,775 train 500 2.336981e+00 8.049526 49.809755
2019-09-10 13:41:21,438 train 550 2.335371e+00 8.181148 49.937613
2019-09-10 13:41:30,113 train 600 2.333828e+00 8.376664 50.044197
2019-09-10 13:41:38,791 train 650 2.332923e+00 8.479743 50.129608
2019-09-10 13:41:47,465 train 700 2.331649e+00 8.594864 50.285307
2019-09-10 13:41:55,966 train_acc 8.800000
2019-09-10 13:41:56,000 valid 000 2.341024e+00 6.250000 37.500000
2019-09-10 13:41:57,557 valid 050 2.310685e+00 11.825980 51.776961
2019-09-10 13:41:59,114 valid 100 2.311505e+00 11.417079 51.856436
2019-09-10 13:42:00,671 valid 150 2.308643e+00 11.548013 52.524834
2019-09-10 13:42:01,810 valid_acc 11.600000
2019-09-10 13:42:01,811 epoch 1 lr 0.000000e+00
2019-09-10 13:42:01,992 train 000 2.311080e+00 14.062500 53.125000
2019-09-10 13:42:10,912 train 050 2.308932e+00 11.488971 52.787990
2019-09-10 13:42:19,829 train 100 2.308834e+00 11.030322 52.970297
2019-09-10 13:42:28,746 train 150 2.312213e+00 10.844371 51.821192
2019-09-10 13:42:37,664 train 200 2.312138e+00 10.719838 52.052239
2019-09-10 13:42:46,583 train 250 2.311963e+00 10.682271 51.973357
2019-09-10 13:42:55,499 train 300 2.311847e+00 10.714286 52.123131
2019-09-10 13:43:04,417 train 350 2.311414e+00 10.737179 52.132301
2019-09-10 13:43:13,335 train 400 2.311407e+00 10.855673 52.119701
2019-09-10 13:43:22,252 train 450 2.311665e+00 10.875139 52.151469
2019-09-10 13:43:31,168 train 500 2.311903e+00 10.787799 52.204965
2019-09-10 13:43:40,079 train 550 2.312443e+00 10.764519 52.123979
2019-09-10 13:43:48,993 train 600 2.312275e+00 10.755512 52.072067
2019-09-10 13:43:57,911 train 650 2.311969e+00 10.822293 52.116935
2019-09-10 13:44:06,831 train 700 2.311945e+00 10.843884 52.177693
2019-09-10 13:44:15,569 train_acc 10.797917
2019-09-10 13:44:15,603 valid 000 2.334191e+00 7.812500 54.687500
2019-09-10 13:44:17,160 valid 050 2.306125e+00 11.335784 53.553922
2019-09-10 13:44:18,716 valid 100 2.308157e+00 11.927599 52.645421
2019-09-10 13:44:20,270 valid 150 2.307959e+00 11.651490 52.700745
2019-09-10 13:44:21,409 valid_acc 11.491667
2019-09-10 13:44:21,410 Configuration achieved a performance of 2.308671 
2019-09-10 13:44:21,410 Evaluation of this configuration took 275.162591 seconds
2019-09-10 13:44:21,410 Current incumbent [2.40000000e+01 2.22222222e-02 6.14814815e+00 5.74078333e-02
 1.00000000e+00 3.50000000e+00 0.00000000e+00 1.75000000e-04] with estimated performance 2.308671
2019-09-10 13:44:21,410 Start iteration 16 ... 
2019-09-10 13:44:21,411 Train model...
2019-09-10 13:44:23,932 Time to train the model: 2.521840
2019-09-10 13:44:52,520 Maximize acquisition function...
2019-09-10 13:45:05,581 Time to maximize the acquisition function: 13.059412
2019-09-10 13:45:05,583 Next candidate [2.40000000e+01 9.62962963e-02 6.59259259e+00 4.25931667e-02
 1.00000000e+00 4.38888889e+00 1.94444444e+00 6.15000000e-04]
2019-09-10 13:45:05,583 gpu device = cuda:0
2019-09-10 13:45:05,583 config = {'batch_size': 32, 'drop_path_prob': 0.03851851851851853, 'grad_clip_value': 8, 'initial_lr': 1.632923478044601e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.0028361940741568e-05}
2019-09-10 13:45:05,635 param size = 0.255930MB
2019-09-10 13:45:05,637 epoch 0 lr 8.164617e-07
2019-09-10 13:45:05,810 train 000 2.394835e+00 12.500000 40.625000
2019-09-10 13:45:13,751 train 050 2.351074e+00 7.352941 48.866422
2019-09-10 13:45:21,677 train 100 2.352590e+00 7.240099 47.633045
2019-09-10 13:45:29,600 train 150 2.353112e+00 7.026076 47.257864
2019-09-10 13:45:37,539 train 200 2.354493e+00 6.918532 46.875000
2019-09-10 13:45:45,496 train 250 2.352868e+00 6.965886 47.229831
2019-09-10 13:45:53,479 train 300 2.351654e+00 7.059801 47.580980
2019-09-10 13:46:01,363 train 350 2.350809e+00 7.055734 47.858796
2019-09-10 13:46:09,246 train 400 2.350178e+00 7.052681 48.008884
2019-09-10 13:46:17,132 train 450 2.349638e+00 7.088415 48.125693
2019-09-10 13:46:25,043 train 500 2.349444e+00 7.070235 48.163049
2019-09-10 13:46:32,982 train 550 2.349016e+00 7.063861 48.131239
2019-09-10 13:46:40,919 train 600 2.348594e+00 7.102745 48.078723
2019-09-10 13:46:48,853 train 650 2.348951e+00 7.058852 48.065476
2019-09-10 13:46:56,795 train 700 2.348774e+00 7.034593 48.078638
2019-09-10 13:47:04,569 train_acc 7.070833
2019-09-10 13:47:04,603 valid 000 2.381063e+00 6.250000 32.812500
2019-09-10 13:47:06,161 valid 050 2.346633e+00 7.567402 47.916667
2019-09-10 13:47:07,720 valid 100 2.348095e+00 7.224629 47.942450
2019-09-10 13:47:09,280 valid 150 2.345464e+00 7.357202 48.447848
2019-09-10 13:47:10,422 valid_acc 7.316667
2019-09-10 13:47:10,422 epoch 1 lr 0.000000e+00
2019-09-10 13:47:10,587 train 000 2.340631e+00 9.375000 46.875000
2019-09-10 13:47:18,756 train 050 2.346486e+00 7.996324 48.743873
2019-09-10 13:47:26,926 train 100 2.346070e+00 7.549505 48.932550
2019-09-10 13:47:35,094 train 150 2.347752e+00 7.408940 48.220199
2019-09-10 13:47:43,263 train 200 2.348213e+00 7.423818 48.087687
2019-09-10 13:47:51,429 train 250 2.347990e+00 7.470120 48.157371
2019-09-10 13:47:59,594 train 300 2.347736e+00 7.449128 48.151993
2019-09-10 13:48:07,795 train 350 2.347461e+00 7.509793 48.094729
2019-09-10 13:48:16,055 train 400 2.347014e+00 7.563123 48.266054
2019-09-10 13:48:25,326 train 450 2.347312e+00 7.569983 48.326635
2019-09-10 13:48:34,957 train 500 2.347529e+00 7.506861 48.375125
2019-09-10 13:48:43,219 train 550 2.347920e+00 7.472210 48.275862
2019-09-10 13:48:56,714 train 600 2.347885e+00 7.482321 48.284110
2019-09-10 13:49:05,702 train 650 2.347619e+00 7.502880 48.360695
2019-09-10 13:49:13,910 train 700 2.347713e+00 7.518277 48.406295
2019-09-10 13:49:24,331 train_acc 7.477083
2019-09-10 13:49:26,413 valid 000 2.351132e+00 6.250000 42.187500
2019-09-10 13:49:27,964 valid 050 2.331537e+00 8.302696 48.713235
2019-09-10 13:49:29,522 valid 100 2.336288e+00 7.766089 47.926980
2019-09-10 13:49:31,085 valid 150 2.335691e+00 7.802152 47.868377
2019-09-10 13:49:32,229 valid_acc 7.608333
2019-09-10 13:49:32,231 Configuration achieved a performance of 2.336637 
2019-09-10 13:49:32,231 Evaluation of this configuration took 266.647713 seconds
2019-09-10 13:49:32,231 Current incumbent [2.40000000e+01 2.22222222e-02 6.14814815e+00 5.74078333e-02
 1.00000000e+00 3.50000000e+00 0.00000000e+00 1.75000000e-04] with estimated performance 2.308671
2019-09-10 13:49:32,231 Start iteration 17 ... 
2019-09-10 13:49:32,231 Train model...
2019-09-10 13:49:34,675 Time to train the model: 2.443331
2019-09-10 13:50:02,137 Maximize acquisition function...
2019-09-10 13:50:15,296 Time to maximize the acquisition function: 13.157720
2019-09-10 13:50:15,297 Next candidate [1.86666667e+01 1.25925926e-01 6.00000000e+00 6.11115000e-02
 1.00000000e+00 4.16666667e+00 1.61111111e+00 6.88333333e-04]
2019-09-10 13:50:15,298 gpu device = cuda:0
2019-09-10 13:50:15,298 config = {'batch_size': 32, 'drop_path_prob': 0.05037037037037038, 'grad_clip_value': 8, 'initial_lr': 2.020958986507003e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.0031749215656294e-05}
2019-09-10 13:50:15,347 param size = 0.255930MB
2019-09-10 13:50:15,349 epoch 0 lr 1.010479e-06
2019-09-10 13:50:15,519 train 000 2.394835e+00 12.500000 40.625000
2019-09-10 13:50:23,384 train 050 2.351045e+00 7.352941 48.866422
2019-09-10 13:50:31,275 train 100 2.352530e+00 7.240099 47.617574
2019-09-10 13:50:39,203 train 150 2.353025e+00 7.046772 47.257864
2019-09-10 13:50:47,091 train 200 2.354369e+00 6.941853 46.867226
2019-09-10 13:50:54,979 train 250 2.352724e+00 6.984562 47.229831
2019-09-10 13:51:02,861 train 300 2.351476e+00 7.059801 47.580980
2019-09-10 13:51:10,744 train 350 2.350599e+00 7.069088 47.881054
2019-09-10 13:51:18,622 train 400 2.349934e+00 7.064370 48.028367
2019-09-10 13:51:26,499 train 450 2.349359e+00 7.102273 48.146480
2019-09-10 13:51:34,412 train 500 2.349134e+00 7.079591 48.184880
2019-09-10 13:51:42,350 train 550 2.348677e+00 7.069533 48.153925
2019-09-10 13:51:50,289 train 600 2.348225e+00 7.113145 48.096922
2019-09-10 13:51:58,228 train 650 2.348543e+00 7.068452 48.082277
2019-09-10 13:52:06,164 train 700 2.348338e+00 7.047967 48.105385
2019-09-10 13:52:13,942 train_acc 7.093750
2019-09-10 13:52:13,975 valid 000 2.379846e+00 6.250000 32.812500
2019-09-10 13:52:15,536 valid 050 2.345736e+00 7.659314 48.069853
2019-09-10 13:52:17,098 valid 100 2.347116e+00 7.286510 48.004332
2019-09-10 13:52:18,660 valid 150 2.344495e+00 7.408940 48.468543
2019-09-10 13:52:19,803 valid_acc 7.366667
2019-09-10 13:52:19,803 epoch 1 lr 0.000000e+00
2019-09-10 13:52:19,970 train 000 2.349848e+00 3.125000 48.437500
2019-09-10 13:52:28,158 train 050 2.347642e+00 8.118873 49.540441
2019-09-10 13:52:36,345 train 100 2.347636e+00 7.905322 49.334777
2019-09-10 13:52:44,532 train 150 2.348053e+00 7.947020 48.644454
2019-09-10 13:52:52,720 train 200 2.348444e+00 7.991294 48.484142
2019-09-10 13:53:00,906 train 250 2.348333e+00 7.961902 48.306773
2019-09-10 13:53:09,093 train 300 2.347776e+00 7.988995 48.307724
2019-09-10 13:53:17,276 train 350 2.347401e+00 8.057336 48.219373
2019-09-10 13:53:25,462 train 400 2.346916e+00 8.077463 48.355673
2019-09-10 13:53:33,644 train 450 2.347287e+00 8.089662 48.323171
2019-09-10 13:53:41,829 train 500 2.347539e+00 7.965319 48.418787
2019-09-10 13:53:50,011 train 550 2.347927e+00 7.937273 48.335413
2019-09-10 13:53:58,200 train 600 2.347698e+00 7.955491 48.317908
2019-09-10 13:54:06,386 train 650 2.347510e+00 7.954109 48.394297
2019-09-10 13:54:14,572 train 700 2.347587e+00 7.955153 48.455332
2019-09-10 13:54:22,590 train_acc 7.902083
2019-09-10 13:54:22,623 valid 000 2.347565e+00 4.687500 45.312500
2019-09-10 13:54:24,183 valid 050 2.328706e+00 8.517157 48.774510
2019-09-10 13:54:25,744 valid 100 2.333867e+00 8.199257 47.942450
2019-09-10 13:54:27,305 valid 150 2.333226e+00 8.174669 47.837334
2019-09-10 13:54:28,447 valid_acc 8.025000
2019-09-10 13:54:28,448 Configuration achieved a performance of 2.334097 
2019-09-10 13:54:28,449 Evaluation of this configuration took 253.150884 seconds
2019-09-10 13:54:28,449 Current incumbent [2.40000000e+01 2.22222222e-02 6.14814815e+00 5.74078333e-02
 1.00000000e+00 3.50000000e+00 0.00000000e+00 1.75000000e-04] with estimated performance 2.308671
2019-09-10 13:54:28,449 Start iteration 18 ... 
2019-09-10 13:54:28,449 Train model...
2019-09-10 13:54:30,901 Time to train the model: 2.451509
2019-09-10 13:54:59,205 Maximize acquisition function...
2019-09-10 13:55:12,630 Time to maximize the acquisition function: 13.424194
2019-09-10 13:55:12,632 Next candidate [2.51851852e+01 2.14814815e-01 5.25925926e+00 4.25931667e-02
 1.00000000e+00 4.27777778e+00 1.05555556e+00 4.68333333e-04]
2019-09-10 13:55:12,632 gpu device = cuda:0
2019-09-10 13:55:12,632 config = {'batch_size': 32, 'drop_path_prob': 0.08592592592592592, 'grad_clip_value': 8, 'initial_lr': 1.632923478044601e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'adad', 'weight_decay': 1.0021590821721555e-05}
2019-09-10 13:55:12,685 param size = 0.255930MB
2019-09-10 13:55:12,687 epoch 0 lr 8.164617e-07
2019-09-10 13:55:12,898 train 000 2.394835e+00 12.500000 40.625000
2019-09-10 13:55:22,299 train 050 2.351187e+00 7.322304 48.897059
2019-09-10 13:55:31,679 train 100 2.352855e+00 7.193688 47.617574
2019-09-10 13:55:41,062 train 150 2.353505e+00 6.932947 47.299255
2019-09-10 13:55:50,446 train 200 2.355038e+00 6.856343 46.944963
2019-09-10 13:55:59,832 train 250 2.353536e+00 6.934761 47.292082
2019-09-10 13:56:09,219 train 300 2.352464e+00 7.007890 47.606935
2019-09-10 13:56:18,603 train 350 2.351760e+00 7.011218 47.845442
2019-09-10 13:56:27,989 train 400 2.351248e+00 7.017612 47.973815
2019-09-10 13:56:37,368 train 450 2.350859e+00 7.071092 48.108370
2019-09-10 13:56:46,752 train 500 2.350819e+00 7.057759 48.156811
2019-09-10 13:56:56,132 train 550 2.350501e+00 7.026996 48.077359
2019-09-10 13:57:05,515 train 600 2.350184e+00 7.055948 48.055324
2019-09-10 13:57:14,899 train 650 2.350688e+00 7.020449 48.043875
2019-09-10 13:57:24,293 train 700 2.350654e+00 6.987785 48.034058
2019-09-10 13:57:33,536 train_acc 7.025000
2019-09-10 13:57:33,571 valid 000 2.387130e+00 4.687500 35.937500
2019-09-10 13:57:35,135 valid 050 2.350716e+00 7.475490 47.334559
2019-09-10 13:57:36,697 valid 100 2.352280e+00 7.209158 47.648515
2019-09-10 13:57:38,259 valid 150 2.349601e+00 7.367550 48.209851
2019-09-10 13:57:39,402 valid_acc 7.283333
2019-09-10 13:57:39,402 epoch 1 lr 0.000000e+00
2019-09-10 13:57:39,599 train 000 2.366999e+00 7.812500 54.687500
2019-09-10 13:57:49,285 train 050 2.354689e+00 8.026961 48.897059
2019-09-10 13:57:58,968 train 100 2.355548e+00 7.781559 48.932550
2019-09-10 13:58:08,652 train 150 2.355941e+00 7.677980 48.406457
2019-09-10 13:58:18,333 train 200 2.355824e+00 7.726990 48.546331
2019-09-10 13:58:28,022 train 250 2.355294e+00 7.681773 48.375249
2019-09-10 13:58:37,706 train 300 2.355284e+00 7.786545 48.416736
2019-09-10 13:58:47,388 train 350 2.354583e+00 7.870370 48.548789
2019-09-10 13:58:57,074 train 400 2.354324e+00 7.874844 48.636222
2019-09-10 13:59:06,753 train 450 2.354659e+00 7.906042 48.621120
2019-09-10 13:59:16,401 train 500 2.354780e+00 7.834331 48.724426
2019-09-10 13:59:26,045 train 550 2.355117e+00 7.803993 48.644510
2019-09-10 13:59:35,687 train 600 2.354714e+00 7.867097 48.749480
2019-09-10 13:59:45,334 train 650 2.354570e+00 7.846102 48.826325
2019-09-10 13:59:54,977 train 700 2.354323e+00 7.912803 48.898894
2019-09-10 14:00:04,427 train_acc 7.895833
2019-09-10 14:00:04,461 valid 000 2.350764e+00 6.250000 43.750000
2019-09-10 14:00:06,008 valid 050 2.327917e+00 9.191176 48.988971
2019-09-10 14:00:07,558 valid 100 2.334082e+00 8.586015 47.308168
2019-09-10 14:00:09,110 valid 150 2.333388e+00 8.723096 47.588990
2019-09-10 14:00:10,245 valid_acc 8.591667
2019-09-10 14:00:10,246 Configuration achieved a performance of 2.334014 
2019-09-10 14:00:10,246 Evaluation of this configuration took 297.613713 seconds
2019-09-10 14:00:10,246 Current incumbent [2.40000000e+01 2.22222222e-02 6.14814815e+00 5.74078333e-02
 1.00000000e+00 3.50000000e+00 0.00000000e+00 1.75000000e-04] with estimated performance 2.308671
2019-09-10 14:00:10,246 Start iteration 19 ... 
2019-09-10 14:00:10,246 Train model...
2019-09-10 14:00:12,702 Time to train the model: 2.455897
2019-09-10 14:00:41,303 Maximize acquisition function...
2019-09-10 14:00:54,324 Time to maximize the acquisition function: 13.018975
2019-09-10 14:00:54,325 Next candidate [2.81481481e+01 2.14814815e-01 6.88888889e+00 4.62968333e-02
 1.00000000e+00 4.61111111e+00 1.50000000e+00 5.78333333e-04]
2019-09-10 14:00:54,325 gpu device = cuda:0
2019-09-10 14:00:54,325 config = {'batch_size': 32, 'drop_path_prob': 0.08592592592592592, 'grad_clip_value': 8, 'initial_lr': 1.704057192352142e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.0026668732207798e-05}
2019-09-10 14:00:54,378 param size = 0.255930MB
2019-09-10 14:00:54,380 epoch 0 lr 8.520286e-07
2019-09-10 14:00:54,551 train 000 2.394835e+00 12.500000 40.625000
2019-09-10 14:01:02,461 train 050 2.351069e+00 7.352941 48.866422
2019-09-10 14:01:10,359 train 100 2.352580e+00 7.240099 47.648515
2019-09-10 14:01:18,262 train 150 2.353097e+00 7.036424 47.257864
2019-09-10 14:01:26,155 train 200 2.354474e+00 6.926306 46.882774
2019-09-10 14:01:34,048 train 250 2.352842e+00 6.972112 47.229831
2019-09-10 14:01:41,944 train 300 2.351622e+00 7.064992 47.575789
2019-09-10 14:01:49,839 train 350 2.350769e+00 7.060185 47.858796
2019-09-10 14:01:57,736 train 400 2.350132e+00 7.056577 48.016677
2019-09-10 14:02:05,655 train 450 2.349588e+00 7.088415 48.136086
2019-09-10 14:02:13,605 train 500 2.349389e+00 7.070235 48.169286
2019-09-10 14:02:21,557 train 550 2.348956e+00 7.066697 48.139746
2019-09-10 14:02:29,508 train 600 2.348528e+00 7.110545 48.089122
2019-09-10 14:02:37,460 train 650 2.348879e+00 7.066052 48.075077
2019-09-10 14:02:45,411 train 700 2.348697e+00 7.039051 48.092011
2019-09-10 14:02:53,205 train_acc 7.081250
2019-09-10 14:02:53,238 valid 000 2.381119e+00 6.250000 32.812500
2019-09-10 14:02:54,798 valid 050 2.346510e+00 7.628676 47.977941
2019-09-10 14:02:56,359 valid 100 2.347931e+00 7.255569 47.957921
2019-09-10 14:02:57,921 valid 150 2.345291e+00 7.377897 48.437500
2019-09-10 14:02:59,063 valid_acc 7.358333
2019-09-10 14:02:59,064 epoch 1 lr 0.000000e+00
2019-09-10 14:02:59,231 train 000 2.363631e+00 7.812500 53.125000
2019-09-10 14:03:07,440 train 050 2.350515e+00 7.965686 48.529412
2019-09-10 14:03:15,653 train 100 2.351475e+00 7.874381 48.762376
2019-09-10 14:03:23,863 train 150 2.351701e+00 7.853891 48.396109
2019-09-10 14:03:32,072 train 200 2.351506e+00 7.967973 48.421953
2019-09-10 14:03:40,286 train 250 2.350990e+00 7.912102 48.387699
2019-09-10 14:03:48,497 train 300 2.350966e+00 7.999377 48.442691
2019-09-10 14:03:56,709 train 350 2.350266e+00 8.043981 48.553241
2019-09-10 14:04:04,916 train 400 2.349964e+00 8.069670 48.706359
2019-09-10 14:04:13,126 train 450 2.350315e+00 8.082733 48.704268
2019-09-10 14:04:21,335 train 500 2.350440e+00 8.018338 48.811751
2019-09-10 14:04:29,545 train 550 2.350734e+00 7.979809 48.732418
2019-09-10 14:04:37,752 train 600 2.350298e+00 8.020487 48.811876
2019-09-10 14:04:45,961 train 650 2.350165e+00 7.985311 48.883929
2019-09-10 14:04:54,172 train 700 2.349956e+00 8.046541 48.916726
2019-09-10 14:05:02,217 train_acc 8.039583
2019-09-10 14:05:02,250 valid 000 2.347091e+00 4.687500 45.312500
2019-09-10 14:05:03,809 valid 050 2.325709e+00 9.681373 48.988971
2019-09-10 14:05:05,368 valid 100 2.331858e+00 8.972772 47.339109
2019-09-10 14:05:06,926 valid 150 2.331133e+00 9.023179 47.609685
2019-09-10 14:05:08,067 valid_acc 8.875000
2019-09-10 14:05:08,068 Configuration achieved a performance of 2.331837 
2019-09-10 14:05:08,068 Evaluation of this configuration took 253.742940 seconds
2019-09-10 14:05:08,069 Current incumbent [2.40000000e+01 2.22222222e-02 6.14814815e+00 5.74078333e-02
 1.00000000e+00 3.50000000e+00 0.00000000e+00 1.75000000e-04] with estimated performance 2.308671
2019-09-10 14:05:08,069 Return [24.0, 0.022222222222222233, 6.148148148148148, 0.057407833333333345, 1.0, 3.5, 0.0, 0.00017500000000000003] as incumbent with error 2.308671 
