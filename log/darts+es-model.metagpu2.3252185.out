Workingdir: /home/rkohli/aml-project/PC-DARTS
Started at Mon Sep  9 21:14:16 CEST 2019
Running job darts+es-model using 2 cpus per node with given JID 3252185 on queue meta_gpu-black
Experiment dir : eval-EXP-20190909-211421
09/09 09:14:22 PM Evaluate: [2.38532751e+01 2.98055545e-01 4.76668131e+00 4.41544910e-02
 9.50624085e-01 3.71819649e+00 2.20168056e+00 5.59387867e-04]
config {'batch_size': 32, 'drop_path_prob': 0.11922221785761788, 'grad_clip_value': 8, 'initial_lr': 1.662541346814963e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.0025793972617949e-05}
09/09 09:14:22 PM gpu device = cuda:0
09/09 09:14:22 PM config = {'batch_size': 32, 'drop_path_prob': 0.11922221785761788, 'grad_clip_value': 8, 'initial_lr': 1.662541346814963e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.0025793972617949e-05}
48 48 16
48 64 16
64 64 32
64 128 32
128 128 64
128 256 64
09/09 09:14:23 PM param size = 0.255930MB
Training size= 48000
09/09 09:14:23 PM epoch 0 lr 1.503783e-06
09/09 09:14:24 PM train 000 2.394835e+00 12.500000 40.625000
09/09 09:14:31 PM train 050 2.350975e+00 7.414216 48.988971
09/09 09:14:39 PM train 100 2.352375e+00 7.301980 47.679455
09/09 09:14:46 PM train 150 2.352786e+00 7.088162 47.288907
09/09 09:14:53 PM train 200 2.354028e+00 6.980721 46.906095
09/09 09:15:01 PM train 250 2.352326e+00 7.028137 47.254731
09/09 09:15:08 PM train 300 2.350997e+00 7.122093 47.612126
09/09 09:15:16 PM train 350 2.350038e+00 7.122507 47.863248
09/09 09:15:23 PM train 400 2.349295e+00 7.099439 48.020574
09/09 09:15:30 PM train 450 2.348626e+00 7.133453 48.170732
09/09 09:15:38 PM train 500 2.348323e+00 7.085828 48.231662
09/09 09:15:45 PM train 550 2.347799e+00 7.092219 48.204968
09/09 09:15:53 PM train 600 2.347293e+00 7.144343 48.148918
09/09 09:16:00 PM train 650 2.347517e+00 7.102055 48.147081
09/09 09:16:08 PM train 700 2.347242e+00 7.083631 48.190086
09/09 09:16:15 PM train_acc 7.127083
09/09 09:16:15 PM valid 000 2.374876e+00 6.250000 32.812500
09/09 09:16:16 PM valid 050 2.343373e+00 7.628676 47.794118
09/09 09:16:18 PM valid 100 2.344624e+00 7.301980 47.911510
09/09 09:16:19 PM valid 150 2.342105e+00 7.439983 48.561672
09/09 09:16:20 PM valid_acc 7.400000
09/09 09:16:20 PM epoch 1 lr 1.088147e-06
09/09 09:16:20 PM train 000 2.352198e+00 3.125000 46.875000
09/09 09:16:28 PM train 050 2.344026e+00 8.241422 49.172794
09/09 09:16:36 PM train 100 2.343515e+00 8.013614 49.458540
09/09 09:16:43 PM train 150 2.344071e+00 7.967715 48.551325
09/09 09:16:51 PM train 200 2.344707e+00 7.898010 48.282027
09/09 09:16:59 PM train 250 2.344502e+00 7.887201 48.213396
09/09 09:17:06 PM train 300 2.343735e+00 7.921512 48.312915
09/09 09:17:14 PM train 350 2.343393e+00 8.003917 48.290598
09/09 09:17:22 PM train 400 2.342663e+00 8.046291 48.445293
09/09 09:17:29 PM train 450 2.342887e+00 8.082733 48.382068
09/09 09:17:37 PM train 500 2.343004e+00 7.990269 48.465569
09/09 09:17:45 PM train 550 2.343152e+00 7.993988 48.400635
09/09 09:17:52 PM train 600 2.342790e+00 8.038686 48.427101
09/09 09:18:00 PM train 650 2.342472e+00 8.038114 48.485503
09/09 09:18:07 PM train 700 2.342487e+00 8.037625 48.562322
09/09 09:18:15 PM train_acc 8.008333
09/09 09:18:15 PM valid 000 2.341460e+00 7.812500 45.312500
09/09 09:18:16 PM valid 050 2.324159e+00 8.915441 48.927696
09/09 09:18:18 PM valid 100 2.329219e+00 8.694307 48.220916
09/09 09:18:19 PM valid 150 2.328574e+00 8.712748 48.075331
09/09 09:18:20 PM valid_acc 8.483333
09/09 09:18:20 PM epoch 2 lr 5.743939e-07
09/09 09:18:20 PM train 000 2.302979e+00 14.062500 56.250000
09/09 09:18:28 PM train 050 2.347809e+00 8.363971 47.303922
09/09 09:18:36 PM train 100 2.345643e+00 8.029084 48.344678
09/09 09:18:43 PM train 150 2.343912e+00 8.433361 48.437500
09/09 09:18:51 PM train 200 2.343774e+00 8.341107 48.694030
09/09 09:18:59 PM train 250 2.342579e+00 8.403884 49.072460
09/09 09:19:06 PM train 300 2.342444e+00 8.456188 49.096761
09/09 09:19:14 PM train 350 2.343731e+00 8.319979 48.789174
09/09 09:19:21 PM train 400 2.344718e+00 8.295667 48.581671
09/09 09:19:29 PM train 450 2.345184e+00 8.238636 48.472145
09/09 09:19:37 PM train 500 2.345322e+00 8.236652 48.337700
09/09 09:19:44 PM train 550 2.345321e+00 8.206670 48.332577
09/09 09:19:52 PM train 600 2.344883e+00 8.231073 48.408902
09/09 09:19:59 PM train 650 2.344565e+00 8.282930 48.449501
09/09 09:20:07 PM train 700 2.344573e+00 8.320703 48.410752
09/09 09:20:15 PM train_acc 8.339583
09/09 09:20:15 PM valid 000 2.327544e+00 9.375000 43.750000
09/09 09:20:16 PM valid 050 2.334559e+00 9.283088 44.944853
09/09 09:20:17 PM valid 100 2.327586e+00 10.102104 46.673886
09/09 09:20:19 PM valid 150 2.325252e+00 10.037252 47.744205
09/09 09:20:20 PM valid_acc 9.891667
09/09 09:20:20 PM epoch 3 lr 1.587586e-07
09/09 09:20:20 PM train 000 2.312439e+00 14.062500 56.250000
09/09 09:20:28 PM train 050 2.347061e+00 9.099265 48.376225
09/09 09:20:35 PM train 100 2.347890e+00 8.694307 48.530322
09/09 09:20:43 PM train 150 2.346230e+00 8.754139 48.644454
09/09 09:20:51 PM train 200 2.342837e+00 9.009639 49.020522
09/09 09:20:58 PM train 250 2.342634e+00 8.864542 49.091135
09/09 09:21:06 PM train 300 2.343044e+00 8.861088 49.200581
09/09 09:21:14 PM train 350 2.343857e+00 8.725071 49.082977
09/09 09:21:21 PM train 400 2.344178e+00 8.747662 48.940150
09/09 09:21:29 PM train 450 2.344626e+00 8.650915 48.891353
09/09 09:21:36 PM train 500 2.344795e+00 8.592191 48.855414
09/09 09:21:44 PM train 550 2.344580e+00 8.575318 48.811819
09/09 09:21:52 PM train 600 2.344265e+00 8.592450 48.941868
09/09 09:21:59 PM train 650 2.344031e+00 8.597350 49.008737
09/09 09:22:07 PM train 700 2.343551e+00 8.690710 49.115103
09/09 09:22:14 PM train_acc 8.675000
09/09 09:22:14 PM valid 000 2.311825e+00 15.625000 46.875000
09/09 09:22:16 PM valid 050 2.324328e+00 9.926471 46.966912
09/09 09:22:17 PM valid 100 2.324411e+00 10.411510 47.447401
09/09 09:22:19 PM valid 150 2.325846e+00 10.389073 47.154387
09/09 09:22:20 PM valid_acc 10.500000
09/09 09:22:20 PM epoch 4 lr 0.000000e+00
09/09 09:22:20 PM train 000 2.378117e+00 3.125000 42.187500
09/09 09:22:28 PM train 050 2.342602e+00 9.926471 49.816176
09/09 09:22:35 PM train 100 2.344355e+00 9.436881 50.077351
09/09 09:22:43 PM train 150 2.343741e+00 9.333609 49.803394
09/09 09:22:51 PM train 200 2.343798e+00 9.452736 49.759017
09/09 09:22:58 PM train 250 2.344868e+00 9.318974 49.452191
09/09 09:23:06 PM train 300 2.344350e+00 9.411337 49.512043
09/09 09:23:13 PM train 350 2.345254e+00 9.277066 49.252137
09/09 09:23:21 PM train 400 2.345518e+00 9.254208 49.189526
09/09 09:23:29 PM train 450 2.346087e+00 9.205238 49.147727
09/09 09:23:36 PM train 500 2.345910e+00 9.228418 49.242141
09/09 09:23:44 PM train 550 2.346644e+00 9.190676 49.160617
09/09 09:23:51 PM train 600 2.346687e+00 9.190412 49.196651
09/09 09:23:59 PM train 650 2.347216e+00 9.146985 49.138345
09/09 09:24:07 PM train 700 2.347515e+00 9.058488 49.021487
09/09 09:24:14 PM train_acc 9.062500
09/09 09:24:14 PM valid 000 2.339357e+00 9.375000 43.750000
09/09 09:24:16 PM valid 050 2.326401e+00 10.110294 47.395833
09/09 09:24:17 PM valid 100 2.327990e+00 10.055693 47.323639
09/09 09:24:19 PM valid 150 2.329738e+00 9.995861 46.988825
09/09 09:24:20 PM valid_acc 10.191667
09/09 09:24:20 PM Configuration achieved a performance of 2.328930 in 597.716596 seconds
09/09 09:24:20 PM Evaluate: [1.92881859e+01 8.18715058e-02 6.76346880e+00 1.06400035e-02
 1.75189831e+00 5.49476985e+00 1.76955209e+00 2.18285464e-04]
config {'batch_size': 32, 'drop_path_prob': 0.03274860231152753, 'grad_clip_value': 8, 'initial_lr': 1.1303163704497322e-06, 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.0010057471347902e-05}
09/09 09:24:20 PM Configuration achieved a performance of 100.000000 in 0.000250 seconds
09/09 09:24:20 PM Evaluate: [2.75943701e+01 2.63015418e-01 5.96243358e+00 8.73804054e-02
 2.05052921e-01 4.72180085e+00 5.88442230e-01 8.85829750e-04]
config {'batch_size': 32, 'drop_path_prob': 0.10520616725498533, 'grad_clip_value': 8, 'initial_lr': 2.7346517447741256e-06, 'lr_scheduler': 'Exponential', 'n_conv_layers': 6, 'optimizer': 'adad', 'weight_decay': 1.0040877288187395e-05}
09/09 09:24:20 PM gpu device = cuda:0
09/09 09:24:20 PM config = {'batch_size': 32, 'drop_path_prob': 0.10520616725498533, 'grad_clip_value': 8, 'initial_lr': 2.7346517447741256e-06, 'lr_scheduler': 'Exponential', 'n_conv_layers': 6, 'optimizer': 'adad', 'weight_decay': 1.0040877288187395e-05}
48 48 16
48 64 16
64 64 32
64 128 32
128 128 64
128 256 64
09/09 09:24:20 PM param size = 0.255930MB
Training size= 48000
09/09 09:24:20 PM epoch 0 lr 2.734652e-07
09/09 09:24:20 PM train 000 2.394835e+00 12.500000 40.625000
09/09 09:24:29 PM train 050 2.351188e+00 7.322304 48.897059
09/09 09:24:38 PM train 100 2.352858e+00 7.193688 47.617574
09/09 09:24:46 PM train 150 2.353510e+00 6.932947 47.299255
09/09 09:24:55 PM train 200 2.355045e+00 6.856343 46.937189
09/09 09:25:04 PM train 250 2.353545e+00 6.928536 47.285857
09/09 09:25:13 PM train 300 2.352475e+00 7.002699 47.601744
09/09 09:25:22 PM train 350 2.351772e+00 7.006766 47.840990
09/09 09:25:31 PM train 400 2.351262e+00 7.013716 47.969919
09/09 09:25:40 PM train 450 2.350874e+00 7.067627 48.104906
09/09 09:25:48 PM train 500 2.350837e+00 7.054641 48.153693
09/09 09:25:57 PM train 550 2.350520e+00 7.024161 48.074524
09/09 09:26:06 PM train 600 2.350204e+00 7.053349 48.052725
09/09 09:26:15 PM train 650 2.350711e+00 7.018049 48.036674
09/09 09:26:24 PM train 700 2.350678e+00 6.985556 48.025143
09/09 09:26:33 PM train_acc 7.022917
09/09 09:26:33 PM valid 000 2.387198e+00 4.687500 35.937500
09/09 09:26:34 PM valid 050 2.350768e+00 7.475490 47.334559
09/09 09:26:35 PM valid 100 2.352334e+00 7.209158 47.648515
09/09 09:26:37 PM valid 150 2.349654e+00 7.357202 48.209851
09/09 09:26:38 PM valid_acc 7.275000
09/09 09:26:38 PM epoch 1 lr 2.734652e-08
09/09 09:26:38 PM train 000 2.358696e+00 3.125000 46.875000
09/09 09:26:47 PM train 050 2.350830e+00 8.210784 48.560049
09/09 09:26:56 PM train 100 2.350469e+00 7.688738 48.715965
09/09 09:27:05 PM train 150 2.352001e+00 7.553808 47.837334
09/09 09:27:14 PM train 200 2.352701e+00 7.493781 47.939988
09/09 09:27:24 PM train 250 2.352588e+00 7.495020 47.970618
09/09 09:27:33 PM train 300 2.352107e+00 7.521802 48.037791
09/09 09:27:42 PM train 350 2.351857e+00 7.589922 48.019053
09/09 09:27:51 PM train 400 2.351526e+00 7.660536 48.176434
09/09 09:28:00 PM train 450 2.351881e+00 7.653132 48.215771
09/09 09:28:09 PM train 500 2.352201e+00 7.587949 48.284681
09/09 09:28:18 PM train 550 2.352587e+00 7.568625 48.139746
09/09 09:28:27 PM train 600 2.352444e+00 7.583715 48.167117
09/09 09:28:36 PM train 650 2.352209e+00 7.591686 48.243088
09/09 09:28:45 PM train 700 2.352322e+00 7.600749 48.277015
09/09 09:28:54 PM train_acc 7.516667
09/09 09:28:54 PM valid 000 2.356221e+00 3.125000 40.625000
09/09 09:28:56 PM valid 050 2.334107e+00 7.935049 48.743873
09/09 09:28:57 PM valid 100 2.338906e+00 7.518564 48.004332
09/09 09:28:58 PM valid 150 2.338169e+00 7.543460 47.785596
09/09 09:29:00 PM valid_acc 7.400000
09/09 09:29:00 PM epoch 2 lr 2.734652e-09
09/09 09:29:00 PM train 000 2.320167e+00 10.937500 56.250000
09/09 09:29:09 PM train 050 2.358964e+00 8.210784 47.334559
09/09 09:29:18 PM train 100 2.357614e+00 7.874381 48.267327
09/09 09:29:27 PM train 150 2.355243e+00 8.091887 48.458195
09/09 09:29:36 PM train 200 2.355250e+00 7.960199 48.600746
09/09 09:29:45 PM train 250 2.354591e+00 8.067729 48.655378
09/09 09:29:54 PM train 300 2.354661e+00 8.108389 48.686669
09/09 09:30:03 PM train 350 2.356125e+00 7.950499 48.428597
09/09 09:30:12 PM train 400 2.357254e+00 7.874844 48.316708
09/09 09:30:21 PM train 450 2.357706e+00 7.854074 48.253880
09/09 09:30:31 PM train 500 2.358137e+00 7.818738 48.081961
09/09 09:30:40 PM train 550 2.358118e+00 7.812500 48.114224
09/09 09:30:49 PM train 600 2.357821e+00 7.807300 48.242512
09/09 09:30:58 PM train 650 2.357657e+00 7.870104 48.238287
09/09 09:31:07 PM train 700 2.357651e+00 7.886056 48.214604
09/09 09:31:16 PM train_acc 7.868750
09/09 09:31:16 PM valid 000 2.338640e+00 9.375000 39.062500
09/09 09:31:17 PM valid 050 2.343451e+00 7.720588 44.240196
09/09 09:31:19 PM valid 100 2.335867e+00 8.183787 46.116955
09/09 09:31:20 PM valid 150 2.333659e+00 8.391970 47.030215
09/09 09:31:21 PM valid_acc 8.408333
09/09 09:31:21 PM epoch 3 lr 2.734652e-10
09/09 09:31:21 PM train 000 2.323496e+00 14.062500 51.562500
09/09 09:31:30 PM train 050 2.361403e+00 8.455882 48.529412
09/09 09:31:39 PM train 100 2.362047e+00 7.827970 48.344678
09/09 09:31:49 PM train 150 2.360138e+00 7.905629 48.799669
09/09 09:31:58 PM train 200 2.356957e+00 8.014614 48.849502
09/09 09:32:07 PM train 250 2.357136e+00 7.993028 48.848357
09/09 09:32:16 PM train 300 2.357585e+00 8.046096 48.904693
09/09 09:32:25 PM train 350 2.358117e+00 7.986111 48.864850
09/09 09:32:34 PM train 400 2.358831e+00 7.972257 48.640118
09/09 09:32:43 PM train 450 2.359564e+00 7.902578 48.524113
09/09 09:32:52 PM train 500 2.359759e+00 7.965319 48.415669
09/09 09:33:01 PM train 550 2.359370e+00 7.945780 48.505558
09/09 09:33:10 PM train 600 2.358922e+00 8.002288 48.637687
09/09 09:33:19 PM train 650 2.358687e+00 8.023714 48.742320
09/09 09:33:28 PM train 700 2.358022e+00 8.088891 48.916726
09/09 09:33:37 PM train_acc 8.116667
09/09 09:33:37 PM valid 000 2.319417e+00 14.062500 45.312500
09/09 09:33:39 PM valid 050 2.330042e+00 9.497549 46.691176
09/09 09:33:40 PM valid 100 2.330135e+00 9.823639 46.890470
09/09 09:33:42 PM valid 150 2.332006e+00 9.840646 46.471440
09/09 09:33:43 PM valid_acc 9.925000
09/09 09:33:43 PM epoch 4 lr 2.734652e-11
09/09 09:33:43 PM train 000 2.404575e+00 1.562500 40.625000
09/09 09:33:52 PM train 050 2.357131e+00 8.731618 48.958333
09/09 09:34:01 PM train 100 2.359083e+00 8.647896 49.040842
09/09 09:34:10 PM train 150 2.358297e+00 8.619619 49.089404
09/09 09:34:19 PM train 200 2.358351e+00 8.659826 49.168221
09/09 09:34:28 PM train 250 2.359889e+00 8.360309 48.935508
09/09 09:34:37 PM train 300 2.359760e+00 8.513289 49.065615
09/09 09:34:47 PM train 350 2.360625e+00 8.449074 48.869302
09/09 09:34:56 PM train 400 2.360700e+00 8.502182 48.901185
09/09 09:35:05 PM train 450 2.360807e+00 8.529656 48.901746
09/09 09:35:14 PM train 500 2.360834e+00 8.545409 48.995758
09/09 09:35:23 PM train 550 2.361749e+00 8.549796 48.800476
09/09 09:35:32 PM train 600 2.361811e+00 8.602849 48.767679
09/09 09:35:41 PM train 650 2.362031e+00 8.551747 48.759121
09/09 09:35:50 PM train 700 2.362369e+00 8.478959 48.689372
09/09 09:35:59 PM train_acc 8.516667
09/09 09:35:59 PM valid 000 2.338208e+00 10.937500 37.500000
09/09 09:36:00 PM valid 050 2.329962e+00 10.202206 46.813725
09/09 09:36:02 PM valid 100 2.331921e+00 10.365099 45.977723
09/09 09:36:03 PM valid 150 2.333656e+00 10.264901 45.809189
09/09 09:36:04 PM valid_acc 10.416667
09/09 09:36:04 PM Configuration achieved a performance of 2.333048 in 704.732141 seconds
09/09 09:36:04 PM Start iteration 3 ... 
09/09 09:36:04 PM Train model...
09/09 09:36:08 PM Time to train the model: 3.635572
09/09 09:36:35 PM Maximize acquisition function...
09/09 09:36:49 PM Time to maximize the acquisition function: 13.171927
09/09 09:36:49 PM Next candidate [2.63703704e+01 2.04938272e-01 4.51851852e+00 3.88895000e-02
 1.14814815e+00 4.50000000e+00 2.50000000e+00 4.68333333e-04]
config {'batch_size': 32, 'drop_path_prob': 0.08197530864197533, 'grad_clip_value': 8, 'initial_lr': 1.5647591507587493e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.0021590821721555e-05}
09/09 09:36:49 PM gpu device = cuda:0
09/09 09:36:49 PM config = {'batch_size': 32, 'drop_path_prob': 0.08197530864197533, 'grad_clip_value': 8, 'initial_lr': 1.5647591507587493e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.0021590821721555e-05}
48 48 16
48 64 16
64 64 32
64 128 32
128 128 64
128 256 64
09/09 09:36:49 PM param size = 0.255930MB
Training size= 48000
09/09 09:36:49 PM epoch 0 lr 7.823796e-07
09/09 09:36:49 PM train 000 2.394835e+00 12.500000 40.625000
09/09 09:36:56 PM train 050 2.351079e+00 7.352941 48.866422
09/09 09:37:04 PM train 100 2.352601e+00 7.240099 47.617574
09/09 09:37:11 PM train 150 2.353129e+00 7.026076 47.268212
09/09 09:37:19 PM train 200 2.354515e+00 6.918532 46.890547
09/09 09:37:26 PM train 250 2.352896e+00 6.965886 47.236056
09/09 09:37:33 PM train 300 2.351689e+00 7.054610 47.580980
09/09 09:37:41 PM train 350 2.350850e+00 7.051282 47.863248
09/09 09:37:48 PM train 400 2.350224e+00 7.052681 48.012781
09/09 09:37:56 PM train 450 2.349692e+00 7.091879 48.139551
09/09 09:38:03 PM train 500 2.349504e+00 7.076472 48.187999
09/09 09:38:11 PM train 550 2.349081e+00 7.058190 48.145417
09/09 09:38:18 PM train 600 2.348662e+00 7.102745 48.091722
09/09 09:38:25 PM train 650 2.349026e+00 7.056452 48.072677
09/09 09:38:33 PM train 700 2.348855e+00 7.036822 48.094240
09/09 09:38:40 PM train_acc 7.075000
09/09 09:38:40 PM valid 000 2.381593e+00 6.250000 32.812500
09/09 09:38:42 PM valid 050 2.346846e+00 7.567402 47.916667
09/09 09:38:43 PM valid 100 2.348284e+00 7.209158 47.957921
09/09 09:38:44 PM valid 150 2.345644e+00 7.357202 48.458195
09/09 09:38:46 PM valid_acc 7.341667
09/09 09:38:46 PM epoch 1 lr 0.000000e+00
09/09 09:38:46 PM train 000 2.358320e+00 10.937500 53.125000
09/09 09:38:53 PM train 050 2.350804e+00 8.180147 49.080882
09/09 09:39:01 PM train 100 2.351505e+00 7.905322 49.071782
09/09 09:39:09 PM train 150 2.351793e+00 7.947020 48.458195
09/09 09:39:16 PM train 200 2.351419e+00 7.983520 48.678483
09/09 09:39:24 PM train 250 2.350846e+00 7.993028 48.537102
09/09 09:39:32 PM train 300 2.350878e+00 8.072051 48.598422
09/09 09:39:39 PM train 350 2.350518e+00 8.097400 48.628917
09/09 09:39:47 PM train 400 2.350274e+00 8.143703 48.686877
09/09 09:39:54 PM train 450 2.350546e+00 8.120843 48.714662
09/09 09:40:02 PM train 500 2.350649e+00 8.052645 48.852295
09/09 09:40:10 PM train 550 2.350869e+00 8.008167 48.729583
09/09 09:40:17 PM train 600 2.350445e+00 8.093282 48.861273
09/09 09:40:25 PM train 650 2.350290e+00 8.062116 48.915131
09/09 09:40:33 PM train 700 2.350193e+00 8.071059 48.943474
09/09 09:40:40 PM train_acc 8.054167
09/09 09:40:40 PM valid 000 2.347547e+00 6.250000 42.187500
09/09 09:40:42 PM valid 050 2.326125e+00 9.283088 48.713235
09/09 09:40:43 PM valid 100 2.332205e+00 8.740718 47.339109
09/09 09:40:44 PM valid 150 2.331484e+00 8.826573 47.599338
09/09 09:40:46 PM valid_acc 8.666667
09/09 09:40:46 PM Configuration achieved a performance of 2.332163 
09/09 09:40:46 PM Evaluation of this configuration took 236.868240 seconds
09/09 09:40:46 PM Current incumbent [2.38532751e+01 2.98055545e-01 4.76668131e+00 4.41544910e-02
 1.00000000e+00 3.71819649e+00 2.00000000e+00 5.59387867e-04] with estimated performance 2.328930
09/09 09:40:46 PM Start iteration 4 ... 
09/09 09:40:46 PM Train model...
09/09 09:40:48 PM Time to train the model: 2.435414
09/09 09:41:15 PM Maximize acquisition function...
09/09 09:41:27 PM Time to maximize the acquisition function: 11.562519
09/09 09:41:27 PM Next candidate [2.16296296e+01 2.00000000e-01 6.00000000e+00 3.88895000e-02
 1.81481481e+00 3.16666667e+00 1.27777778e+00 8.71666667e-04]
config {'batch_size': 32, 'drop_path_prob': 0.08000000000000002, 'grad_clip_value': 8, 'initial_lr': 1.5647591507587493e-06, 'n_conv_layers': 6, 'optimizer': 'adad', 'weight_decay': 1.0040222409305598e-05}
09/09 09:41:27 PM Configuration achieved a performance of 100.000000 
09/09 09:41:27 PM Evaluation of this configuration took 0.000227 seconds
09/09 09:41:27 PM Current incumbent [2.38532751e+01 2.98055545e-01 4.76668131e+00 4.41544910e-02
 1.00000000e+00 3.71819649e+00 2.00000000e+00 5.59387867e-04] with estimated performance 2.328930
09/09 09:41:27 PM Start iteration 5 ... 
09/09 09:41:27 PM Train model...
09/09 09:41:29 PM Time to train the model: 2.396673
09/09 09:41:56 PM Maximize acquisition function...
DIRECT Version 2.0.4
 Problem Dimension n                    :      8
 Eps value                              :   0.1000E-03
 Epsilon is constant.
 Maximum number of f-evaluations (maxf) :    400
 Maximum number of iterations (MaxT)    :    200
 Value of f_global                      :  -0.1000+101
 Global percentage wanted               :   0.1000E-01
 Volume percentage wanted               :  -0.1000E+01
 Measure percentage wanted              :  -0.1000E+01
 Jones original DIRECT algorithm is used.
Bounds on variable x 1    :     16.00000 <= xi <=     32.00000
Bounds on variable x 2    :      0.00000 <= xi <=      0.40000
Bounds on variable x 3    :      4.00000 <= xi <=      8.00000
Bounds on variable x 4    :      0.00000 <= xi <=      0.10000
Bounds on variable x 5    :      0.00000 <= xi <=      2.00000
Bounds on variable x 6    :      3.00000 <= xi <=      6.00000
Bounds on variable x 7    :      0.00000 <= xi <=      3.00000
Bounds on variable x 8    :      0.00001 <= xi <=      0.00100
---------------------------------------------------------------------------
   17 &      -0.0031291323 &      -0.0018071149 \\\\ 
   31 &      -0.0032395706 &      -0.0014845271 \\\\ 
   95 &      -0.0035136350 &      -0.0010058136 \\\\ 
  131 &      -0.0035302697 &      -0.0010058136 \\\\ 
  165 &      -0.0035327649 &      -0.0010058136 \\\\ 
  253 &      -0.0036663362 &      -0.0010058136 \\\\ 
  297 &      -0.0037151404 &      -0.0010058136 \\\\ 
  327 &      -0.0037352687 &      -0.0010058136 \\\\ 
  355 &      -0.0037380580 &      -0.0010058136 \\\\ 
  437 &      -0.0038376824 &      -0.0010058136 \\\\ 
DIRECT stopped: numfunc >= maxf.
DIRECT Version 2.0.4
 Problem Dimension n                    :      8
 Eps value                              :   0.1000E-03
 Epsilon is constant.
 Maximum number of f-evaluations (maxf) :    400
 Maximum number of iterations (MaxT)    :    200
 Value of f_global                      :  -0.1000+101
 Global percentage wanted               :   0.1000E-01
 Volume percentage wanted               :  -0.1000E+01
 Measure percentage wanted              :  -0.1000E+01
 Jones original DIRECT algorithm is used.
Bounds on variable x 1    :     16.00000 <= xi <=     32.00000
Bounds on variable x 2    :      0.00000 <= xi <=      0.40000
Bounds on variable x 3    :      4.00000 <= xi <=      8.00000
Bounds on variable x 4    :      0.00000 <= xi <=      0.10000
Bounds on variable x 5    :      0.00000 <= xi <=      2.00000
Bounds on variable x 6    :      3.00000 <= xi <=      6.00000
Bounds on variable x 7    :      0.00000 <= xi <=      3.00000
Bounds on variable x 8    :      0.00001 <= xi <=      0.00100
---------------------------------------------------------------------------
   17 &      -0.0004987124 &      -0.0001147438 \\\\ 
   31 &      -0.0006102123 &      -0.0000571366 \\\\ 
   57 &      -0.0007738738 &      -0.0000571366 \\\\ 
   79 &      -0.0012956390 &      -0.0000419125 \\\\ 
  137 &      -0.0020000137 &      -0.0000419125 \\\\ 
  181 &      -0.0022271465 &      -0.0000313282 \\\\ 
  215 &      -0.0024024748 &      -0.0000176075 \\\\ 
  243 &      -0.0025559260 &      -0.0000176075 \\\\ 
  267 &      -0.0025663379 &      -0.0000176075 \\\\ 
  323 &      -0.0031524534 &      -0.0000176075 \\\\ 
  347 &      -0.0033673619 &      -0.0000176075 \\\\ 
  377 &      -0.0035131614 &      -0.0000176075 \\\\ 
  403 &      -0.0035737610 &      -0.0000150316 \\\\ 
DIRECT stopped: numfunc >= maxf.
DIRECT Version 2.0.4
 Problem Dimension n                    :      8
 Eps value                              :   0.1000E-03
 Epsilon is constant.
 Maximum number of f-evaluations (maxf) :    400
 Maximum number of iterations (MaxT)    :    200
 Value of f_global                      :  -0.1000+101
 Global percentage wanted               :   0.1000E-01
 Volume percentage wanted               :  -0.1000E+01
 Measure percentage wanted              :  -0.1000E+01
 Jones original DIRECT algorithm is used.
Bounds on variable x 1    :     16.00000 <= xi <=     32.00000
Bounds on variable x 2    :      0.00000 <= xi <=      0.40000
09/09 09:42:09 PM Time to maximize the acquisition function: 12.700953
09/09 09:42:09 PM Next candidate [2.93333333e+01 2.00000000e-01 4.66666667e+00 2.77785000e-02
 1.00000000e+00 4.50000000e+00 5.00000000e-01 2.85000000e-04]
config {'batch_size': 32, 'drop_path_prob': 0.08000000000000002, 'grad_clip_value': 8, 'initial_lr': 1.376868613317072e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'adam', 'weight_decay': 1.0013133351732858e-05}
09/09 09:42:09 PM gpu device = cuda:0
09/09 09:42:09 PM config = {'batch_size': 32, 'drop_path_prob': 0.08000000000000002, 'grad_clip_value': 8, 'initial_lr': 1.376868613317072e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'adam', 'weight_decay': 1.0013133351732858e-05}
48 48 16
48 64 16
64 64 32
64 128 32
128 128 64
128 256 64
09/09 09:42:09 PM param size = 0.255930MB
Training size= 48000
09/09 09:42:09 PM epoch 0 lr 6.884343e-07
09/09 09:42:09 PM train 000 2.394835e+00 12.500000 40.625000
09/09 09:42:17 PM train 050 2.350210e+00 7.352941 48.988971
09/09 09:42:25 PM train 100 2.350873e+00 7.301980 47.896040
09/09 09:42:33 PM train 150 2.350504e+00 7.150248 47.733858
09/09 09:42:41 PM train 200 2.350949e+00 7.128420 47.504664
09/09 09:42:49 PM train 250 2.348441e+00 7.227341 48.007968
09/09 09:42:57 PM train 300 2.346361e+00 7.350498 48.427118
09/09 09:43:05 PM train 350 2.344695e+00 7.451923 48.789174
09/09 09:43:14 PM train 400 2.343268e+00 7.578709 49.033666
09/09 09:43:22 PM train 450 2.341930e+00 7.701635 49.237805
09/09 09:43:30 PM train 500 2.340857e+00 7.762600 49.398079
09/09 09:43:38 PM train 550 2.339597e+00 7.849365 49.498072
09/09 09:43:46 PM train 600 2.338388e+00 7.978889 49.576227
09/09 09:43:54 PM train 650 2.337863e+00 8.002112 49.630376
09/09 09:44:02 PM train 700 2.336921e+00 8.048770 49.732525
09/09 09:44:10 PM train_acc 8.191667
09/09 09:44:10 PM valid 000 2.353886e+00 4.687500 37.500000
09/09 09:44:11 PM valid 050 2.321558e+00 10.202206 50.980392
09/09 09:44:13 PM valid 100 2.322593e+00 9.993812 51.082921
09/09 09:44:14 PM valid 150 2.319777e+00 10.151076 51.583195
09/09 09:44:15 PM valid_acc 10.133333
09/09 09:44:15 PM epoch 1 lr 0.000000e+00
09/09 09:44:16 PM train 000 2.331398e+00 10.937500 53.125000
09/09 09:44:24 PM train 050 2.325043e+00 10.232843 52.083333
09/09 09:44:32 PM train 100 2.326035e+00 9.947401 51.995668
09/09 09:44:40 PM train 150 2.327040e+00 9.871689 51.158940
09/09 09:44:49 PM train 200 2.326576e+00 9.888060 51.298197
09/09 09:44:57 PM train 250 2.326111e+00 9.835657 51.251245
09/09 09:45:05 PM train 300 2.326255e+00 9.852575 51.261420
09/09 09:45:14 PM train 350 2.325896e+00 9.918091 51.264245
09/09 09:45:22 PM train 400 2.325703e+00 9.971166 51.355985
09/09 09:45:30 PM train 450 2.325975e+00 9.977827 51.399667
09/09 09:45:39 PM train 500 2.326061e+00 9.889596 51.587450
09/09 09:45:47 PM train 550 2.326289e+00 9.831556 51.502949
09/09 09:45:55 PM train 600 2.325889e+00 9.892367 51.627496
09/09 09:46:04 PM train 650 2.325712e+00 9.893433 51.648906
09/09 09:46:12 PM train 700 2.325669e+00 9.916637 51.651658
09/09 09:46:20 PM train_acc 9.920833
09/09 09:46:20 PM valid 000 2.337916e+00 3.125000 50.000000
09/09 09:46:22 PM valid 050 2.310943e+00 9.191176 52.389706
09/09 09:46:23 PM valid 100 2.315313e+00 8.941832 51.577970
09/09 09:46:24 PM valid 150 2.314952e+00 9.074917 51.500414
09/09 09:46:26 PM valid_acc 9.083333
09/09 09:46:26 PM Configuration achieved a performance of 2.315414 
09/09 09:46:26 PM Evaluation of this configuration took 256.890291 seconds
09/09 09:46:26 PM Current incumbent [2.93333333e+01 2.00000000e-01 4.66666667e+00 2.77785000e-02
 1.00000000e+00 4.50000000e+00 0.00000000e+00 2.85000000e-04] with estimated performance 2.315414
09/09 09:46:26 PM Start iteration 6 ... 
09/09 09:46:26 PM Train model...
09/09 09:46:28 PM Time to train the model: 2.339235
09/09 09:46:55 PM Maximize acquisition function...
09/09 09:47:07 PM Time to maximize the acquisition function: 12.179743
09/09 09:47:07 PM Next candidate [2.40000000e+01 6.66666667e-02 5.25925926e+00 4.62968333e-02
 6.29629630e-01 3.50000000e+00 1.50000000e+00 4.68333333e-04]
config {'batch_size': 32, 'drop_path_prob': 0.026666666666666672, 'grad_clip_value': 8, 'initial_lr': 1.704057192352142e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.0021590821721555e-05}
09/09 09:47:07 PM gpu device = cuda:0
09/09 09:47:07 PM config = {'batch_size': 32, 'drop_path_prob': 0.026666666666666672, 'grad_clip_value': 8, 'initial_lr': 1.704057192352142e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.0021590821721555e-05}
48 48 16
48 64 16
64 64 32
64 128 32
128 128 64
128 256 64
09/09 09:47:07 PM param size = 0.255930MB
Training size= 48000
09/09 09:47:07 PM epoch 0 lr 8.520286e-07
09/09 09:47:08 PM train 000 2.394835e+00 12.500000 40.625000
09/09 09:47:15 PM train 050 2.351069e+00 7.352941 48.866422
09/09 09:47:23 PM train 100 2.352580e+00 7.240099 47.648515
09/09 09:47:30 PM train 150 2.353098e+00 7.036424 47.278560
09/09 09:47:37 PM train 200 2.354475e+00 6.918532 46.898321
09/09 09:47:45 PM train 250 2.352844e+00 6.959661 47.242281
09/09 09:47:52 PM train 300 2.351623e+00 7.049419 47.596553
09/09 09:48:00 PM train 350 2.350769e+00 7.046830 47.876603
09/09 09:48:07 PM train 400 2.350131e+00 7.048784 48.020574
09/09 09:48:14 PM train 450 2.349586e+00 7.091879 48.146480
09/09 09:48:22 PM train 500 2.349385e+00 7.073353 48.178643
09/09 09:48:29 PM train 550 2.348953e+00 7.066697 48.145417
09/09 09:48:37 PM train 600 2.348526e+00 7.107945 48.091722
09/09 09:48:44 PM train 650 2.348877e+00 7.058852 48.075077
09/09 09:48:52 PM train 700 2.348697e+00 7.034593 48.094240
09/09 09:48:59 PM train_acc 7.075000
09/09 09:48:59 PM valid 000 2.380863e+00 6.250000 32.812500
09/09 09:49:00 PM valid 050 2.346482e+00 7.598039 47.947304
09/09 09:49:02 PM valid 100 2.347918e+00 7.240099 47.988861
09/09 09:49:03 PM valid 150 2.345298e+00 7.377897 48.416805
09/09 09:49:04 PM valid_acc 7.375000
09/09 09:49:04 PM epoch 1 lr 0.000000e+00
09/09 09:49:04 PM train 000 2.333922e+00 9.375000 50.000000
09/09 09:49:12 PM train 050 2.344247e+00 7.689951 48.835784
09/09 09:49:20 PM train 100 2.343990e+00 7.611386 49.009901
09/09 09:49:27 PM train 150 2.346224e+00 7.460679 48.054636
09/09 09:49:35 PM train 200 2.346642e+00 7.454913 48.204291
09/09 09:49:43 PM train 250 2.346537e+00 7.476345 48.306773
09/09 09:49:50 PM train 300 2.346221e+00 7.376453 48.380399
09/09 09:49:58 PM train 350 2.345889e+00 7.402956 48.419694
09/09 09:50:05 PM train 400 2.345886e+00 7.407263 48.460879
09/09 09:50:13 PM train 450 2.346342e+00 7.407151 48.513720
09/09 09:50:21 PM train 500 2.346536e+00 7.341567 48.474925
09/09 09:50:28 PM train 550 2.347092e+00 7.279378 48.375113
09/09 09:50:36 PM train 600 2.347154e+00 7.266535 48.260711
09/09 09:50:44 PM train 650 2.346988e+00 7.279666 48.317492
09/09 09:50:51 PM train 700 2.347030e+00 7.277550 48.357257
09/09 09:50:59 PM train_acc 7.252083
09/09 09:50:59 PM valid 000 2.355283e+00 6.250000 42.187500
09/09 09:51:00 PM valid 050 2.334149e+00 8.057598 49.019608
09/09 09:51:02 PM valid 100 2.338459e+00 7.704208 48.282797
09/09 09:51:03 PM valid 150 2.337898e+00 7.698675 48.230546
09/09 09:51:04 PM valid_acc 7.558333
09/09 09:51:04 PM Configuration achieved a performance of 2.338894 
09/09 09:51:04 PM Evaluation of this configuration took 236.798088 seconds
09/09 09:51:04 PM Current incumbent [2.93333333e+01 2.00000000e-01 4.66666667e+00 2.77785000e-02
 1.00000000e+00 4.50000000e+00 0.00000000e+00 2.85000000e-04] with estimated performance 2.315414
09/09 09:51:04 PM Start iteration 7 ... 
09/09 09:51:04 PM Train model...
09/09 09:51:07 PM Time to train the model: 2.376804
09/09 09:51:34 PM Maximize acquisition function...
Bounds on variable x 3    :      4.00000 <= xi <=      8.00000
Bounds on variable x 4    :      0.00000 <= xi <=      0.10000
Bounds on variable x 5    :      0.00000 <= xi <=      2.00000
Bounds on variable x 6    :      3.00000 <= xi <=      6.00000
Bounds on variable x 7    :      0.00000 <= xi <=      3.00000
Bounds on variable x 8    :      0.00001 <= xi <=      0.00100
---------------------------------------------------------------------------
   17 &      -0.0009845992 &      -0.0002481609 \\\\ 
   31 &      -0.0012359803 &      -0.0002481609 \\\\ 
   57 &      -0.0013298006 &      -0.0001262926 \\\\ 
   79 &      -0.0015832270 &      -0.0001262926 \\\\ 
  101 &      -0.0016008493 &      -0.0001262926 \\\\ 
  183 &      -0.0017451313 &      -0.0000964130 \\\\ 
  233 &      -0.0020122973 &      -0.0000964130 \\\\ 
  263 &      -0.0020233025 &      -0.0000964130 \\\\ 
  341 &      -0.0020261024 &      -0.0000964130 \\\\ 
  399 &      -0.0020794681 &      -0.0000964130 \\\\ 
  441 &      -0.0021310726 &      -0.0000964130 \\\\ 
DIRECT stopped: numfunc >= maxf.
DIRECT Version 2.0.4
 Problem Dimension n                    :      8
 Eps value                              :   0.1000E-03
 Epsilon is constant.
 Maximum number of f-evaluations (maxf) :    400
 Maximum number of iterations (MaxT)    :    200
 Value of f_global                      :  -0.1000+101
 Global percentage wanted               :   0.1000E-01
 Volume percentage wanted               :  -0.1000E+01
 Measure percentage wanted              :  -0.1000E+01
 Jones original DIRECT algorithm is used.
Bounds on variable x 1    :     16.00000 <= xi <=     32.00000
Bounds on variable x 2    :      0.00000 <= xi <=      0.40000
Bounds on variable x 3    :      4.00000 <= xi <=      8.00000
Bounds on variable x 4    :      0.00000 <= xi <=      0.10000
Bounds on variable x 5    :      0.00000 <= xi <=      2.00000
Bounds on variable x 6    :      3.00000 <= xi <=      6.00000
Bounds on variable x 7    :      0.00000 <= xi <=      3.00000
Bounds on variable x 8    :      0.00001 <= xi <=      0.00100
---------------------------------------------------------------------------
   17 &      -0.0010225763 &      -0.0001109286 \\\\ 
   31 &      -0.0011476253 &      -0.0001022104 \\\\ 
   57 &      -0.0012370313 &      -0.0000455635 \\\\ 
   79 &      -0.0012560185 &      -0.0000455635 \\\\ 
  145 &      -0.0015920345 &      -0.0000455635 \\\\ 
  189 &      -0.0017838516 &      -0.0000455635 \\\\ 
  281 &      -0.0018384484 &      -0.0000240502 \\\\ 
  323 &      -0.0018887326 &      -0.0000240502 \\\\ 
  357 &      -0.0019272671 &      -0.0000240502 \\\\ 
  391 &      -0.0019466835 &      -0.0000240502 \\\\ 
DIRECT stopped: numfunc >= maxf.
DIRECT Version 2.0.4
 Problem Dimension n                    :      8
 Eps value                              :   0.1000E-03
 Epsilon is constant.
 Maximum number of f-evaluations (maxf) :    400
 Maximum number of iterations (MaxT)    :    200
 Value of f_global                      :  -0.1000+101
 Global percentage wanted               :   0.1000E-01
 Volume percentage wanted               :  -0.1000E+01
 Measure percentage wanted              :  -0.1000E+01
 Jones original DIRECT algorithm is used.
Bounds on variable x 1    :     16.00000 <= xi <=     32.00000
Bounds on variable x 2    :      0.00000 <= xi <=      0.40000
Bounds on variable x 3    :      4.00000 <= xi <=      8.00000
Bounds on variable x 4    :      0.00000 <= xi <=      0.10000
Bounds on variable x 5    :      0.00000 <= xi <=      2.00000
Bounds on variable x 6    :      3.00000 <= xi <=      6.00000
Bounds on variable x 7    :      0.00000 <= xi <=      3.00000
Bounds on variable x 8    :      0.00001 <= xi <=      0.00100
---------------------------------------------------------------------------
   17 &      -0.0015684537 &      -0.0006955760 \\\\ 
   31 &      -0.0018308378 &      -0.0006955760 \\\\ 
   57 &      -0.0018542841 &      -0.0004671147 \\\\ 
  125 &      -0.0021132832 &      -0.0004671147 \\\\ 
  169 &      -0.0022227480 &      -0.0002430512 \\\\ 
09/09 09:51:46 PM Time to maximize the acquisition function: 12.148487
09/09 09:51:46 PM Next candidate [2.04444444e+01 2.74074074e-01 6.59259259e+00 3.88895000e-02
 5.55555556e-01 4.50000000e+00 1.16666667e+00 5.05000000e-04]
config {'batch_size': 32, 'drop_path_prob': 0.10962962962962963, 'grad_clip_value': 8, 'initial_lr': 1.5647591507587493e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'adad', 'weight_decay': 1.0023283172746057e-05}
09/09 09:51:46 PM gpu device = cuda:0
09/09 09:51:46 PM config = {'batch_size': 32, 'drop_path_prob': 0.10962962962962963, 'grad_clip_value': 8, 'initial_lr': 1.5647591507587493e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'adad', 'weight_decay': 1.0023283172746057e-05}
48 48 16
48 64 16
64 64 32
64 128 32
128 128 64
128 256 64
09/09 09:51:46 PM param size = 0.255930MB
Training size= 48000
09/09 09:51:46 PM epoch 0 lr 7.823796e-07
09/09 09:51:46 PM train 000 2.394835e+00 12.500000 40.625000
09/09 09:51:55 PM train 050 2.351187e+00 7.322304 48.897059
09/09 09:52:04 PM train 100 2.352855e+00 7.193688 47.617574
09/09 09:52:13 PM train 150 2.353506e+00 6.932947 47.299255
09/09 09:52:22 PM train 200 2.355038e+00 6.856343 46.944963
09/09 09:52:30 PM train 250 2.353537e+00 6.934761 47.292082
09/09 09:52:39 PM train 300 2.352465e+00 7.007890 47.606935
09/09 09:52:48 PM train 350 2.351761e+00 7.011218 47.845442
09/09 09:52:57 PM train 400 2.351249e+00 7.017612 47.973815
09/09 09:53:06 PM train 450 2.350860e+00 7.071092 48.108370
09/09 09:53:15 PM train 500 2.350821e+00 7.057759 48.156811
09/09 09:53:24 PM train 550 2.350503e+00 7.026996 48.077359
09/09 09:53:32 PM train 600 2.350185e+00 7.055948 48.055324
09/09 09:53:41 PM train 650 2.350690e+00 7.020449 48.043875
09/09 09:53:50 PM train 700 2.350655e+00 6.987785 48.034058
09/09 09:53:59 PM train_acc 7.025000
09/09 09:53:59 PM valid 000 2.387135e+00 4.687500 35.937500
09/09 09:54:01 PM valid 050 2.350719e+00 7.475490 47.334559
09/09 09:54:02 PM valid 100 2.352283e+00 7.209158 47.648515
09/09 09:54:03 PM valid 150 2.349604e+00 7.367550 48.209851
09/09 09:54:04 PM valid_acc 7.283333
09/09 09:54:04 PM epoch 1 lr 0.000000e+00
09/09 09:54:05 PM train 000 2.373659e+00 9.375000 50.000000
09/09 09:54:14 PM train 050 2.358398e+00 8.455882 48.713235
09/09 09:54:23 PM train 100 2.357468e+00 7.874381 48.592203
09/09 09:54:32 PM train 150 2.357538e+00 7.926325 48.302980
09/09 09:54:41 PM train 200 2.357182e+00 7.913557 48.445274
09/09 09:54:50 PM train 250 2.356639e+00 7.930777 48.487301
09/09 09:54:59 PM train 300 2.356941e+00 7.890365 48.484219
09/09 09:55:08 PM train 350 2.356143e+00 7.937144 48.744658
09/09 09:55:17 PM train 400 2.356135e+00 7.874844 48.690773
09/09 09:55:26 PM train 450 2.356474e+00 7.885255 48.690410
09/09 09:55:35 PM train 500 2.356495e+00 7.884232 48.771208
09/09 09:55:45 PM train 550 2.356592e+00 7.843693 48.715404
09/09 09:55:54 PM train 600 2.356478e+00 7.895695 48.705283
09/09 09:56:03 PM train 650 2.356518e+00 7.872504 48.682316
09/09 09:56:12 PM train 700 2.356045e+00 7.948466 48.769615
09/09 09:56:21 PM train_acc 7.952083
09/09 09:56:21 PM valid 000 2.349001e+00 7.812500 40.625000
09/09 09:56:22 PM valid 050 2.326387e+00 10.447304 48.284314
09/09 09:56:24 PM valid 100 2.332924e+00 9.467822 46.828589
09/09 09:56:25 PM valid 150 2.332161e+00 9.550911 47.092301
09/09 09:56:26 PM valid_acc 9.350000
09/09 09:56:26 PM Configuration achieved a performance of 2.332891 
09/09 09:56:26 PM Evaluation of this configuration took 280.121473 seconds
09/09 09:56:26 PM Current incumbent [2.93333333e+01 2.00000000e-01 4.66666667e+00 2.77785000e-02
 1.00000000e+00 4.50000000e+00 0.00000000e+00 2.85000000e-04] with estimated performance 2.315414
09/09 09:56:26 PM Start iteration 8 ... 
09/09 09:56:26 PM Train model...
09/09 09:56:28 PM Time to train the model: 2.340203
09/09 09:56:56 PM Maximize acquisition function...
09/09 09:57:08 PM Time to maximize the acquisition function: 11.891287
09/09 09:57:08 PM Next candidate [2.38024691e+01 2.00000000e-01 5.11111111e+00 5.00005000e-02
 1.64197531e+00 4.50000000e+00 1.72222222e+00 6.27222222e-04]
config {'batch_size': 32, 'drop_path_prob': 0.08000000000000002, 'grad_clip_value': 8, 'initial_lr': 1.7782896466675373e-06, 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.0028926407124432e-05}
09/09 09:57:08 PM Configuration achieved a performance of 100.000000 
09/09 09:57:08 PM Evaluation of this configuration took 0.000226 seconds
09/09 09:57:08 PM Current incumbent [2.93333333e+01 2.00000000e-01 4.66666667e+00 2.77785000e-02
 1.00000000e+00 4.50000000e+00 0.00000000e+00 2.85000000e-04] with estimated performance 2.315414
09/09 09:57:08 PM Start iteration 9 ... 
09/09 09:57:08 PM Train model...
09/09 09:57:10 PM Time to train the model: 2.358703
09/09 09:57:37 PM Maximize acquisition function...
09/09 09:57:49 PM Time to maximize the acquisition function: 12.272016
09/09 09:57:49 PM Next candidate [1.74814815e+01 8.14814815e-02 5.11111111e+00 4.62968333e-02
 1.00000000e+00 5.50000000e+00 1.50000000e+00 6.15000000e-04]
config {'batch_size': 32, 'drop_path_prob': 0.0325925925925926, 'grad_clip_value': 8, 'initial_lr': 1.704057192352142e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.0028361940741568e-05}
09/09 09:57:49 PM gpu device = cuda:0
09/09 09:57:49 PM config = {'batch_size': 32, 'drop_path_prob': 0.0325925925925926, 'grad_clip_value': 8, 'initial_lr': 1.704057192352142e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.0028361940741568e-05}
48 48 16
48 64 16
64 64 32
64 128 32
128 128 64
128 256 64
09/09 09:57:49 PM param size = 0.255930MB
Training size= 48000
09/09 09:57:49 PM epoch 0 lr 8.520286e-07
09/09 09:57:50 PM train 000 2.394835e+00 12.500000 40.625000
09/09 09:57:57 PM train 050 2.351069e+00 7.352941 48.866422
09/09 09:58:04 PM train 100 2.352580e+00 7.240099 47.633045
09/09 09:58:12 PM train 150 2.353097e+00 7.036424 47.247517
09/09 09:58:19 PM train 200 2.354474e+00 6.926306 46.875000
09/09 09:58:27 PM train 250 2.352843e+00 6.972112 47.236056
09/09 09:58:34 PM train 300 2.351622e+00 7.059801 47.586171
09/09 09:58:41 PM train 350 2.350770e+00 7.055734 47.872151
09/09 09:58:49 PM train 400 2.350134e+00 7.052681 48.008884
09/09 09:58:56 PM train 450 2.349588e+00 7.088415 48.139551
09/09 09:59:04 PM train 500 2.349388e+00 7.067116 48.175524
09/09 09:59:11 PM train 550 2.348955e+00 7.061025 48.142582
09/09 09:59:19 PM train 600 2.348528e+00 7.102745 48.091722
09/09 09:59:26 PM train 650 2.348880e+00 7.058852 48.077477
09/09 09:59:33 PM train 700 2.348700e+00 7.032364 48.094240
09/09 09:59:41 PM train_acc 7.075000
09/09 09:59:41 PM valid 000 2.381027e+00 6.250000 32.812500
09/09 09:59:42 PM valid 050 2.346495e+00 7.659314 48.039216
09/09 09:59:44 PM valid 100 2.347921e+00 7.255569 48.004332
09/09 09:59:45 PM valid 150 2.345288e+00 7.367550 48.478891
09/09 09:59:46 PM valid_acc 7.366667
09/09 09:59:46 PM epoch 1 lr 0.000000e+00
09/09 09:59:46 PM train 000 2.335659e+00 10.937500 51.562500
09/09 09:59:54 PM train 050 2.345378e+00 7.935049 49.356618
09/09 10:00:01 PM train 100 2.345498e+00 7.595916 48.963490
09/09 10:00:09 PM train 150 2.347623e+00 7.346854 48.013245
09/09 10:00:17 PM train 200 2.347894e+00 7.353856 47.932214
09/09 10:00:24 PM train 250 2.347597e+00 7.401643 47.983068
09/09 10:00:32 PM train 300 2.347353e+00 7.324543 48.053364
09/09 10:00:40 PM train 350 2.347048e+00 7.402956 48.076923
09/09 10:00:47 PM train 400 2.346793e+00 7.473504 48.227089
09/09 10:00:55 PM train 450 2.347137e+00 7.462583 48.271203
09/09 10:01:02 PM train 500 2.347217e+00 7.378992 48.300274
09/09 10:01:10 PM train 550 2.347608e+00 7.344601 48.236162
09/09 10:01:18 PM train 600 2.347546e+00 7.328931 48.146319
09/09 10:01:26 PM train 650 2.347390e+00 7.339670 48.202285
09/09 10:01:33 PM train 700 2.347417e+00 7.344419 48.265870
09/09 10:01:41 PM train_acc 7.310417
09/09 10:01:41 PM valid 000 2.352922e+00 6.250000 43.750000
09/09 10:01:42 PM valid 050 2.332672e+00 8.241422 48.743873
09/09 10:01:44 PM valid 100 2.337200e+00 7.704208 48.035272
09/09 10:01:45 PM valid 150 2.336649e+00 7.667632 48.054636
09/09 10:01:46 PM valid_acc 7.516667
09/09 10:01:46 PM Configuration achieved a performance of 2.337636 
09/09 10:01:46 PM Evaluation of this configuration took 236.666801 seconds
09/09 10:01:46 PM Current incumbent [2.93333333e+01 2.00000000e-01 4.66666667e+00 2.77785000e-02
 1.00000000e+00 4.50000000e+00 0.00000000e+00 2.85000000e-04] with estimated performance 2.315414
09/09 10:01:46 PM Start iteration 10 ... 
09/09 10:01:46 PM Train model...
09/09 10:01:48 PM Time to train the model: 2.362337
09/09 10:02:16 PM Maximize acquisition function...
  211 &      -0.0023504515 &      -0.0002430512 \\\\ 
  251 &      -0.0025742394 &      -0.0002430512 \\\\ 
  277 &      -0.0027464398 &      -0.0002430512 \\\\ 
  299 &      -0.0027693565 &      -0.0002430512 \\\\ 
  363 &      -0.0030407578 &      -0.0002430512 \\\\ 
  417 &      -0.0030973618 &      -0.0002430512 \\\\ 
DIRECT stopped: numfunc >= maxf.
DIRECT Version 2.0.4
 Problem Dimension n                    :      8
 Eps value                              :   0.1000E-03
 Epsilon is constant.
 Maximum number of f-evaluations (maxf) :    400
 Maximum number of iterations (MaxT)    :    200
 Value of f_global                      :  -0.1000+101
 Global percentage wanted               :   0.1000E-01
 Volume percentage wanted               :  -0.1000E+01
 Measure percentage wanted              :  -0.1000E+01
 Jones original DIRECT algorithm is used.
Bounds on variable x 1    :     16.00000 <= xi <=     32.00000
Bounds on variable x 2    :      0.00000 <= xi <=      0.40000
Bounds on variable x 3    :      4.00000 <= xi <=      8.00000
Bounds on variable x 4    :      0.00000 <= xi <=      0.10000
Bounds on variable x 5    :      0.00000 <= xi <=      2.00000
Bounds on variable x 6    :      3.00000 <= xi <=      6.00000
Bounds on variable x 7    :      0.00000 <= xi <=      3.00000
Bounds on variable x 8    :      0.00001 <= xi <=      0.00100
---------------------------------------------------------------------------
   17 &      -0.0014604343 &      -0.0002904824 \\\\ 
   31 &      -0.0016567737 &      -0.0002904824 \\\\ 
   95 &      -0.0017429320 &      -0.0001125145 \\\\ 
  131 &      -0.0018338909 &      -0.0001125145 \\\\ 
  165 &      -0.0018778469 &      -0.0001125145 \\\\ 
  259 &      -0.0023163555 &      -0.0000186768 \\\\ 
  337 &      -0.0024815304 &      -0.0000186768 \\\\ 
  375 &      -0.0025132150 &      -0.0000186768 \\\\ 
  405 &      -0.0025161690 &      -0.0000186768 \\\\ 
DIRECT stopped: numfunc >= maxf.
DIRECT Version 2.0.4
 Problem Dimension n                    :      8
 Eps value                              :   0.1000E-03
 Epsilon is constant.
 Maximum number of f-evaluations (maxf) :    400
 Maximum number of iterations (MaxT)    :    200
 Value of f_global                      :  -0.1000+101
 Global percentage wanted               :   0.1000E-01
 Volume percentage wanted               :  -0.1000E+01
 Measure percentage wanted              :  -0.1000E+01
 Jones original DIRECT algorithm is used.
Bounds on variable x 1    :     16.00000 <= xi <=     32.00000
Bounds on variable x 2    :      0.00000 <= xi <=      0.40000
Bounds on variable x 3    :      4.00000 <= xi <=      8.00000
Bounds on variable x 4    :      0.00000 <= xi <=      0.10000
Bounds on variable x 5    :      0.00000 <= xi <=      2.00000
Bounds on variable x 6    :      3.00000 <= xi <=      6.00000
Bounds on variable x 7    :      0.00000 <= xi <=      3.00000
Bounds on variable x 8    :      0.00001 <= xi <=      0.00100
---------------------------------------------------------------------------
   17 &      -0.0008116768 &      -0.0001524739 \\\\ 
   31 &      -0.0010253937 &      -0.0001524739 \\\\ 
   57 &      -0.0010636433 &      -0.0001117210 \\\\ 
  117 &      -0.0013722386 &      -0.0001117210 \\\\ 
  181 &      -0.0016803718 &      -0.0001117210 \\\\ 
  223 &      -0.0018428118 &      -0.0001117210 \\\\ 
  245 &      -0.0018745546 &      -0.0001117210 \\\\ 
  319 &      -0.0019880148 &      -0.0001117210 \\\\ 
  379 &      -0.0020440142 &      -0.0001117210 \\\\ 
  419 &      -0.0021362456 &      -0.0001117210 \\\\ 
DIRECT stopped: numfunc >= maxf.
DIRECT Version 2.0.4
 Problem Dimension n                    :      8
 Eps value                              :   0.1000E-03
 Epsilon is constant.
 Maximum number of f-evaluations (maxf) :    400
 Maximum number of iterations (MaxT)    :    200
 Value of f_global                      :  -0.1000+101
 Global percentage wanted               :   0.1000E-01
 Volume percentage wanted               :  -0.1000E+01
 Measure percentage wanted              :  -0.1000E+01
 Jones original DIRECT algorithm is used.
09/09 10:02:29 PM Time to maximize the acquisition function: 13.014933
09/09 10:02:29 PM Next candidate [2.75555556e+01 6.66666667e-02 6.88888889e+00 8.70371667e-02
 2.59259259e-01 3.50000000e+00 1.50000000e+00 1.75000000e-04]
config {'batch_size': 32, 'drop_path_prob': 0.026666666666666672, 'grad_clip_value': 8, 'initial_lr': 2.723866593264654e-06, 'lr_scheduler': 'Exponential', 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.0008062296110608e-05}
09/09 10:02:29 PM gpu device = cuda:0
09/09 10:02:29 PM config = {'batch_size': 32, 'drop_path_prob': 0.026666666666666672, 'grad_clip_value': 8, 'initial_lr': 2.723866593264654e-06, 'lr_scheduler': 'Exponential', 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.0008062296110608e-05}
48 48 16
48 64 16
64 64 32
64 128 32
128 128 64
128 256 64
09/09 10:02:29 PM param size = 0.255930MB
Training size= 48000
09/09 10:02:29 PM epoch 0 lr 2.723867e-07
09/09 10:02:29 PM train 000 2.394835e+00 12.500000 40.625000
09/09 10:02:36 PM train 050 2.351151e+00 7.322304 48.958333
09/09 10:02:44 PM train 100 2.352767e+00 7.209158 47.663985
09/09 10:02:51 PM train 150 2.353375e+00 6.984685 47.288907
09/09 10:02:59 PM train 200 2.354861e+00 6.887438 46.937189
09/09 10:03:06 PM train 250 2.353319e+00 6.953436 47.298307
09/09 10:03:14 PM train 300 2.352202e+00 7.023463 47.622508
09/09 10:03:21 PM train 350 2.351452e+00 7.015670 47.867699
09/09 10:03:28 PM train 400 2.350903e+00 7.013716 48.004988
09/09 10:03:36 PM train 450 2.350468e+00 7.053769 48.129157
09/09 10:03:43 PM train 500 2.350379e+00 7.048403 48.169286
09/09 10:03:51 PM train 550 2.350024e+00 7.024161 48.100045
09/09 10:03:58 PM train 600 2.349674e+00 7.061148 48.081323
09/09 10:04:05 PM train 650 2.350129e+00 7.022849 48.072677
09/09 10:04:13 PM train 700 2.350048e+00 6.994472 48.076409
09/09 10:04:20 PM train_acc 7.027083
09/09 10:04:20 PM valid 000 2.384679e+00 6.250000 35.937500
09/09 10:04:22 PM valid 050 2.349373e+00 7.352941 47.518382
09/09 10:04:23 PM valid 100 2.350899e+00 7.193688 47.834158
09/09 10:04:24 PM valid 150 2.348238e+00 7.274421 48.416805
09/09 10:04:26 PM valid_acc 7.216667
09/09 10:04:26 PM epoch 1 lr 2.723867e-08
09/09 10:04:26 PM train 000 2.335860e+00 9.375000 50.000000
09/09 10:04:33 PM train 050 2.347328e+00 7.628676 49.019608
09/09 10:04:41 PM train 100 2.346921e+00 7.518564 49.272896
09/09 10:04:49 PM train 150 2.349211e+00 7.398593 48.344371
09/09 10:04:56 PM train 200 2.349662e+00 7.400498 48.243159
09/09 10:05:04 PM train 250 2.349445e+00 7.463894 48.306773
09/09 10:05:11 PM train 300 2.349124e+00 7.371262 48.390781
09/09 10:05:19 PM train 350 2.348797e+00 7.402956 48.424145
09/09 10:05:27 PM train 400 2.348846e+00 7.391677 48.468672
09/09 10:05:34 PM train 450 2.349304e+00 7.375970 48.472145
09/09 10:05:42 PM train 500 2.349474e+00 7.319736 48.471806
09/09 10:05:50 PM train 550 2.350033e+00 7.256692 48.380785
09/09 10:05:57 PM train 600 2.350098e+00 7.235337 48.239913
09/09 10:06:05 PM train 650 2.349937e+00 7.241263 48.305492
09/09 10:06:12 PM train 700 2.349957e+00 7.239658 48.366173
09/09 10:06:20 PM train_acc 7.197917
09/09 10:06:20 PM valid 000 2.358253e+00 4.687500 42.187500
09/09 10:06:21 PM valid 050 2.336517e+00 7.781863 48.529412
09/09 10:06:23 PM valid 100 2.340792e+00 7.441213 48.050743
09/09 10:06:24 PM valid 150 2.340190e+00 7.357202 48.002897
09/09 10:06:25 PM valid_acc 7.250000
09/09 10:06:25 PM Configuration achieved a performance of 2.341174 
09/09 10:06:25 PM Evaluation of this configuration took 236.507793 seconds
09/09 10:06:25 PM Current incumbent [2.93333333e+01 2.00000000e-01 4.66666667e+00 2.77785000e-02
 1.00000000e+00 4.50000000e+00 0.00000000e+00 2.85000000e-04] with estimated performance 2.315414
09/09 10:06:25 PM Start iteration 11 ... 
09/09 10:06:25 PM Train model...
09/09 10:06:28 PM Time to train the model: 2.357596
09/09 10:06:55 PM Maximize acquisition function...
09/09 10:07:07 PM Time to maximize the acquisition function: 12.409510
09/09 10:07:07 PM Next candidate [1.86666667e+01 6.66666667e-02 4.66666667e+00 5.55650000e-03
 5.55555556e-01 4.50000000e+00 1.83333333e+00 5.05000000e-04]
config {'batch_size': 32, 'drop_path_prob': 0.026666666666666672, 'grad_clip_value': 8, 'initial_lr': 1.0660620905544188e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.0023283172746057e-05}
09/09 10:07:07 PM gpu device = cuda:0
09/09 10:07:07 PM config = {'batch_size': 32, 'drop_path_prob': 0.026666666666666672, 'grad_clip_value': 8, 'initial_lr': 1.0660620905544188e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.0023283172746057e-05}
48 48 16
48 64 16
64 64 32
64 128 32
128 128 64
128 256 64
09/09 10:07:07 PM param size = 0.255930MB
Training size= 48000
09/09 10:07:07 PM epoch 0 lr 5.330310e-07
09/09 10:07:08 PM train 000 2.394835e+00 12.500000 40.625000
09/09 10:07:15 PM train 050 2.351113e+00 7.322304 48.927696
09/09 10:07:22 PM train 100 2.352680e+00 7.209158 47.663985
09/09 10:07:30 PM train 150 2.353248e+00 6.995033 47.330298
09/09 10:07:37 PM train 200 2.354684e+00 6.902985 46.944963
09/09 10:07:45 PM train 250 2.353104e+00 6.959661 47.292082
09/09 10:07:52 PM train 300 2.351942e+00 7.039037 47.617317
09/09 10:07:59 PM train 350 2.351144e+00 7.029024 47.867699
09/09 10:08:07 PM train 400 2.350555e+00 7.029302 48.008884
09/09 10:08:14 PM train 450 2.350071e+00 7.067627 48.115299
09/09 10:08:22 PM train 500 2.349932e+00 7.051522 48.150574
09/09 10:08:29 PM train 550 2.349540e+00 7.029832 48.111388
09/09 10:08:37 PM train 600 2.349155e+00 7.066348 48.089122
09/09 10:08:44 PM train 650 2.349560e+00 7.034850 48.072677
09/09 10:08:51 PM train 700 2.349433e+00 7.016762 48.071951
09/09 10:08:59 PM train_acc 7.052083
09/09 10:08:59 PM valid 000 2.382888e+00 6.250000 32.812500
09/09 10:09:00 PM valid 050 2.348060e+00 7.567402 47.549020
09/09 10:09:01 PM valid 100 2.349527e+00 7.193688 47.741337
09/09 10:09:03 PM valid 150 2.346872e+00 7.305464 48.365066
09/09 10:09:04 PM valid_acc 7.275000
09/09 10:09:04 PM epoch 1 lr 0.000000e+00
09/09 10:09:04 PM train 000 2.335053e+00 9.375000 50.000000
09/09 10:09:12 PM train 050 2.345917e+00 7.628676 48.866422
09/09 10:09:19 PM train 100 2.345575e+00 7.534035 49.102723
09/09 10:09:27 PM train 150 2.347841e+00 7.388245 48.147765
09/09 10:09:35 PM train 200 2.348279e+00 7.431592 48.212065
09/09 10:09:42 PM train 250 2.348109e+00 7.501245 48.288098
09/09 10:09:50 PM train 300 2.347798e+00 7.407600 48.364826
09/09 10:09:58 PM train 350 2.347477e+00 7.429665 48.392984
09/09 10:10:05 PM train 400 2.347512e+00 7.411160 48.437500
09/09 10:10:13 PM train 450 2.347969e+00 7.393293 48.454823
09/09 10:10:20 PM train 500 2.348155e+00 7.332211 48.465569
09/09 10:10:28 PM train 550 2.348714e+00 7.265200 48.366606
09/09 10:10:36 PM train 600 2.348781e+00 7.256136 48.242512
09/09 10:10:43 PM train 650 2.348620e+00 7.258065 48.310292
09/09 10:10:51 PM train 700 2.348654e+00 7.259718 48.341655
09/09 10:10:58 PM train_acc 7.229167
09/09 10:10:58 PM valid 000 2.356983e+00 6.250000 42.187500
09/09 10:11:00 PM valid 050 2.335482e+00 7.935049 48.835784
09/09 10:11:01 PM valid 100 2.339753e+00 7.580446 48.189975
09/09 10:11:03 PM valid 150 2.339171e+00 7.512417 48.085679
09/09 10:11:04 PM valid_acc 7.383333
09/09 10:11:04 PM Configuration achieved a performance of 2.340161 
09/09 10:11:04 PM Evaluation of this configuration took 236.555239 seconds
09/09 10:11:04 PM Current incumbent [2.93333333e+01 2.00000000e-01 4.66666667e+00 2.77785000e-02
 1.00000000e+00 4.50000000e+00 0.00000000e+00 2.85000000e-04] with estimated performance 2.315414
09/09 10:11:04 PM Start iteration 12 ... 
09/09 10:11:04 PM Train model...
09/09 10:11:06 PM Time to train the model: 2.337789
09/09 10:11:34 PM Maximize acquisition function...
Bounds on variable x 1    :     16.00000 <= xi <=     32.00000
Bounds on variable x 2    :      0.00000 <= xi <=      0.40000
Bounds on variable x 3    :      4.00000 <= xi <=      8.00000
Bounds on variable x 4    :      0.00000 <= xi <=      0.10000
Bounds on variable x 5    :      0.00000 <= xi <=      2.00000
Bounds on variable x 6    :      3.00000 <= xi <=      6.00000
Bounds on variable x 7    :      0.00000 <= xi <=      3.00000
Bounds on variable x 8    :      0.00001 <= xi <=      0.00100
---------------------------------------------------------------------------
   17 &      -0.0011546179 &      -0.0000326471 \\\\ 
   31 &      -0.0014961507 &      -0.0000326471 \\\\ 
   57 &      -0.0014992305 &      -0.0000201457 \\\\ 
  125 &      -0.0015674178 &      -0.0000201457 \\\\ 
  175 &      -0.0019796633 &      -0.0000201457 \\\\ 
  201 &      -0.0021378142 &      -0.0000201457 \\\\ 
  233 &      -0.0021820803 &      -0.0000201457 \\\\ 
  273 &      -0.0024929048 &      -0.0000201457 \\\\ 
  311 &      -0.0025714687 &      -0.0000201457 \\\\ 
  397 &      -0.0026121717 &      -0.0000201457 \\\\ 
  439 &      -0.0026503268 &      -0.0000201457 \\\\ 
DIRECT stopped: numfunc >= maxf.
DIRECT Version 2.0.4
 Problem Dimension n                    :      8
 Eps value                              :   0.1000E-03
 Epsilon is constant.
 Maximum number of f-evaluations (maxf) :    400
 Maximum number of iterations (MaxT)    :    200
 Value of f_global                      :  -0.1000+101
 Global percentage wanted               :   0.1000E-01
 Volume percentage wanted               :  -0.1000E+01
 Measure percentage wanted              :  -0.1000E+01
 Jones original DIRECT algorithm is used.
Bounds on variable x 1    :     16.00000 <= xi <=     32.00000
Bounds on variable x 2    :      0.00000 <= xi <=      0.40000
Bounds on variable x 3    :      4.00000 <= xi <=      8.00000
Bounds on variable x 4    :      0.00000 <= xi <=      0.10000
Bounds on variable x 5    :      0.00000 <= xi <=      2.00000
Bounds on variable x 6    :      3.00000 <= xi <=      6.00000
Bounds on variable x 7    :      0.00000 <= xi <=      3.00000
Bounds on variable x 8    :      0.00001 <= xi <=      0.00100
---------------------------------------------------------------------------
   17 &      -0.0023312618 &      -0.0004353747 \\\\ 
   31 &      -0.0026174135 &      -0.0004353747 \\\\ 
   95 &      -0.0028395862 &      -0.0002858409 \\\\ 
  139 &      -0.0029102380 &      -0.0002858409 \\\\ 
  181 &      -0.0030184741 &      -0.0002858409 \\\\ 
  213 &      -0.0031696825 &      -0.0002858409 \\\\ 
  243 &      -0.0032676581 &      -0.0002457371 \\\\ 
  259 &      -0.0032892899 &      -0.0002457371 \\\\ 
  281 &      -0.0037200101 &      -0.0002457371 \\\\ 
  335 &      -0.0038258306 &      -0.0002457371 \\\\ 
  377 &      -0.0040483601 &      -0.0002457371 \\\\ 
  411 &      -0.0043142015 &      -0.0002457371 \\\\ 
DIRECT stopped: numfunc >= maxf.
DIRECT Version 2.0.4
 Problem Dimension n                    :      8
 Eps value                              :   0.1000E-03
 Epsilon is constant.
 Maximum number of f-evaluations (maxf) :    400
 Maximum number of iterations (MaxT)    :    200
 Value of f_global                      :  -0.1000+101
 Global percentage wanted               :   0.1000E-01
 Volume percentage wanted               :  -0.1000E+01
 Measure percentage wanted              :  -0.1000E+01
 Jones original DIRECT algorithm is used.
Bounds on variable x 1    :     16.00000 <= xi <=     32.00000
Bounds on variable x 2    :      0.00000 <= xi <=      0.40000
Bounds on variable x 3    :      4.00000 <= xi <=      8.00000
Bounds on variable x 4    :      0.00000 <= xi <=      0.10000
Bounds on variable x 5    :      0.00000 <= xi <=      2.00000
Bounds on variable x 6    :      3.00000 <= xi <=      6.00000
Bounds on variable x 7    :      0.00000 <= xi <=      3.00000
Bounds on variable x 8    :      0.00001 <= xi <=      0.00100
---------------------------------------------------------------------------
   17 &      -0.0035813283 &      -0.0005531202 \\\\ 
09/09 10:11:46 PM Time to maximize the acquisition function: 12.349153
09/09 10:11:46 PM Next candidate [2.40000000e+01 6.17283951e-02 4.81481481e+00 1.29638333e-02
 1.00000000e+00 4.94444444e+00 1.61111111e+00 5.05000000e-04]
config {'batch_size': 32, 'drop_path_prob': 0.024691358024691364, 'grad_clip_value': 8, 'initial_lr': 1.1609651057303842e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.0023283172746057e-05}
09/09 10:11:46 PM gpu device = cuda:0
09/09 10:11:46 PM config = {'batch_size': 32, 'drop_path_prob': 0.024691358024691364, 'grad_clip_value': 8, 'initial_lr': 1.1609651057303842e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.0023283172746057e-05}
48 48 16
48 64 16
64 64 32
64 128 32
128 128 64
128 256 64
09/09 10:11:46 PM param size = 0.255930MB
Training size= 48000
09/09 10:11:46 PM epoch 0 lr 5.804826e-07
09/09 10:11:46 PM train 000 2.394835e+00 12.500000 40.625000
09/09 10:11:54 PM train 050 2.351106e+00 7.322304 48.958333
09/09 10:12:01 PM train 100 2.352665e+00 7.224629 47.679455
09/09 10:12:08 PM train 150 2.353224e+00 7.005381 47.330298
09/09 10:12:16 PM train 200 2.354651e+00 6.902985 46.944963
09/09 10:12:23 PM train 250 2.353063e+00 6.959661 47.279631
09/09 10:12:31 PM train 300 2.351893e+00 7.039037 47.606935
09/09 10:12:38 PM train 350 2.351088e+00 7.033476 47.863248
09/09 10:12:45 PM train 400 2.350491e+00 7.037095 47.997195
09/09 10:12:53 PM train 450 2.349999e+00 7.078021 48.094512
09/09 10:13:00 PM train 500 2.349852e+00 7.060878 48.150574
09/09 10:13:08 PM train 550 2.349453e+00 7.049682 48.111388
09/09 10:13:15 PM train 600 2.349062e+00 7.087146 48.091722
09/09 10:13:23 PM train 650 2.349456e+00 7.054051 48.067876
09/09 10:13:30 PM train 700 2.349322e+00 7.032364 48.069722
09/09 10:13:37 PM train_acc 7.070833
09/09 10:13:37 PM valid 000 2.382416e+00 6.250000 32.812500
09/09 10:13:39 PM valid 050 2.347804e+00 7.536765 47.610294
09/09 10:13:40 PM valid 100 2.349259e+00 7.209158 47.803218
09/09 10:13:42 PM valid 150 2.346607e+00 7.336507 48.427152
09/09 10:13:43 PM valid_acc 7.283333
09/09 10:13:43 PM epoch 1 lr 0.000000e+00
09/09 10:13:43 PM train 000 2.340150e+00 9.375000 48.437500
09/09 10:13:50 PM train 050 2.346293e+00 7.873775 48.774510
09/09 10:13:58 PM train 100 2.345618e+00 7.657797 49.025371
09/09 10:14:06 PM train 150 2.347865e+00 7.450331 48.106374
09/09 10:14:13 PM train 200 2.348284e+00 7.384950 48.072139
09/09 10:14:21 PM train 250 2.348131e+00 7.420319 48.151145
09/09 10:14:29 PM train 300 2.347840e+00 7.308970 48.266196
09/09 10:14:36 PM train 350 2.347581e+00 7.300570 48.361823
09/09 10:14:44 PM train 400 2.347575e+00 7.282575 48.402431
09/09 10:14:52 PM train 450 2.347918e+00 7.275499 48.472145
09/09 10:14:59 PM train 500 2.348096e+00 7.226173 48.434381
09/09 10:15:07 PM train 550 2.348741e+00 7.157441 48.312727
09/09 10:15:14 PM train 600 2.348751e+00 7.133943 48.200915
09/09 10:15:22 PM train 650 2.348513e+00 7.150058 48.255088
09/09 10:15:30 PM train 700 2.348561e+00 7.143812 48.301534
09/09 10:15:37 PM train_acc 7.116667
09/09 10:15:37 PM valid 000 2.357326e+00 6.250000 42.187500
09/09 10:15:39 PM valid 050 2.335813e+00 7.965686 48.590686
09/09 10:15:40 PM valid 100 2.339980e+00 7.549505 48.019802
09/09 10:15:42 PM valid 150 2.339408e+00 7.533113 48.054636
09/09 10:15:43 PM valid_acc 7.391667
09/09 10:15:43 PM Configuration achieved a performance of 2.340396 
09/09 10:15:43 PM Evaluation of this configuration took 236.705774 seconds
09/09 10:15:43 PM Current incumbent [2.93333333e+01 2.00000000e-01 4.66666667e+00 2.77785000e-02
 1.00000000e+00 4.50000000e+00 0.00000000e+00 2.85000000e-04] with estimated performance 2.315414
09/09 10:15:43 PM Start iteration 13 ... 
09/09 10:15:43 PM Train model...
09/09 10:15:45 PM Time to train the model: 2.347375
09/09 10:16:13 PM Maximize acquisition function...
09/09 10:16:26 PM Time to maximize the acquisition function: 12.895116
09/09 10:16:26 PM Next candidate [2.22222222e+01 2.00000000e-01 5.25925926e+00 1.66675000e-02
 9.25925926e-01 4.50000000e+00 2.50000000e+00 4.31666667e-04]
config {'batch_size': 32, 'drop_path_prob': 0.08000000000000002, 'grad_clip_value': 8, 'initial_lr': 1.211539282207375e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.001989875643696e-05}
09/09 10:16:26 PM gpu device = cuda:0
09/09 10:16:26 PM config = {'batch_size': 32, 'drop_path_prob': 0.08000000000000002, 'grad_clip_value': 8, 'initial_lr': 1.211539282207375e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.001989875643696e-05}
48 48 16
48 64 16
64 64 32
64 128 32
128 128 64
128 256 64
09/09 10:16:26 PM param size = 0.255930MB
Training size= 48000
09/09 10:16:26 PM epoch 0 lr 6.057696e-07
09/09 10:16:26 PM train 000 2.394835e+00 12.500000 40.625000
09/09 10:16:33 PM train 050 2.351103e+00 7.322304 48.897059
09/09 10:16:41 PM train 100 2.352657e+00 7.224629 47.663985
09/09 10:16:48 PM train 150 2.353213e+00 7.005381 47.309603
09/09 10:16:56 PM train 200 2.354634e+00 6.902985 46.929415
09/09 10:17:03 PM train 250 2.353043e+00 6.959661 47.267181
09/09 10:17:11 PM train 300 2.351867e+00 7.044228 47.596553
09/09 10:17:18 PM train 350 2.351056e+00 7.037927 47.863248
09/09 10:17:25 PM train 400 2.350457e+00 7.037095 48.001091
09/09 10:17:33 PM train 450 2.349959e+00 7.074557 48.118764
09/09 10:17:40 PM train 500 2.349805e+00 7.060878 48.150574
09/09 10:17:48 PM train 550 2.349405e+00 7.044011 48.108553
09/09 10:17:55 PM train 600 2.349011e+00 7.081947 48.078723
09/09 10:18:02 PM train 650 2.349403e+00 7.051651 48.063076
09/09 10:18:10 PM train 700 2.349263e+00 7.032364 48.063035
09/09 10:18:17 PM train_acc 7.070833
09/09 10:18:17 PM valid 000 2.382588e+00 6.250000 32.812500
09/09 10:18:19 PM valid 050 2.347720e+00 7.536765 47.671569
09/09 10:18:20 PM valid 100 2.349171e+00 7.178218 47.803218
09/09 10:18:21 PM valid 150 2.346512e+00 7.315811 48.406457
09/09 10:18:23 PM valid_acc 7.275000
09/09 10:18:23 PM epoch 1 lr 0.000000e+00
09/09 10:18:23 PM train 000 2.358843e+00 10.937500 51.562500
09/09 10:18:30 PM train 050 2.351109e+00 7.996324 49.264706
09/09 10:18:38 PM train 100 2.351846e+00 7.797030 49.071782
09/09 10:18:46 PM train 150 2.352181e+00 7.833195 48.509934
09/09 10:18:53 PM train 200 2.352006e+00 7.905784 48.624067
09/09 10:19:01 PM train 250 2.351464e+00 7.943227 48.568227
09/09 10:19:09 PM train 300 2.351560e+00 8.035714 48.624377
09/09 10:19:16 PM train 350 2.351185e+00 8.066239 48.602208
09/09 10:19:24 PM train 400 2.350986e+00 8.124221 48.655704
09/09 10:19:31 PM train 450 2.351321e+00 8.089662 48.659229
09/09 10:19:39 PM train 500 2.351398e+00 8.002745 48.814870
09/09 10:19:47 PM train 550 2.351620e+00 7.974138 48.701225
09/09 10:19:54 PM train 600 2.351217e+00 8.051685 48.817076
09/09 10:20:02 PM train 650 2.351054e+00 8.028514 48.859927
09/09 10:20:10 PM train 700 2.350952e+00 8.035396 48.887750
09/09 10:20:17 PM train_acc 8.016667
09/09 10:20:17 PM valid 000 2.348104e+00 6.250000 43.750000
09/09 10:20:19 PM valid 050 2.326761e+00 9.160539 48.774510
09/09 10:20:20 PM valid 100 2.332770e+00 8.647896 47.447401
09/09 10:20:21 PM valid 150 2.332071e+00 8.712748 47.661424
09/09 10:20:22 PM valid_acc 8.591667
09/09 10:20:22 PM Configuration achieved a performance of 2.332714 
09/09 10:20:22 PM Evaluation of this configuration took 236.676056 seconds
09/09 10:20:22 PM Current incumbent [2.93333333e+01 2.00000000e-01 4.66666667e+00 2.77785000e-02
 1.00000000e+00 4.50000000e+00 0.00000000e+00 2.85000000e-04] with estimated performance 2.315414
09/09 10:20:22 PM Start iteration 14 ... 
09/09 10:20:22 PM Train model...
09/09 10:20:25 PM Time to train the model: 2.365080
09/09 10:20:52 PM Maximize acquisition function...
09/09 10:21:05 PM Time to maximize the acquisition function: 12.911218
09/09 10:21:05 PM Next candidate [2.93333333e+01 3.18518519e-01 6.00000000e+00 8.70371667e-02
 7.77777778e-01 4.38888889e+00 1.72222222e+00 3.58333333e-04]
config {'batch_size': 32, 'drop_path_prob': 0.1274074074074074, 'grad_clip_value': 8, 'initial_lr': 2.723866593264654e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.0016515482894514e-05}
09/09 10:21:05 PM gpu device = cuda:0
09/09 10:21:05 PM config = {'batch_size': 32, 'drop_path_prob': 0.1274074074074074, 'grad_clip_value': 8, 'initial_lr': 2.723866593264654e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.0016515482894514e-05}
48 48 16
48 64 16
64 64 32
64 128 32
128 128 64
128 256 64
09/09 10:21:05 PM param size = 0.255930MB
Training size= 48000
09/09 10:21:05 PM epoch 0 lr 1.361933e-06
09/09 10:21:05 PM train 000 2.394835e+00 12.500000 40.625000
09/09 10:21:13 PM train 050 2.350994e+00 7.383578 48.958333
09/09 10:21:20 PM train 100 2.352417e+00 7.271040 47.633045
09/09 10:21:28 PM train 150 2.352852e+00 7.057119 47.237169
09/09 10:21:35 PM train 200 2.354122e+00 6.949627 46.875000
09/09 10:21:43 PM train 250 2.352439e+00 7.003237 47.229831
09/09 10:21:50 PM train 300 2.351130e+00 7.085756 47.601744
09/09 10:21:57 PM train 350 2.350191e+00 7.095798 47.876603
09/09 10:22:05 PM train 400 2.349477e+00 7.076060 48.024470
09/09 10:22:12 PM train 450 2.348836e+00 7.112666 48.177661
09/09 10:22:20 PM train 500 2.348559e+00 7.063997 48.241018
09/09 10:22:27 PM train 550 2.348053e+00 7.075204 48.187954
09/09 10:22:35 PM train 600 2.347562e+00 7.136543 48.130720
09/09 10:22:42 PM train 650 2.347816e+00 7.092454 48.125480
09/09 10:22:49 PM train 700 2.347565e+00 7.076944 48.154422
09/09 10:22:57 PM train_acc 7.116667
09/09 10:22:57 PM valid 000 2.377167e+00 6.250000 32.812500
09/09 10:22:58 PM valid 050 2.344053e+00 7.720588 48.008578
09/09 10:23:00 PM valid 100 2.345311e+00 7.286510 48.081683
09/09 10:23:01 PM valid 150 2.342748e+00 7.471026 48.623758
09/09 10:23:02 PM valid_acc 7.416667
09/09 10:23:02 PM epoch 1 lr 0.000000e+00
09/09 10:23:02 PM train 000 2.380039e+00 6.250000 45.312500
09/09 10:23:10 PM train 050 2.352357e+00 8.302696 48.958333
09/09 10:23:17 PM train 100 2.353784e+00 7.781559 48.422030
09/09 10:23:25 PM train 150 2.353511e+00 7.988411 48.116722
09/09 10:23:33 PM train 200 2.353586e+00 7.991294 48.289801
09/09 10:23:40 PM train 250 2.352421e+00 8.042829 48.562002
09/09 10:23:48 PM train 300 2.352440e+00 8.134344 48.489410
09/09 10:23:56 PM train 350 2.351837e+00 8.275463 48.677885
09/09 10:24:03 PM train 400 2.351655e+00 8.167082 48.628429
09/09 10:24:11 PM train 450 2.351955e+00 8.176275 48.572616
09/09 10:24:19 PM train 500 2.351951e+00 8.121257 48.705714
09/09 10:24:26 PM train 550 2.351785e+00 8.130104 48.718240
09/09 10:24:34 PM train 600 2.351484e+00 8.163478 48.757280
09/09 10:24:42 PM train 650 2.351583e+00 8.162922 48.708717
09/09 10:24:49 PM train 700 2.351336e+00 8.207026 48.760699
09/09 10:24:57 PM train_acc 8.225000
09/09 10:24:57 PM valid 000 2.340521e+00 6.250000 46.875000
09/09 10:24:58 PM valid 050 2.323409e+00 11.458333 47.640931
09/09 10:25:00 PM valid 100 2.330075e+00 10.318688 46.132426
09/09 10:25:01 PM valid 150 2.329368e+00 10.285596 46.543874
09/09 10:25:02 PM valid_acc 10.083333
09/09 10:25:02 PM Configuration achieved a performance of 2.330142 
09/09 10:25:02 PM Evaluation of this configuration took 236.780122 seconds
09/09 10:25:02 PM Current incumbent [2.93333333e+01 2.00000000e-01 4.66666667e+00 2.77785000e-02
 1.00000000e+00 4.50000000e+00 0.00000000e+00 2.85000000e-04] with estimated performance 2.315414
09/09 10:25:02 PM Start iteration 15 ... 
09/09 10:25:02 PM Train model...
09/09 10:25:04 PM Time to train the model: 2.373164
09/09 10:25:33 PM Maximize acquisition function...
   31 &      -0.0036664077 &      -0.0005046349 \\\\ 
   57 &      -0.0039982884 &      -0.0003933554 \\\\ 
  125 &      -0.0044356507 &      -0.0003933554 \\\\ 
  209 &      -0.0045345968 &      -0.0003529559 \\\\ 
  269 &      -0.0046026551 &      -0.0003529559 \\\\ 
  307 &      -0.0046203229 &      -0.0003529559 \\\\ 
  347 &      -0.0046297982 &      -0.0003529559 \\\\ 
  419 &      -0.0046664750 &      -0.0003529559 \\\\ 
DIRECT stopped: numfunc >= maxf.
DIRECT Version 2.0.4
 Problem Dimension n                    :      8
 Eps value                              :   0.1000E-03
 Epsilon is constant.
 Maximum number of f-evaluations (maxf) :    400
 Maximum number of iterations (MaxT)    :    200
 Value of f_global                      :  -0.1000+101
 Global percentage wanted               :   0.1000E-01
 Volume percentage wanted               :  -0.1000E+01
 Measure percentage wanted              :  -0.1000E+01
 Jones original DIRECT algorithm is used.
Bounds on variable x 1    :     16.00000 <= xi <=     32.00000
Bounds on variable x 2    :      0.00000 <= xi <=      0.40000
Bounds on variable x 3    :      4.00000 <= xi <=      8.00000
Bounds on variable x 4    :      0.00000 <= xi <=      0.10000
Bounds on variable x 5    :      0.00000 <= xi <=      2.00000
Bounds on variable x 6    :      3.00000 <= xi <=      6.00000
Bounds on variable x 7    :      0.00000 <= xi <=      3.00000
Bounds on variable x 8    :      0.00001 <= xi <=      0.00100
---------------------------------------------------------------------------
   17 &      -0.0057824320 &      -0.0017578704 \\\\ 
   31 &      -0.0070298492 &      -0.0017578704 \\\\ 
   57 &      -0.0078255921 &      -0.0017578704 \\\\ 
  125 &      -0.0080834947 &      -0.0017578704 \\\\ 
  175 &      -0.0082455759 &      -0.0017578704 \\\\ 
  223 &      -0.0082682456 &      -0.0017578704 \\\\ 
  331 &      -0.0084800540 &      -0.0016228259 \\\\ 
  381 &      -0.0085842743 &      -0.0016228259 \\\\ 
  427 &      -0.0086515038 &      -0.0016228259 \\\\ 
DIRECT stopped: numfunc >= maxf.
DIRECT Version 2.0.4
 Problem Dimension n                    :      8
 Eps value                              :   0.1000E-03
 Epsilon is constant.
 Maximum number of f-evaluations (maxf) :    400
 Maximum number of iterations (MaxT)    :    200
 Value of f_global                      :  -0.1000+101
 Global percentage wanted               :   0.1000E-01
 Volume percentage wanted               :  -0.1000E+01
 Measure percentage wanted              :  -0.1000E+01
 Jones original DIRECT algorithm is used.
Bounds on variable x 1    :     16.00000 <= xi <=     32.00000
Bounds on variable x 2    :      0.00000 <= xi <=      0.40000
Bounds on variable x 3    :      4.00000 <= xi <=      8.00000
Bounds on variable x 4    :      0.00000 <= xi <=      0.10000
Bounds on variable x 5    :      0.00000 <= xi <=      2.00000
Bounds on variable x 6    :      3.00000 <= xi <=      6.00000
Bounds on variable x 7    :      0.00000 <= xi <=      3.00000
Bounds on variable x 8    :      0.00001 <= xi <=      0.00100
---------------------------------------------------------------------------
   17 &      -0.0027297338 &      -0.0002819497 \\\\ 
   31 &      -0.0028375642 &      -0.0002819497 \\\\ 
   57 &      -0.0029274524 &      -0.0000950876 \\\\ 
  125 &      -0.0032092979 &      -0.0000950876 \\\\ 
  167 &      -0.0032831370 &      -0.0000950876 \\\\ 
  209 &      -0.0033714074 &      -0.0000927959 \\\\ 
  297 &      -0.0037148256 &      -0.0000684778 \\\\ 
  335 &      -0.0038573571 &      -0.0000684778 \\\\ 
  365 &      -0.0038811873 &      -0.0000684778 \\\\ 
  399 &      -0.0038906349 &      -0.0000684778 \\\\ 
  431 &      -0.0038912852 &      -0.0000684778 \\\\ 
DIRECT stopped: numfunc >= maxf.
DIRECT Version 2.0.4
 Problem Dimension n                    :      8
 Eps value                              :   0.1000E-03
 Epsilon is constant.
 Maximum number of f-evaluations (maxf) :    400
 Maximum number of iterations (MaxT)    :    200
 Value of f_global                      :  -0.1000+101
 Global percentage wanted               :   0.1000E-01
09/09 10:25:46 PM Time to maximize the acquisition function: 12.872431
09/09 10:25:46 PM Next candidate [2.63703704e+01 2.00000000e-01 5.55555556e+00 1.66675000e-02
 4.07407407e-01 4.50000000e+00 1.53703704e+00 6.15000000e-04]
config {'batch_size': 32, 'drop_path_prob': 0.08000000000000002, 'grad_clip_value': 8, 'initial_lr': 1.211539282207375e-06, 'lr_scheduler': 'Exponential', 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.0028361940741568e-05}
09/09 10:25:46 PM gpu device = cuda:0
09/09 10:25:46 PM config = {'batch_size': 32, 'drop_path_prob': 0.08000000000000002, 'grad_clip_value': 8, 'initial_lr': 1.211539282207375e-06, 'lr_scheduler': 'Exponential', 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.0028361940741568e-05}
48 48 16
48 64 16
64 64 32
64 128 32
128 128 64
128 256 64
09/09 10:25:46 PM param size = 0.255930MB
Training size= 48000
09/09 10:25:46 PM epoch 0 lr 1.211539e-07
09/09 10:25:46 PM train 000 2.394835e+00 12.500000 40.625000
09/09 10:25:53 PM train 050 2.351172e+00 7.322304 48.897059
09/09 10:26:01 PM train 100 2.352819e+00 7.209158 47.586634
09/09 10:26:08 PM train 150 2.353453e+00 6.974338 47.299255
09/09 10:26:15 PM train 200 2.354967e+00 6.887438 46.944963
09/09 10:26:23 PM train 250 2.353450e+00 6.947211 47.292082
09/09 10:26:30 PM train 300 2.352359e+00 7.018272 47.617317
09/09 10:26:38 PM train 350 2.351636e+00 7.015670 47.854345
09/09 10:26:45 PM train 400 2.351109e+00 7.009819 47.985505
09/09 10:26:52 PM train 450 2.350702e+00 7.064163 48.108370
09/09 10:27:00 PM train 500 2.350643e+00 7.051522 48.147455
09/09 10:27:07 PM train 550 2.350310e+00 7.029832 48.066016
09/09 10:27:15 PM train 600 2.349979e+00 7.061148 48.047525
09/09 10:27:22 PM train 650 2.350464e+00 7.022849 48.031874
09/09 10:27:30 PM train 700 2.350411e+00 6.998930 48.025143
09/09 10:27:37 PM train_acc 7.035417
09/09 10:27:37 PM valid 000 2.386125e+00 4.687500 35.937500
09/09 10:27:38 PM valid 050 2.350175e+00 7.352941 47.334559
09/09 10:27:40 PM valid 100 2.351726e+00 7.116337 47.663985
09/09 10:27:41 PM valid 150 2.349058e+00 7.233030 48.271937
09/09 10:27:42 PM valid_acc 7.166667
09/09 10:27:42 PM epoch 1 lr 1.211539e-08
09/09 10:27:42 PM train 000 2.361015e+00 9.375000 50.000000
09/09 10:27:50 PM train 050 2.353469e+00 7.873775 49.325980
09/09 10:27:58 PM train 100 2.354228e+00 7.688738 48.917079
09/09 10:28:05 PM train 150 2.354650e+00 7.709023 48.406457
09/09 10:28:13 PM train 200 2.354534e+00 7.781405 48.538557
09/09 10:28:20 PM train 250 2.353954e+00 7.837400 48.431275
09/09 10:28:28 PM train 300 2.354054e+00 7.911130 48.525748
09/09 10:28:36 PM train 350 2.353682e+00 7.928241 48.593305
09/09 10:28:43 PM train 400 2.353519e+00 7.980050 48.671291
09/09 10:28:51 PM train 450 2.353850e+00 7.958010 48.693875
09/09 10:28:59 PM train 500 2.353922e+00 7.856163 48.830464
09/09 10:29:06 PM train 550 2.354158e+00 7.815336 48.718240
09/09 10:29:14 PM train 600 2.353773e+00 7.893095 48.819676
09/09 10:29:22 PM train 650 2.353594e+00 7.879704 48.869528
09/09 10:29:29 PM train 700 2.353462e+00 7.897200 48.910039
09/09 10:29:37 PM train_acc 7.885417
09/09 10:29:37 PM valid 000 2.350267e+00 6.250000 43.750000
09/09 10:29:38 PM valid 050 2.328084e+00 9.007353 48.621324
09/09 10:29:40 PM valid 100 2.334087e+00 8.539604 47.416460
09/09 10:29:41 PM valid 150 2.333414e+00 8.588576 47.547599
09/09 10:29:42 PM valid_acc 8.441667
09/09 10:29:42 PM Configuration achieved a performance of 2.334009 
09/09 10:29:42 PM Evaluation of this configuration took 236.538875 seconds
09/09 10:29:42 PM Current incumbent [2.93333333e+01 2.00000000e-01 4.66666667e+00 2.77785000e-02
 1.00000000e+00 4.50000000e+00 0.00000000e+00 2.85000000e-04] with estimated performance 2.315414
09/09 10:29:42 PM Start iteration 16 ... 
09/09 10:29:42 PM Train model...
09/09 10:29:44 PM Time to train the model: 2.361187
09/09 10:30:13 PM Maximize acquisition function...
09/09 10:30:26 PM Time to maximize the acquisition function: 13.168233
09/09 10:30:26 PM Next candidate [2.57777778e+01 2.44444444e-01 6.44444444e+00 5.74078333e-02
 5.55555556e-01 4.16666667e+00 5.00000000e-01 4.31666667e-04]
config {'batch_size': 32, 'drop_path_prob': 0.0977777777777778, 'grad_clip_value': 8, 'initial_lr': 1.936596607228515e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'adam', 'weight_decay': 1.001989875643696e-05}
09/09 10:30:26 PM gpu device = cuda:0
09/09 10:30:26 PM config = {'batch_size': 32, 'drop_path_prob': 0.0977777777777778, 'grad_clip_value': 8, 'initial_lr': 1.936596607228515e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'adam', 'weight_decay': 1.001989875643696e-05}
48 48 16
48 64 16
64 64 32
64 128 32
128 128 64
128 256 64
09/09 10:30:26 PM param size = 0.255930MB
Training size= 48000
09/09 10:30:26 PM epoch 0 lr 9.682983e-07
09/09 10:30:26 PM train 000 2.394835e+00 12.500000 40.625000
09/09 10:30:34 PM train 050 2.349818e+00 7.444853 49.172794
09/09 10:30:42 PM train 100 2.350080e+00 7.348391 48.097153
09/09 10:30:50 PM train 150 2.349305e+00 7.284768 48.013245
09/09 10:30:58 PM train 200 2.349321e+00 7.237251 47.768968
09/09 10:31:06 PM train 250 2.346421e+00 7.370518 48.288098
09/09 10:31:14 PM train 300 2.343952e+00 7.532184 48.733389
09/09 10:31:23 PM train 350 2.341919e+00 7.692308 49.096332
09/09 10:31:31 PM train 400 2.340143e+00 7.843672 49.353180
09/09 10:31:39 PM train 450 2.338444e+00 7.985726 49.598115
09/09 10:31:47 PM train 500 2.336981e+00 8.068239 49.815993
09/09 10:31:55 PM train 550 2.335372e+00 8.200998 49.946121
09/09 10:32:03 PM train 600 2.333828e+00 8.394863 50.049397
09/09 10:32:11 PM train 650 2.332922e+00 8.498944 50.127208
09/09 10:32:19 PM train 700 2.331646e+00 8.610467 50.280849
09/09 10:32:27 PM train_acc 8.820833
09/09 10:32:27 PM valid 000 2.341129e+00 6.250000 37.500000
09/09 10:32:29 PM valid 050 2.310707e+00 11.825980 51.868873
09/09 10:32:30 PM valid 100 2.311529e+00 11.370668 51.902847
09/09 10:32:31 PM valid 150 2.308659e+00 11.516970 52.535182
09/09 10:32:32 PM valid_acc 11.575000
09/09 10:32:32 PM epoch 1 lr 0.000000e+00
09/09 10:32:33 PM train 000 2.330919e+00 12.500000 56.250000
09/09 10:32:41 PM train 050 2.318170e+00 11.580882 52.389706
09/09 10:32:49 PM train 100 2.318038e+00 10.906559 52.336015
09/09 10:32:58 PM train 150 2.318934e+00 10.637417 52.007450
09/09 10:33:06 PM train 200 2.317876e+00 10.719838 52.231032
09/09 10:33:14 PM train 250 2.317372e+00 10.725847 52.247261
09/09 10:33:23 PM train 300 2.317516e+00 10.802533 52.211379
09/09 10:33:31 PM train 350 2.317071e+00 10.821759 52.359330
09/09 10:33:39 PM train 400 2.316690e+00 10.840087 52.478180
09/09 10:33:47 PM train 450 2.316863e+00 10.861280 52.452882
09/09 10:33:56 PM train 500 2.316984e+00 10.843937 52.516841
09/09 10:34:04 PM train 550 2.317062e+00 10.812727 52.526656
09/09 10:34:12 PM train 600 2.316856e+00 10.836106 52.498440
09/09 10:34:21 PM train 650 2.316853e+00 10.788690 52.452957
09/09 10:34:29 PM train 700 2.316627e+00 10.870631 52.505350
09/09 10:34:37 PM train_acc 10.889583
09/09 10:34:37 PM valid 000 2.336048e+00 1.562500 48.437500
09/09 10:34:39 PM valid 050 2.305066e+00 10.079657 52.849265
09/09 10:34:40 PM valid 100 2.309098e+00 9.808168 51.840965
09/09 10:34:41 PM valid 150 2.308857e+00 9.902732 51.738411
09/09 10:34:42 PM valid_acc 9.866667
09/09 10:34:42 PM Configuration achieved a performance of 2.309331 
09/09 10:34:42 PM Evaluation of this configuration took 256.780346 seconds
09/09 10:34:42 PM Current incumbent [2.57777778e+01 2.44444444e-01 6.44444444e+00 5.74078333e-02
 1.00000000e+00 4.16666667e+00 0.00000000e+00 4.31666667e-04] with estimated performance 2.309331
09/09 10:34:42 PM Start iteration 17 ... 
09/09 10:34:42 PM Train model...
09/09 10:34:45 PM Time to train the model: 2.395668
09/09 10:35:14 PM Maximize acquisition function...
 Volume percentage wanted               :  -0.1000E+01
 Measure percentage wanted              :  -0.1000E+01
 Jones original DIRECT algorithm is used.
Bounds on variable x 1    :     16.00000 <= xi <=     32.00000
Bounds on variable x 2    :      0.00000 <= xi <=      0.40000
Bounds on variable x 3    :      4.00000 <= xi <=      8.00000
Bounds on variable x 4    :      0.00000 <= xi <=      0.10000
Bounds on variable x 5    :      0.00000 <= xi <=      2.00000
Bounds on variable x 6    :      3.00000 <= xi <=      6.00000
Bounds on variable x 7    :      0.00000 <= xi <=      3.00000
Bounds on variable x 8    :      0.00001 <= xi <=      0.00100
---------------------------------------------------------------------------
   17 &      -0.0060362726 &      -0.0007287023 \\\\ 
   31 &      -0.0068402715 &      -0.0007287023 \\\\ 
   95 &      -0.0071922157 &      -0.0002640683 \\\\ 
  139 &      -0.0074228827 &      -0.0002640683 \\\\ 
  187 &      -0.0075242853 &      -0.0002640683 \\\\ 
  303 &      -0.0079085654 &      -0.0002640683 \\\\ 
  341 &      -0.0079796820 &      -0.0002640683 \\\\ 
  431 &      -0.0080246386 &      -0.0002640683 \\\\ 
DIRECT stopped: numfunc >= maxf.
DIRECT Version 2.0.4
 Problem Dimension n                    :      8
 Eps value                              :   0.1000E-03
 Epsilon is constant.
 Maximum number of f-evaluations (maxf) :    400
 Maximum number of iterations (MaxT)    :    200
 Value of f_global                      :  -0.1000+101
 Global percentage wanted               :   0.1000E-01
 Volume percentage wanted               :  -0.1000E+01
 Measure percentage wanted              :  -0.1000E+01
 Jones original DIRECT algorithm is used.
Bounds on variable x 1    :     16.00000 <= xi <=     32.00000
Bounds on variable x 2    :      0.00000 <= xi <=      0.40000
Bounds on variable x 3    :      4.00000 <= xi <=      8.00000
Bounds on variable x 4    :      0.00000 <= xi <=      0.10000
Bounds on variable x 5    :      0.00000 <= xi <=      2.00000
Bounds on variable x 6    :      3.00000 <= xi <=      6.00000
Bounds on variable x 7    :      0.00000 <= xi <=      3.00000
Bounds on variable x 8    :      0.00001 <= xi <=      0.00100
---------------------------------------------------------------------------
   17 &      -0.0106566728 &      -0.0014710228 \\\\ 
   31 &      -0.0117228206 &      -0.0014710228 \\\\ 
   95 &      -0.0138288005 &      -0.0009143294 \\\\ 
  131 &      -0.0144626657 &      -0.0009143294 \\\\ 
  173 &      -0.0145666794 &      -0.0009143294 \\\\ 
  213 &      -0.0146300406 &      -0.0009143294 \\\\ 
  251 &      -0.0147339698 &      -0.0007194074 \\\\ 
  275 &      -0.0147835004 &      -0.0007194074 \\\\ 
  305 &      -0.0148223566 &      -0.0007194074 \\\\ 
  389 &      -0.0148464513 &      -0.0007194074 \\\\ 
  439 &      -0.0148570521 &      -0.0007194074 \\\\ 
DIRECT stopped: numfunc >= maxf.
DIRECT Version 2.0.4
 Problem Dimension n                    :      8
 Eps value                              :   0.1000E-03
 Epsilon is constant.
 Maximum number of f-evaluations (maxf) :    400
 Maximum number of iterations (MaxT)    :    200
 Value of f_global                      :  -0.1000+101
 Global percentage wanted               :   0.1000E-01
 Volume percentage wanted               :  -0.1000E+01
 Measure percentage wanted              :  -0.1000E+01
 Jones original DIRECT algorithm is used.
Bounds on variable x 1    :     16.00000 <= xi <=     32.00000
Bounds on variable x 2    :      0.00000 <= xi <=      0.40000
Bounds on variable x 3    :      4.00000 <= xi <=      8.00000
Bounds on variable x 4    :      0.00000 <= xi <=      0.10000
Bounds on variable x 5    :      0.00000 <= xi <=      2.00000
Bounds on variable x 6    :      3.00000 <= xi <=      6.00000
Bounds on variable x 7    :      0.00000 <= xi <=      3.00000
Bounds on variable x 8    :      0.00001 <= xi <=      0.00100
---------------------------------------------------------------------------
   17 &      -0.0160962549 &      -0.0022880655 \\\\ 
   31 &      -0.0189019489 &      -0.0022880655 \\\\ 
09/09 10:35:27 PM Time to maximize the acquisition function: 13.354534
09/09 10:35:27 PM Next candidate [2.04444444e+01 6.66666667e-02 7.48148148e+00 2.77785000e-02
 4.07407407e-01 4.50000000e+00 5.00000000e-01 5.05000000e-04]
config {'batch_size': 32, 'drop_path_prob': 0.026666666666666672, 'grad_clip_value': 8, 'initial_lr': 1.376868613317072e-06, 'lr_scheduler': 'Exponential', 'n_conv_layers': 6, 'optimizer': 'adam', 'weight_decay': 1.0023283172746057e-05}
09/09 10:35:27 PM gpu device = cuda:0
09/09 10:35:27 PM config = {'batch_size': 32, 'drop_path_prob': 0.026666666666666672, 'grad_clip_value': 8, 'initial_lr': 1.376868613317072e-06, 'lr_scheduler': 'Exponential', 'n_conv_layers': 6, 'optimizer': 'adam', 'weight_decay': 1.0023283172746057e-05}
48 48 16
48 64 16
64 64 32
64 128 32
128 128 64
128 256 64
09/09 10:35:27 PM param size = 0.255930MB
Training size= 48000
09/09 10:35:27 PM epoch 0 lr 1.376869e-07
09/09 10:35:28 PM train 000 2.394835e+00 12.500000 40.625000
09/09 10:35:36 PM train 050 2.350993e+00 7.322304 48.958333
09/09 10:35:44 PM train 100 2.352458e+00 7.224629 47.679455
09/09 10:35:52 PM train 150 2.352903e+00 7.015728 47.382036
09/09 10:36:00 PM train 200 2.354217e+00 6.926306 47.069341
09/09 10:36:08 PM train 250 2.352510e+00 6.997012 47.503735
09/09 10:36:16 PM train 300 2.351232e+00 7.075374 47.824958
09/09 10:36:24 PM train 350 2.350330e+00 7.086895 48.085826
09/09 10:36:32 PM train 400 2.349630e+00 7.111128 48.242675
09/09 10:36:40 PM train 450 2.349046e+00 7.164634 48.406319
09/09 10:36:48 PM train 500 2.348792e+00 7.166916 48.481163
09/09 10:36:57 PM train 550 2.348276e+00 7.160277 48.437500
09/09 10:37:05 PM train 600 2.347770e+00 7.193740 48.427101
09/09 10:37:13 PM train 650 2.348057e+00 7.162058 48.427899
09/09 10:37:21 PM train 700 2.347831e+00 7.152728 48.457561
09/09 10:37:29 PM train_acc 7.212500
09/09 10:37:29 PM valid 000 2.379924e+00 6.250000 37.500000
09/09 10:37:30 PM valid 050 2.344598e+00 7.689951 48.100490
09/09 10:37:32 PM valid 100 2.346043e+00 7.611386 48.483911
09/09 10:37:33 PM valid 150 2.343342e+00 7.781457 48.975579
09/09 10:37:34 PM valid_acc 7.675000
09/09 10:37:34 PM epoch 1 lr 1.376869e-08
09/09 10:37:34 PM train 000 2.331232e+00 7.812500 51.562500
09/09 10:37:43 PM train 050 2.342565e+00 8.088235 49.724265
09/09 10:37:51 PM train 100 2.342118e+00 7.827970 49.907178
09/09 10:37:59 PM train 150 2.344548e+00 7.657285 48.996275
09/09 10:38:08 PM train 200 2.344936e+00 7.672575 48.865050
09/09 10:38:16 PM train 250 2.344700e+00 7.719124 48.929283
09/09 10:38:24 PM train 300 2.344356e+00 7.667151 49.024086
09/09 10:38:32 PM train 350 2.344011e+00 7.710114 49.029558
09/09 10:38:41 PM train 400 2.344035e+00 7.691708 49.092113
09/09 10:38:49 PM train 450 2.344451e+00 7.680848 49.102688
09/09 10:38:57 PM train 500 2.344606e+00 7.619137 49.136103
09/09 10:39:06 PM train 550 2.345146e+00 7.577132 49.047187
09/09 10:39:14 PM train 600 2.345190e+00 7.562916 48.926269
09/09 10:39:22 PM train 650 2.345015e+00 7.577285 49.013537
09/09 10:39:31 PM train 700 2.345025e+00 7.598520 49.048235
09/09 10:39:39 PM train_acc 7.531250
09/09 10:39:39 PM valid 000 2.355119e+00 4.687500 42.187500
09/09 10:39:40 PM valid 050 2.332263e+00 8.088235 49.601716
09/09 10:39:42 PM valid 100 2.336261e+00 7.827970 48.978960
09/09 10:39:43 PM valid 150 2.335697e+00 7.771109 48.882450
09/09 10:39:44 PM valid_acc 7.708333
09/09 10:39:44 PM Configuration achieved a performance of 2.336640 
09/09 10:39:44 PM Evaluation of this configuration took 256.914231 seconds
09/09 10:39:44 PM Current incumbent [2.57777778e+01 2.44444444e-01 6.44444444e+00 5.74078333e-02
 1.00000000e+00 4.16666667e+00 0.00000000e+00 4.31666667e-04] with estimated performance 2.309331
09/09 10:39:44 PM Start iteration 18 ... 
09/09 10:39:44 PM Train model...
09/09 10:39:47 PM Time to train the model: 2.422139
09/09 10:40:18 PM Maximize acquisition function...
09/09 10:40:31 PM Time to maximize the acquisition function: 13.242028
09/09 10:40:31 PM Next candidate [2.04444444e+01 2.59259259e-01 6.44444444e+00 3.88895000e-02
 5.55555556e-01 4.16666667e+00 1.83333333e+00 6.50000000e-05]
config {'batch_size': 32, 'drop_path_prob': 0.1037037037037037, 'grad_clip_value': 8, 'initial_lr': 1.5647591507587493e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.0002993808675978e-05}
09/09 10:40:31 PM gpu device = cuda:0
09/09 10:40:31 PM config = {'batch_size': 32, 'drop_path_prob': 0.1037037037037037, 'grad_clip_value': 8, 'initial_lr': 1.5647591507587493e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'optimizer': 'sgd', 'weight_decay': 1.0002993808675978e-05}
48 48 16
48 64 16
64 64 32
64 128 32
128 128 64
128 256 64
09/09 10:40:31 PM param size = 0.255930MB
Training size= 48000
09/09 10:40:31 PM epoch 0 lr 7.823796e-07
09/09 10:40:31 PM train 000 2.394835e+00 12.500000 40.625000
09/09 10:40:39 PM train 050 2.351078e+00 7.352941 48.866422
09/09 10:40:46 PM train 100 2.352601e+00 7.240099 47.633045
09/09 10:40:54 PM train 150 2.353129e+00 7.026076 47.268212
09/09 10:41:01 PM train 200 2.354517e+00 6.918532 46.898321
09/09 10:41:08 PM train 250 2.352898e+00 6.959661 47.242281
09/09 10:41:16 PM train 300 2.351691e+00 7.049419 47.591362
09/09 10:41:23 PM train 350 2.350850e+00 7.046830 47.872151
09/09 10:41:31 PM train 400 2.350224e+00 7.044888 48.012781
09/09 10:41:38 PM train 450 2.349690e+00 7.084950 48.143016
09/09 10:41:45 PM train 500 2.349502e+00 7.067116 48.187999
09/09 10:41:53 PM train 550 2.349080e+00 7.052518 48.153925
09/09 10:42:00 PM train 600 2.348662e+00 7.097546 48.102121
09/09 10:42:08 PM train 650 2.349027e+00 7.051651 48.082277
09/09 10:42:15 PM train 700 2.348856e+00 7.032364 48.103156
09/09 10:42:22 PM train_acc 7.070833
09/09 10:42:22 PM valid 000 2.381748e+00 6.250000 32.812500
09/09 10:42:24 PM valid 050 2.346852e+00 7.598039 47.977941
09/09 10:42:25 PM valid 100 2.348285e+00 7.209158 47.973391
09/09 10:42:27 PM valid 150 2.345643e+00 7.357202 48.437500
09/09 10:42:28 PM valid_acc 7.358333
09/09 10:42:28 PM epoch 1 lr 0.000000e+00
09/09 10:42:28 PM train 000 2.369678e+00 7.812500 48.437500
09/09 10:42:36 PM train 050 2.354725e+00 8.210784 48.100490
09/09 10:42:43 PM train 100 2.353546e+00 7.750619 48.483911
09/09 10:42:51 PM train 150 2.353186e+00 7.812500 48.334023
09/09 10:42:58 PM train 200 2.352403e+00 7.820274 48.523010
09/09 10:43:06 PM train 250 2.351725e+00 7.893426 48.636703
09/09 10:43:14 PM train 300 2.352172e+00 7.937085 48.499792
09/09 10:43:21 PM train 350 2.351576e+00 7.972756 48.753561
09/09 10:43:29 PM train 400 2.351481e+00 7.956671 48.714152
09/09 10:43:37 PM train 450 2.351785e+00 8.020371 48.652300
09/09 10:43:44 PM train 500 2.351806e+00 7.987151 48.793039
09/09 10:43:52 PM train 550 2.351926e+00 7.993988 48.766447
09/09 10:43:59 PM train 600 2.351821e+00 8.043885 48.775478
09/09 10:44:07 PM train 650 2.351934e+00 8.006912 48.730319
09/09 10:44:15 PM train 700 2.351501e+00 8.082204 48.805278
09/09 10:44:22 PM train_acc 8.079167
09/09 10:44:22 PM valid 000 2.346912e+00 4.687500 46.875000
09/09 10:44:24 PM valid 050 2.324793e+00 10.447304 48.498775
09/09 10:44:25 PM valid 100 2.331278e+00 9.467822 47.091584
09/09 10:44:27 PM valid 150 2.330491e+00 9.592301 47.278560
09/09 10:44:28 PM valid_acc 9.391667
09/09 10:44:28 PM Configuration achieved a performance of 2.331247 
09/09 10:44:28 PM Evaluation of this configuration took 236.519006 seconds
09/09 10:44:28 PM Current incumbent [2.57777778e+01 2.44444444e-01 6.44444444e+00 5.74078333e-02
 1.00000000e+00 4.16666667e+00 0.00000000e+00 4.31666667e-04] with estimated performance 2.309331
09/09 10:44:28 PM Start iteration 19 ... 
09/09 10:44:28 PM Train model...
09/09 10:44:30 PM Time to train the model: 2.536282
09/09 10:45:02 PM Maximize acquisition function...
09/09 10:45:15 PM Time to maximize the acquisition function: 12.337026
09/09 10:45:15 PM Next candidate [2.40000000e+01 1.85185185e-01 6.00000000e+00 4.62968333e-02
 5.55555556e-01 4.83333333e+00 2.61111111e+00 4.68333333e-04]
config {'batch_size': 32, 'drop_path_prob': 0.07407407407407408, 'grad_clip_value': 8, 'initial_lr': 1.704057192352142e-06, 'lr_scheduler': 'Cosine', 'n_conv_layers': 6, 'weight_decay': 1.0021590821721555e-05}
09/09 10:45:15 PM Configuration achieved a performance of 100.000000 
09/09 10:45:15 PM Evaluation of this configuration took 0.000229 seconds
09/09 10:45:15 PM Current incumbent [2.57777778e+01 2.44444444e-01 6.44444444e+00 5.74078333e-02
 1.00000000e+00 4.16666667e+00 0.00000000e+00 4.31666667e-04] with estimated performance 2.309331
09/09 10:45:15 PM Return [25.77777777777778, 0.24444444444444446, 6.444444444444445, 0.057407833333333345, 1.0, 4.166666666666667, 0.0, 0.0004316666666666667] as incumbent with error 2.309331 
   57 &      -0.0216757601 &      -0.0022880655 \\\\ 
   79 &      -0.0234513609 &      -0.0022880655 \\\\ 
  161 &      -0.0242180354 &      -0.0022880655 \\\\ 
  189 &      -0.0244124616 &      -0.0022880655 \\\\ 
  267 &      -0.0249024144 &      -0.0022880655 \\\\ 
  303 &      -0.0250369423 &      -0.0022880655 \\\\ 
  389 &      -0.0253265753 &      -0.0022880655 \\\\ 
  443 &      -0.0255130445 &      -0.0022880655 \\\\ 
DIRECT stopped: numfunc >= maxf.
DIRECT Version 2.0.4
 Problem Dimension n                    :      8
 Eps value                              :   0.1000E-03
 Epsilon is constant.
 Maximum number of f-evaluations (maxf) :    400
 Maximum number of iterations (MaxT)    :    200
 Value of f_global                      :  -0.1000+101
 Global percentage wanted               :   0.1000E-01
 Volume percentage wanted               :  -0.1000E+01
 Measure percentage wanted              :  -0.1000E+01
 Jones original DIRECT algorithm is used.
Bounds on variable x 1    :     16.00000 <= xi <=     32.00000
Bounds on variable x 2    :      0.00000 <= xi <=      0.40000
Bounds on variable x 3    :      4.00000 <= xi <=      8.00000
Bounds on variable x 4    :      0.00000 <= xi <=      0.10000
Bounds on variable x 5    :      0.00000 <= xi <=      2.00000
Bounds on variable x 6    :      3.00000 <= xi <=      6.00000
Bounds on variable x 7    :      0.00000 <= xi <=      3.00000
Bounds on variable x 8    :      0.00001 <= xi <=      0.00100
---------------------------------------------------------------------------
   17 &      -0.0245681392 &      -0.0007767951 \\\\ 
   31 &      -0.0282516594 &      -0.0007767951 \\\\ 
   57 &      -0.0299514469 &      -0.0007767951 \\\\ 
  125 &      -0.0311965789 &      -0.0007767951 \\\\ 
  175 &      -0.0321825813 &      -0.0007767951 \\\\ 
  217 &      -0.0328147956 &      -0.0007767951 \\\\ 
  263 &      -0.0331268526 &      -0.0007767951 \\\\ 
  299 &      -0.0335801115 &      -0.0007767951 \\\\ 
  329 &      -0.0338393187 &      -0.0007767951 \\\\ 
  357 &      -0.0339074330 &      -0.0007767951 \\\\ 
  387 &      -0.0339695928 &      -0.0007767951 \\\\ 
  437 &      -0.0340226546 &      -0.0007767951 \\\\ 
DIRECT stopped: numfunc >= maxf.
DIRECT Version 2.0.4
 Problem Dimension n                    :      8
 Eps value                              :   0.1000E-03
 Epsilon is constant.
 Maximum number of f-evaluations (maxf) :    400
 Maximum number of iterations (MaxT)    :    200
 Value of f_global                      :  -0.1000+101
 Global percentage wanted               :   0.1000E-01
 Volume percentage wanted               :  -0.1000E+01
 Measure percentage wanted              :  -0.1000E+01
 Jones original DIRECT algorithm is used.
Bounds on variable x 1    :     16.00000 <= xi <=     32.00000
Bounds on variable x 2    :      0.00000 <= xi <=      0.40000
Bounds on variable x 3    :      4.00000 <= xi <=      8.00000
Bounds on variable x 4    :      0.00000 <= xi <=      0.10000
Bounds on variable x 5    :      0.00000 <= xi <=      2.00000
Bounds on variable x 6    :      3.00000 <= xi <=      6.00000
Bounds on variable x 7    :      0.00000 <= xi <=      3.00000
Bounds on variable x 8    :      0.00001 <= xi <=      0.00100
---------------------------------------------------------------------------
   17 &      -0.0673384692 &      -0.0016562836 \\\\ 
   31 &      -0.0718644881 &      -0.0016562836 \\\\ 
   95 &      -0.0812972961 &      -0.0016562836 \\\\ 
  139 &      -0.0819300534 &      -0.0016562836 \\\\ 
  237 &      -0.0823113930 &      -0.0016562836 \\\\ 
  289 &      -0.0825015459 &      -0.0007875094 \\\\ 
  343 &      -0.0827874526 &      -0.0007875094 \\\\ 
  405 &      -0.0828716904 &      -0.0007875094 \\\\ 
DIRECT stopped: numfunc >= maxf.
